{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 9285,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0032310177705977385,
      "grad_norm": 34.0753173828125,
      "learning_rate": 4.9951534733441036e-05,
      "loss": 6.0805,
      "step": 10
    },
    {
      "epoch": 0.006462035541195477,
      "grad_norm": 17.43198013305664,
      "learning_rate": 4.9897684437264406e-05,
      "loss": 1.4963,
      "step": 20
    },
    {
      "epoch": 0.009693053311793215,
      "grad_norm": 10.218494415283203,
      "learning_rate": 4.984383414108778e-05,
      "loss": 0.8785,
      "step": 30
    },
    {
      "epoch": 0.012924071082390954,
      "grad_norm": 10.021735191345215,
      "learning_rate": 4.9789983844911146e-05,
      "loss": 0.8844,
      "step": 40
    },
    {
      "epoch": 0.01615508885298869,
      "grad_norm": 10.396621704101562,
      "learning_rate": 4.973613354873452e-05,
      "loss": 0.6746,
      "step": 50
    },
    {
      "epoch": 0.01938610662358643,
      "grad_norm": 6.229109764099121,
      "learning_rate": 4.968228325255789e-05,
      "loss": 0.6948,
      "step": 60
    },
    {
      "epoch": 0.022617124394184167,
      "grad_norm": 8.677510261535645,
      "learning_rate": 4.962843295638126e-05,
      "loss": 0.6282,
      "step": 70
    },
    {
      "epoch": 0.025848142164781908,
      "grad_norm": 5.078341484069824,
      "learning_rate": 4.9574582660204634e-05,
      "loss": 0.8092,
      "step": 80
    },
    {
      "epoch": 0.029079159935379646,
      "grad_norm": 8.823516845703125,
      "learning_rate": 4.9520732364028004e-05,
      "loss": 0.7702,
      "step": 90
    },
    {
      "epoch": 0.03231017770597738,
      "grad_norm": 9.344785690307617,
      "learning_rate": 4.946688206785138e-05,
      "loss": 0.771,
      "step": 100
    },
    {
      "epoch": 0.035541195476575124,
      "grad_norm": 9.899773597717285,
      "learning_rate": 4.9413031771674744e-05,
      "loss": 0.7513,
      "step": 110
    },
    {
      "epoch": 0.03877221324717286,
      "grad_norm": 4.770247936248779,
      "learning_rate": 4.9359181475498114e-05,
      "loss": 0.8725,
      "step": 120
    },
    {
      "epoch": 0.0420032310177706,
      "grad_norm": 8.954900741577148,
      "learning_rate": 4.930533117932149e-05,
      "loss": 0.6456,
      "step": 130
    },
    {
      "epoch": 0.045234248788368334,
      "grad_norm": 7.731972694396973,
      "learning_rate": 4.9251480883144855e-05,
      "loss": 0.8212,
      "step": 140
    },
    {
      "epoch": 0.048465266558966075,
      "grad_norm": 8.727777481079102,
      "learning_rate": 4.919763058696823e-05,
      "loss": 0.8216,
      "step": 150
    },
    {
      "epoch": 0.051696284329563816,
      "grad_norm": 7.132745742797852,
      "learning_rate": 4.91437802907916e-05,
      "loss": 0.6854,
      "step": 160
    },
    {
      "epoch": 0.05492730210016155,
      "grad_norm": 6.953613758087158,
      "learning_rate": 4.908992999461497e-05,
      "loss": 0.7559,
      "step": 170
    },
    {
      "epoch": 0.05815831987075929,
      "grad_norm": 6.949471473693848,
      "learning_rate": 4.903607969843834e-05,
      "loss": 0.6783,
      "step": 180
    },
    {
      "epoch": 0.061389337641357025,
      "grad_norm": 5.419915676116943,
      "learning_rate": 4.898222940226171e-05,
      "loss": 0.7272,
      "step": 190
    },
    {
      "epoch": 0.06462035541195477,
      "grad_norm": 5.572080135345459,
      "learning_rate": 4.892837910608509e-05,
      "loss": 0.6984,
      "step": 200
    },
    {
      "epoch": 0.06785137318255251,
      "grad_norm": 4.152251243591309,
      "learning_rate": 4.887452880990845e-05,
      "loss": 0.6364,
      "step": 210
    },
    {
      "epoch": 0.07108239095315025,
      "grad_norm": 4.543114185333252,
      "learning_rate": 4.882067851373183e-05,
      "loss": 0.5163,
      "step": 220
    },
    {
      "epoch": 0.07431340872374798,
      "grad_norm": 7.520122051239014,
      "learning_rate": 4.87668282175552e-05,
      "loss": 0.7731,
      "step": 230
    },
    {
      "epoch": 0.07754442649434572,
      "grad_norm": 8.398537635803223,
      "learning_rate": 4.871297792137857e-05,
      "loss": 0.6554,
      "step": 240
    },
    {
      "epoch": 0.08077544426494346,
      "grad_norm": 5.979633331298828,
      "learning_rate": 4.865912762520194e-05,
      "loss": 0.57,
      "step": 250
    },
    {
      "epoch": 0.0840064620355412,
      "grad_norm": 8.134841918945312,
      "learning_rate": 4.860527732902531e-05,
      "loss": 0.7389,
      "step": 260
    },
    {
      "epoch": 0.08723747980613894,
      "grad_norm": 6.747562408447266,
      "learning_rate": 4.855142703284868e-05,
      "loss": 0.782,
      "step": 270
    },
    {
      "epoch": 0.09046849757673667,
      "grad_norm": 8.840903282165527,
      "learning_rate": 4.849757673667205e-05,
      "loss": 0.6765,
      "step": 280
    },
    {
      "epoch": 0.09369951534733441,
      "grad_norm": 7.44451379776001,
      "learning_rate": 4.844372644049542e-05,
      "loss": 0.6815,
      "step": 290
    },
    {
      "epoch": 0.09693053311793215,
      "grad_norm": 7.596870422363281,
      "learning_rate": 4.83898761443188e-05,
      "loss": 0.579,
      "step": 300
    },
    {
      "epoch": 0.10016155088852989,
      "grad_norm": 6.126553535461426,
      "learning_rate": 4.833602584814217e-05,
      "loss": 0.6172,
      "step": 310
    },
    {
      "epoch": 0.10339256865912763,
      "grad_norm": 5.047300815582275,
      "learning_rate": 4.828217555196554e-05,
      "loss": 0.6803,
      "step": 320
    },
    {
      "epoch": 0.10662358642972536,
      "grad_norm": 4.315315246582031,
      "learning_rate": 4.822832525578891e-05,
      "loss": 0.5842,
      "step": 330
    },
    {
      "epoch": 0.1098546042003231,
      "grad_norm": 6.132907867431641,
      "learning_rate": 4.817447495961228e-05,
      "loss": 0.6585,
      "step": 340
    },
    {
      "epoch": 0.11308562197092084,
      "grad_norm": 7.39940071105957,
      "learning_rate": 4.8120624663435656e-05,
      "loss": 0.6464,
      "step": 350
    },
    {
      "epoch": 0.11631663974151858,
      "grad_norm": 11.19018268585205,
      "learning_rate": 4.806677436725902e-05,
      "loss": 0.6052,
      "step": 360
    },
    {
      "epoch": 0.11954765751211632,
      "grad_norm": 5.490081310272217,
      "learning_rate": 4.8012924071082396e-05,
      "loss": 0.7056,
      "step": 370
    },
    {
      "epoch": 0.12277867528271405,
      "grad_norm": 5.816595554351807,
      "learning_rate": 4.795907377490577e-05,
      "loss": 0.6664,
      "step": 380
    },
    {
      "epoch": 0.1260096930533118,
      "grad_norm": 5.5861310958862305,
      "learning_rate": 4.790522347872913e-05,
      "loss": 0.5473,
      "step": 390
    },
    {
      "epoch": 0.12924071082390953,
      "grad_norm": 5.677304267883301,
      "learning_rate": 4.785137318255251e-05,
      "loss": 0.7861,
      "step": 400
    },
    {
      "epoch": 0.13247172859450726,
      "grad_norm": 5.45418119430542,
      "learning_rate": 4.779752288637588e-05,
      "loss": 0.6849,
      "step": 410
    },
    {
      "epoch": 0.13570274636510501,
      "grad_norm": 5.886417388916016,
      "learning_rate": 4.7743672590199254e-05,
      "loss": 0.6443,
      "step": 420
    },
    {
      "epoch": 0.13893376413570274,
      "grad_norm": 9.187479972839355,
      "learning_rate": 4.768982229402262e-05,
      "loss": 0.6366,
      "step": 430
    },
    {
      "epoch": 0.1421647819063005,
      "grad_norm": 6.043044567108154,
      "learning_rate": 4.763597199784599e-05,
      "loss": 0.6619,
      "step": 440
    },
    {
      "epoch": 0.14539579967689822,
      "grad_norm": 4.649696350097656,
      "learning_rate": 4.7582121701669365e-05,
      "loss": 0.797,
      "step": 450
    },
    {
      "epoch": 0.14862681744749595,
      "grad_norm": 7.0474629402160645,
      "learning_rate": 4.752827140549273e-05,
      "loss": 0.6499,
      "step": 460
    },
    {
      "epoch": 0.1518578352180937,
      "grad_norm": 4.192047119140625,
      "learning_rate": 4.7474421109316105e-05,
      "loss": 0.5539,
      "step": 470
    },
    {
      "epoch": 0.15508885298869143,
      "grad_norm": 7.474441051483154,
      "learning_rate": 4.7420570813139475e-05,
      "loss": 0.7941,
      "step": 480
    },
    {
      "epoch": 0.1583198707592892,
      "grad_norm": 4.800999164581299,
      "learning_rate": 4.7366720516962846e-05,
      "loss": 0.5504,
      "step": 490
    },
    {
      "epoch": 0.16155088852988692,
      "grad_norm": 8.753898620605469,
      "learning_rate": 4.7312870220786216e-05,
      "loss": 0.6171,
      "step": 500
    },
    {
      "epoch": 0.16478190630048464,
      "grad_norm": 6.092473983764648,
      "learning_rate": 4.7259019924609586e-05,
      "loss": 0.561,
      "step": 510
    },
    {
      "epoch": 0.1680129240710824,
      "grad_norm": 6.263099193572998,
      "learning_rate": 4.720516962843296e-05,
      "loss": 0.5916,
      "step": 520
    },
    {
      "epoch": 0.17124394184168013,
      "grad_norm": 8.457779884338379,
      "learning_rate": 4.7151319332256326e-05,
      "loss": 0.6263,
      "step": 530
    },
    {
      "epoch": 0.17447495961227788,
      "grad_norm": 4.0908331871032715,
      "learning_rate": 4.70974690360797e-05,
      "loss": 0.6554,
      "step": 540
    },
    {
      "epoch": 0.1777059773828756,
      "grad_norm": 4.279803276062012,
      "learning_rate": 4.7043618739903073e-05,
      "loss": 0.7109,
      "step": 550
    },
    {
      "epoch": 0.18093699515347333,
      "grad_norm": 5.417016506195068,
      "learning_rate": 4.6989768443726444e-05,
      "loss": 0.6019,
      "step": 560
    },
    {
      "epoch": 0.1841680129240711,
      "grad_norm": 5.828342914581299,
      "learning_rate": 4.6935918147549814e-05,
      "loss": 0.7134,
      "step": 570
    },
    {
      "epoch": 0.18739903069466882,
      "grad_norm": 4.591030597686768,
      "learning_rate": 4.6882067851373184e-05,
      "loss": 0.7083,
      "step": 580
    },
    {
      "epoch": 0.19063004846526657,
      "grad_norm": 5.88403844833374,
      "learning_rate": 4.6828217555196554e-05,
      "loss": 0.698,
      "step": 590
    },
    {
      "epoch": 0.1938610662358643,
      "grad_norm": 7.931091785430908,
      "learning_rate": 4.6774367259019924e-05,
      "loss": 0.6515,
      "step": 600
    },
    {
      "epoch": 0.19709208400646203,
      "grad_norm": 6.014880657196045,
      "learning_rate": 4.6720516962843295e-05,
      "loss": 0.6566,
      "step": 610
    },
    {
      "epoch": 0.20032310177705978,
      "grad_norm": 7.409234046936035,
      "learning_rate": 4.666666666666667e-05,
      "loss": 0.6507,
      "step": 620
    },
    {
      "epoch": 0.2035541195476575,
      "grad_norm": 6.342907428741455,
      "learning_rate": 4.661281637049004e-05,
      "loss": 0.5796,
      "step": 630
    },
    {
      "epoch": 0.20678513731825526,
      "grad_norm": 6.366989612579346,
      "learning_rate": 4.655896607431341e-05,
      "loss": 0.716,
      "step": 640
    },
    {
      "epoch": 0.210016155088853,
      "grad_norm": 5.631803512573242,
      "learning_rate": 4.650511577813678e-05,
      "loss": 0.6638,
      "step": 650
    },
    {
      "epoch": 0.21324717285945072,
      "grad_norm": 4.203280448913574,
      "learning_rate": 4.645126548196015e-05,
      "loss": 0.5892,
      "step": 660
    },
    {
      "epoch": 0.21647819063004847,
      "grad_norm": 6.56283712387085,
      "learning_rate": 4.639741518578352e-05,
      "loss": 0.605,
      "step": 670
    },
    {
      "epoch": 0.2197092084006462,
      "grad_norm": 6.640733242034912,
      "learning_rate": 4.634356488960689e-05,
      "loss": 0.8735,
      "step": 680
    },
    {
      "epoch": 0.22294022617124395,
      "grad_norm": 5.294511795043945,
      "learning_rate": 4.628971459343027e-05,
      "loss": 0.6706,
      "step": 690
    },
    {
      "epoch": 0.22617124394184168,
      "grad_norm": 8.261088371276855,
      "learning_rate": 4.623586429725364e-05,
      "loss": 0.6751,
      "step": 700
    },
    {
      "epoch": 0.2294022617124394,
      "grad_norm": 3.81868314743042,
      "learning_rate": 4.6182014001077e-05,
      "loss": 0.685,
      "step": 710
    },
    {
      "epoch": 0.23263327948303716,
      "grad_norm": 10.138895988464355,
      "learning_rate": 4.612816370490038e-05,
      "loss": 0.6219,
      "step": 720
    },
    {
      "epoch": 0.2358642972536349,
      "grad_norm": 7.007048606872559,
      "learning_rate": 4.607431340872375e-05,
      "loss": 0.6654,
      "step": 730
    },
    {
      "epoch": 0.23909531502423265,
      "grad_norm": 5.96441650390625,
      "learning_rate": 4.602046311254712e-05,
      "loss": 0.6903,
      "step": 740
    },
    {
      "epoch": 0.24232633279483037,
      "grad_norm": 6.107661724090576,
      "learning_rate": 4.596661281637049e-05,
      "loss": 0.6404,
      "step": 750
    },
    {
      "epoch": 0.2455573505654281,
      "grad_norm": 5.454407215118408,
      "learning_rate": 4.591276252019386e-05,
      "loss": 0.6349,
      "step": 760
    },
    {
      "epoch": 0.24878836833602586,
      "grad_norm": 4.563236236572266,
      "learning_rate": 4.585891222401724e-05,
      "loss": 0.7557,
      "step": 770
    },
    {
      "epoch": 0.2520193861066236,
      "grad_norm": 6.125796318054199,
      "learning_rate": 4.58050619278406e-05,
      "loss": 0.6683,
      "step": 780
    },
    {
      "epoch": 0.2552504038772213,
      "grad_norm": 4.779496192932129,
      "learning_rate": 4.575121163166398e-05,
      "loss": 0.609,
      "step": 790
    },
    {
      "epoch": 0.25848142164781907,
      "grad_norm": 5.258349418640137,
      "learning_rate": 4.569736133548735e-05,
      "loss": 0.6984,
      "step": 800
    },
    {
      "epoch": 0.2617124394184168,
      "grad_norm": 4.948271751403809,
      "learning_rate": 4.564351103931072e-05,
      "loss": 0.623,
      "step": 810
    },
    {
      "epoch": 0.2649434571890145,
      "grad_norm": 5.9449639320373535,
      "learning_rate": 4.558966074313409e-05,
      "loss": 0.6516,
      "step": 820
    },
    {
      "epoch": 0.2681744749596123,
      "grad_norm": 5.46173095703125,
      "learning_rate": 4.553581044695746e-05,
      "loss": 0.5932,
      "step": 830
    },
    {
      "epoch": 0.27140549273021003,
      "grad_norm": 7.43815279006958,
      "learning_rate": 4.5481960150780836e-05,
      "loss": 0.7513,
      "step": 840
    },
    {
      "epoch": 0.27463651050080773,
      "grad_norm": 10.136825561523438,
      "learning_rate": 4.54281098546042e-05,
      "loss": 0.5615,
      "step": 850
    },
    {
      "epoch": 0.2778675282714055,
      "grad_norm": 6.646399974822998,
      "learning_rate": 4.537425955842757e-05,
      "loss": 0.6255,
      "step": 860
    },
    {
      "epoch": 0.28109854604200324,
      "grad_norm": 4.491087436676025,
      "learning_rate": 4.532040926225095e-05,
      "loss": 0.7445,
      "step": 870
    },
    {
      "epoch": 0.284329563812601,
      "grad_norm": 8.246696472167969,
      "learning_rate": 4.526655896607432e-05,
      "loss": 0.7707,
      "step": 880
    },
    {
      "epoch": 0.2875605815831987,
      "grad_norm": 5.700790882110596,
      "learning_rate": 4.521270866989769e-05,
      "loss": 0.7866,
      "step": 890
    },
    {
      "epoch": 0.29079159935379645,
      "grad_norm": 4.993128776550293,
      "learning_rate": 4.515885837372106e-05,
      "loss": 0.7403,
      "step": 900
    },
    {
      "epoch": 0.2940226171243942,
      "grad_norm": 8.98244571685791,
      "learning_rate": 4.510500807754443e-05,
      "loss": 0.6067,
      "step": 910
    },
    {
      "epoch": 0.2972536348949919,
      "grad_norm": 6.367303371429443,
      "learning_rate": 4.50511577813678e-05,
      "loss": 0.6465,
      "step": 920
    },
    {
      "epoch": 0.30048465266558966,
      "grad_norm": 5.947965145111084,
      "learning_rate": 4.499730748519117e-05,
      "loss": 0.697,
      "step": 930
    },
    {
      "epoch": 0.3037156704361874,
      "grad_norm": 6.025789737701416,
      "learning_rate": 4.4943457189014545e-05,
      "loss": 0.5661,
      "step": 940
    },
    {
      "epoch": 0.3069466882067851,
      "grad_norm": 3.880239248275757,
      "learning_rate": 4.4889606892837915e-05,
      "loss": 0.6072,
      "step": 950
    },
    {
      "epoch": 0.31017770597738287,
      "grad_norm": 5.827055931091309,
      "learning_rate": 4.4835756596661285e-05,
      "loss": 0.6964,
      "step": 960
    },
    {
      "epoch": 0.3134087237479806,
      "grad_norm": 5.009071350097656,
      "learning_rate": 4.4781906300484656e-05,
      "loss": 0.6829,
      "step": 970
    },
    {
      "epoch": 0.3166397415185784,
      "grad_norm": 6.982411861419678,
      "learning_rate": 4.4728056004308026e-05,
      "loss": 0.571,
      "step": 980
    },
    {
      "epoch": 0.3198707592891761,
      "grad_norm": 5.275861740112305,
      "learning_rate": 4.4674205708131396e-05,
      "loss": 0.5833,
      "step": 990
    },
    {
      "epoch": 0.32310177705977383,
      "grad_norm": 3.115532636642456,
      "learning_rate": 4.4620355411954766e-05,
      "loss": 0.6333,
      "step": 1000
    },
    {
      "epoch": 0.3263327948303716,
      "grad_norm": 4.905674934387207,
      "learning_rate": 4.456650511577814e-05,
      "loss": 0.6031,
      "step": 1010
    },
    {
      "epoch": 0.3295638126009693,
      "grad_norm": 6.972469806671143,
      "learning_rate": 4.451265481960151e-05,
      "loss": 0.6781,
      "step": 1020
    },
    {
      "epoch": 0.33279483037156704,
      "grad_norm": 3.9800636768341064,
      "learning_rate": 4.445880452342488e-05,
      "loss": 0.655,
      "step": 1030
    },
    {
      "epoch": 0.3360258481421648,
      "grad_norm": 7.3007283210754395,
      "learning_rate": 4.4404954227248254e-05,
      "loss": 0.7034,
      "step": 1040
    },
    {
      "epoch": 0.3392568659127625,
      "grad_norm": 5.7714924812316895,
      "learning_rate": 4.4351103931071624e-05,
      "loss": 0.6311,
      "step": 1050
    },
    {
      "epoch": 0.34248788368336025,
      "grad_norm": 7.213589668273926,
      "learning_rate": 4.4297253634894994e-05,
      "loss": 0.5714,
      "step": 1060
    },
    {
      "epoch": 0.345718901453958,
      "grad_norm": 3.5361251831054688,
      "learning_rate": 4.4243403338718364e-05,
      "loss": 0.6268,
      "step": 1070
    },
    {
      "epoch": 0.34894991922455576,
      "grad_norm": 6.756217002868652,
      "learning_rate": 4.4189553042541734e-05,
      "loss": 0.6267,
      "step": 1080
    },
    {
      "epoch": 0.35218093699515346,
      "grad_norm": 7.201263427734375,
      "learning_rate": 4.413570274636511e-05,
      "loss": 0.678,
      "step": 1090
    },
    {
      "epoch": 0.3554119547657512,
      "grad_norm": 5.173950672149658,
      "learning_rate": 4.4081852450188475e-05,
      "loss": 0.6535,
      "step": 1100
    },
    {
      "epoch": 0.35864297253634897,
      "grad_norm": 7.079433441162109,
      "learning_rate": 4.402800215401185e-05,
      "loss": 0.5297,
      "step": 1110
    },
    {
      "epoch": 0.36187399030694667,
      "grad_norm": 5.026819705963135,
      "learning_rate": 4.397415185783522e-05,
      "loss": 0.6042,
      "step": 1120
    },
    {
      "epoch": 0.3651050080775444,
      "grad_norm": 4.992667198181152,
      "learning_rate": 4.392030156165859e-05,
      "loss": 0.6269,
      "step": 1130
    },
    {
      "epoch": 0.3683360258481422,
      "grad_norm": 7.293528079986572,
      "learning_rate": 4.386645126548196e-05,
      "loss": 0.5629,
      "step": 1140
    },
    {
      "epoch": 0.3715670436187399,
      "grad_norm": 5.648796558380127,
      "learning_rate": 4.381260096930533e-05,
      "loss": 0.5555,
      "step": 1150
    },
    {
      "epoch": 0.37479806138933763,
      "grad_norm": 8.666446685791016,
      "learning_rate": 4.375875067312871e-05,
      "loss": 0.619,
      "step": 1160
    },
    {
      "epoch": 0.3780290791599354,
      "grad_norm": 7.06863260269165,
      "learning_rate": 4.370490037695207e-05,
      "loss": 0.7113,
      "step": 1170
    },
    {
      "epoch": 0.38126009693053314,
      "grad_norm": 5.1075334548950195,
      "learning_rate": 4.365105008077544e-05,
      "loss": 0.726,
      "step": 1180
    },
    {
      "epoch": 0.38449111470113084,
      "grad_norm": 5.973669528961182,
      "learning_rate": 4.359719978459882e-05,
      "loss": 0.7338,
      "step": 1190
    },
    {
      "epoch": 0.3877221324717286,
      "grad_norm": 4.622194290161133,
      "learning_rate": 4.3543349488422184e-05,
      "loss": 0.7762,
      "step": 1200
    },
    {
      "epoch": 0.39095315024232635,
      "grad_norm": 6.152627944946289,
      "learning_rate": 4.348949919224556e-05,
      "loss": 0.6994,
      "step": 1210
    },
    {
      "epoch": 0.39418416801292405,
      "grad_norm": 5.533524036407471,
      "learning_rate": 4.343564889606893e-05,
      "loss": 0.6708,
      "step": 1220
    },
    {
      "epoch": 0.3974151857835218,
      "grad_norm": 5.418243885040283,
      "learning_rate": 4.33817985998923e-05,
      "loss": 0.6769,
      "step": 1230
    },
    {
      "epoch": 0.40064620355411956,
      "grad_norm": 5.15695858001709,
      "learning_rate": 4.332794830371567e-05,
      "loss": 0.5932,
      "step": 1240
    },
    {
      "epoch": 0.40387722132471726,
      "grad_norm": 8.226658821105957,
      "learning_rate": 4.327409800753904e-05,
      "loss": 0.6824,
      "step": 1250
    },
    {
      "epoch": 0.407108239095315,
      "grad_norm": 6.876315116882324,
      "learning_rate": 4.322024771136242e-05,
      "loss": 0.6364,
      "step": 1260
    },
    {
      "epoch": 0.41033925686591277,
      "grad_norm": 5.561731338500977,
      "learning_rate": 4.316639741518578e-05,
      "loss": 0.694,
      "step": 1270
    },
    {
      "epoch": 0.4135702746365105,
      "grad_norm": 7.170412063598633,
      "learning_rate": 4.311254711900916e-05,
      "loss": 0.6081,
      "step": 1280
    },
    {
      "epoch": 0.4168012924071082,
      "grad_norm": 5.638001441955566,
      "learning_rate": 4.305869682283253e-05,
      "loss": 0.6447,
      "step": 1290
    },
    {
      "epoch": 0.420032310177706,
      "grad_norm": 6.921096324920654,
      "learning_rate": 4.30048465266559e-05,
      "loss": 0.6492,
      "step": 1300
    },
    {
      "epoch": 0.42326332794830374,
      "grad_norm": 4.082505702972412,
      "learning_rate": 4.295099623047927e-05,
      "loss": 0.6492,
      "step": 1310
    },
    {
      "epoch": 0.42649434571890144,
      "grad_norm": 8.228219032287598,
      "learning_rate": 4.289714593430264e-05,
      "loss": 0.6191,
      "step": 1320
    },
    {
      "epoch": 0.4297253634894992,
      "grad_norm": 6.746574878692627,
      "learning_rate": 4.2843295638126016e-05,
      "loss": 0.5761,
      "step": 1330
    },
    {
      "epoch": 0.43295638126009695,
      "grad_norm": 4.63884162902832,
      "learning_rate": 4.278944534194938e-05,
      "loss": 0.5897,
      "step": 1340
    },
    {
      "epoch": 0.43618739903069464,
      "grad_norm": 4.474815368652344,
      "learning_rate": 4.273559504577275e-05,
      "loss": 0.5679,
      "step": 1350
    },
    {
      "epoch": 0.4394184168012924,
      "grad_norm": 5.937878131866455,
      "learning_rate": 4.268174474959613e-05,
      "loss": 0.621,
      "step": 1360
    },
    {
      "epoch": 0.44264943457189015,
      "grad_norm": 5.862432956695557,
      "learning_rate": 4.26278944534195e-05,
      "loss": 0.5858,
      "step": 1370
    },
    {
      "epoch": 0.4458804523424879,
      "grad_norm": 6.819049835205078,
      "learning_rate": 4.257404415724287e-05,
      "loss": 0.8518,
      "step": 1380
    },
    {
      "epoch": 0.4491114701130856,
      "grad_norm": 4.298892974853516,
      "learning_rate": 4.252019386106624e-05,
      "loss": 0.5846,
      "step": 1390
    },
    {
      "epoch": 0.45234248788368336,
      "grad_norm": 5.562167167663574,
      "learning_rate": 4.246634356488961e-05,
      "loss": 0.5534,
      "step": 1400
    },
    {
      "epoch": 0.4555735056542811,
      "grad_norm": 3.557796001434326,
      "learning_rate": 4.241249326871298e-05,
      "loss": 0.6818,
      "step": 1410
    },
    {
      "epoch": 0.4588045234248788,
      "grad_norm": 7.093986511230469,
      "learning_rate": 4.235864297253635e-05,
      "loss": 0.4935,
      "step": 1420
    },
    {
      "epoch": 0.4620355411954766,
      "grad_norm": 5.53594446182251,
      "learning_rate": 4.2304792676359725e-05,
      "loss": 0.6172,
      "step": 1430
    },
    {
      "epoch": 0.46526655896607433,
      "grad_norm": 4.774928569793701,
      "learning_rate": 4.2250942380183095e-05,
      "loss": 0.7517,
      "step": 1440
    },
    {
      "epoch": 0.46849757673667203,
      "grad_norm": 9.675851821899414,
      "learning_rate": 4.219709208400646e-05,
      "loss": 0.678,
      "step": 1450
    },
    {
      "epoch": 0.4717285945072698,
      "grad_norm": 5.297379493713379,
      "learning_rate": 4.2143241787829836e-05,
      "loss": 0.6048,
      "step": 1460
    },
    {
      "epoch": 0.47495961227786754,
      "grad_norm": 4.54803991317749,
      "learning_rate": 4.2089391491653206e-05,
      "loss": 0.5877,
      "step": 1470
    },
    {
      "epoch": 0.4781906300484653,
      "grad_norm": 4.9278106689453125,
      "learning_rate": 4.203554119547658e-05,
      "loss": 0.5741,
      "step": 1480
    },
    {
      "epoch": 0.481421647819063,
      "grad_norm": 8.183439254760742,
      "learning_rate": 4.1981690899299946e-05,
      "loss": 0.7778,
      "step": 1490
    },
    {
      "epoch": 0.48465266558966075,
      "grad_norm": 5.642411231994629,
      "learning_rate": 4.1927840603123316e-05,
      "loss": 0.7557,
      "step": 1500
    },
    {
      "epoch": 0.4878836833602585,
      "grad_norm": 4.317013740539551,
      "learning_rate": 4.1873990306946693e-05,
      "loss": 0.6219,
      "step": 1510
    },
    {
      "epoch": 0.4911147011308562,
      "grad_norm": 4.463254928588867,
      "learning_rate": 4.182014001077006e-05,
      "loss": 0.6092,
      "step": 1520
    },
    {
      "epoch": 0.49434571890145396,
      "grad_norm": 5.30766487121582,
      "learning_rate": 4.1766289714593434e-05,
      "loss": 0.6413,
      "step": 1530
    },
    {
      "epoch": 0.4975767366720517,
      "grad_norm": 17.289899826049805,
      "learning_rate": 4.1712439418416804e-05,
      "loss": 0.6293,
      "step": 1540
    },
    {
      "epoch": 0.5008077544426495,
      "grad_norm": 6.429140567779541,
      "learning_rate": 4.1658589122240174e-05,
      "loss": 0.6064,
      "step": 1550
    },
    {
      "epoch": 0.5040387722132472,
      "grad_norm": 5.450157642364502,
      "learning_rate": 4.1604738826063544e-05,
      "loss": 0.7137,
      "step": 1560
    },
    {
      "epoch": 0.5072697899838449,
      "grad_norm": 6.1420578956604,
      "learning_rate": 4.1550888529886915e-05,
      "loss": 0.6831,
      "step": 1570
    },
    {
      "epoch": 0.5105008077544426,
      "grad_norm": 9.907917976379395,
      "learning_rate": 4.149703823371029e-05,
      "loss": 0.6089,
      "step": 1580
    },
    {
      "epoch": 0.5137318255250404,
      "grad_norm": 5.157035827636719,
      "learning_rate": 4.1443187937533655e-05,
      "loss": 0.6913,
      "step": 1590
    },
    {
      "epoch": 0.5169628432956381,
      "grad_norm": 6.308208465576172,
      "learning_rate": 4.138933764135703e-05,
      "loss": 0.5301,
      "step": 1600
    },
    {
      "epoch": 0.5201938610662359,
      "grad_norm": 5.167101860046387,
      "learning_rate": 4.13354873451804e-05,
      "loss": 0.626,
      "step": 1610
    },
    {
      "epoch": 0.5234248788368336,
      "grad_norm": 3.8084943294525146,
      "learning_rate": 4.128163704900377e-05,
      "loss": 0.5968,
      "step": 1620
    },
    {
      "epoch": 0.5266558966074314,
      "grad_norm": 6.008001804351807,
      "learning_rate": 4.122778675282714e-05,
      "loss": 0.6248,
      "step": 1630
    },
    {
      "epoch": 0.529886914378029,
      "grad_norm": 7.294092178344727,
      "learning_rate": 4.117393645665051e-05,
      "loss": 0.6915,
      "step": 1640
    },
    {
      "epoch": 0.5331179321486268,
      "grad_norm": 5.32042121887207,
      "learning_rate": 4.112008616047388e-05,
      "loss": 0.6271,
      "step": 1650
    },
    {
      "epoch": 0.5363489499192245,
      "grad_norm": 7.177106857299805,
      "learning_rate": 4.106623586429725e-05,
      "loss": 0.7163,
      "step": 1660
    },
    {
      "epoch": 0.5395799676898223,
      "grad_norm": 4.874721050262451,
      "learning_rate": 4.101238556812062e-05,
      "loss": 0.6872,
      "step": 1670
    },
    {
      "epoch": 0.5428109854604201,
      "grad_norm": 4.677715301513672,
      "learning_rate": 4.0958535271944e-05,
      "loss": 0.5302,
      "step": 1680
    },
    {
      "epoch": 0.5460420032310178,
      "grad_norm": 8.272920608520508,
      "learning_rate": 4.090468497576737e-05,
      "loss": 0.5424,
      "step": 1690
    },
    {
      "epoch": 0.5492730210016155,
      "grad_norm": 4.82570743560791,
      "learning_rate": 4.085083467959074e-05,
      "loss": 0.7043,
      "step": 1700
    },
    {
      "epoch": 0.5525040387722132,
      "grad_norm": 7.974873065948486,
      "learning_rate": 4.079698438341411e-05,
      "loss": 0.6633,
      "step": 1710
    },
    {
      "epoch": 0.555735056542811,
      "grad_norm": 6.089016437530518,
      "learning_rate": 4.074313408723748e-05,
      "loss": 0.5597,
      "step": 1720
    },
    {
      "epoch": 0.5589660743134087,
      "grad_norm": 4.247400283813477,
      "learning_rate": 4.068928379106085e-05,
      "loss": 0.6766,
      "step": 1730
    },
    {
      "epoch": 0.5621970920840065,
      "grad_norm": 4.82316780090332,
      "learning_rate": 4.063543349488422e-05,
      "loss": 0.6388,
      "step": 1740
    },
    {
      "epoch": 0.5654281098546042,
      "grad_norm": 6.509833335876465,
      "learning_rate": 4.05815831987076e-05,
      "loss": 0.6637,
      "step": 1750
    },
    {
      "epoch": 0.568659127625202,
      "grad_norm": 5.070039749145508,
      "learning_rate": 4.052773290253097e-05,
      "loss": 0.6219,
      "step": 1760
    },
    {
      "epoch": 0.5718901453957996,
      "grad_norm": 7.556416034698486,
      "learning_rate": 4.047388260635433e-05,
      "loss": 0.6304,
      "step": 1770
    },
    {
      "epoch": 0.5751211631663974,
      "grad_norm": 7.074969291687012,
      "learning_rate": 4.042003231017771e-05,
      "loss": 0.6381,
      "step": 1780
    },
    {
      "epoch": 0.5783521809369951,
      "grad_norm": 4.140515327453613,
      "learning_rate": 4.036618201400108e-05,
      "loss": 0.5132,
      "step": 1790
    },
    {
      "epoch": 0.5815831987075929,
      "grad_norm": 5.131270885467529,
      "learning_rate": 4.031233171782445e-05,
      "loss": 0.7487,
      "step": 1800
    },
    {
      "epoch": 0.5848142164781907,
      "grad_norm": 7.172304630279541,
      "learning_rate": 4.025848142164782e-05,
      "loss": 0.7329,
      "step": 1810
    },
    {
      "epoch": 0.5880452342487884,
      "grad_norm": 4.882132530212402,
      "learning_rate": 4.020463112547119e-05,
      "loss": 0.5767,
      "step": 1820
    },
    {
      "epoch": 0.5912762520193862,
      "grad_norm": 4.9695210456848145,
      "learning_rate": 4.015078082929457e-05,
      "loss": 0.6158,
      "step": 1830
    },
    {
      "epoch": 0.5945072697899838,
      "grad_norm": 6.865639686584473,
      "learning_rate": 4.009693053311793e-05,
      "loss": 0.6365,
      "step": 1840
    },
    {
      "epoch": 0.5977382875605816,
      "grad_norm": 4.481626510620117,
      "learning_rate": 4.004308023694131e-05,
      "loss": 0.5522,
      "step": 1850
    },
    {
      "epoch": 0.6009693053311793,
      "grad_norm": 4.866164207458496,
      "learning_rate": 3.998922994076468e-05,
      "loss": 0.573,
      "step": 1860
    },
    {
      "epoch": 0.6042003231017771,
      "grad_norm": 6.905168533325195,
      "learning_rate": 3.993537964458805e-05,
      "loss": 0.5641,
      "step": 1870
    },
    {
      "epoch": 0.6074313408723748,
      "grad_norm": 6.353161811828613,
      "learning_rate": 3.988152934841142e-05,
      "loss": 0.7394,
      "step": 1880
    },
    {
      "epoch": 0.6106623586429726,
      "grad_norm": 8.775757789611816,
      "learning_rate": 3.982767905223479e-05,
      "loss": 0.5654,
      "step": 1890
    },
    {
      "epoch": 0.6138933764135702,
      "grad_norm": 5.429425239562988,
      "learning_rate": 3.9773828756058165e-05,
      "loss": 0.6692,
      "step": 1900
    },
    {
      "epoch": 0.617124394184168,
      "grad_norm": 6.828724384307861,
      "learning_rate": 3.971997845988153e-05,
      "loss": 0.591,
      "step": 1910
    },
    {
      "epoch": 0.6203554119547657,
      "grad_norm": 5.227725505828857,
      "learning_rate": 3.9666128163704905e-05,
      "loss": 0.5093,
      "step": 1920
    },
    {
      "epoch": 0.6235864297253635,
      "grad_norm": 6.3347930908203125,
      "learning_rate": 3.9612277867528275e-05,
      "loss": 0.7099,
      "step": 1930
    },
    {
      "epoch": 0.6268174474959612,
      "grad_norm": 6.772780418395996,
      "learning_rate": 3.955842757135164e-05,
      "loss": 0.5872,
      "step": 1940
    },
    {
      "epoch": 0.630048465266559,
      "grad_norm": 4.937075138092041,
      "learning_rate": 3.9504577275175016e-05,
      "loss": 0.5808,
      "step": 1950
    },
    {
      "epoch": 0.6332794830371568,
      "grad_norm": 5.4543867111206055,
      "learning_rate": 3.9450726978998386e-05,
      "loss": 0.6105,
      "step": 1960
    },
    {
      "epoch": 0.6365105008077544,
      "grad_norm": 6.319263458251953,
      "learning_rate": 3.9396876682821756e-05,
      "loss": 0.6641,
      "step": 1970
    },
    {
      "epoch": 0.6397415185783522,
      "grad_norm": 5.6656270027160645,
      "learning_rate": 3.9343026386645126e-05,
      "loss": 0.7074,
      "step": 1980
    },
    {
      "epoch": 0.6429725363489499,
      "grad_norm": 2.8928866386413574,
      "learning_rate": 3.9289176090468497e-05,
      "loss": 0.5834,
      "step": 1990
    },
    {
      "epoch": 0.6462035541195477,
      "grad_norm": 4.535325527191162,
      "learning_rate": 3.9235325794291874e-05,
      "loss": 0.5792,
      "step": 2000
    },
    {
      "epoch": 0.6494345718901454,
      "grad_norm": 4.546639442443848,
      "learning_rate": 3.918147549811524e-05,
      "loss": 0.5867,
      "step": 2010
    },
    {
      "epoch": 0.6526655896607432,
      "grad_norm": 7.3557634353637695,
      "learning_rate": 3.9127625201938614e-05,
      "loss": 0.5758,
      "step": 2020
    },
    {
      "epoch": 0.6558966074313409,
      "grad_norm": 4.156857490539551,
      "learning_rate": 3.9073774905761984e-05,
      "loss": 0.6916,
      "step": 2030
    },
    {
      "epoch": 0.6591276252019386,
      "grad_norm": 5.9208598136901855,
      "learning_rate": 3.9019924609585354e-05,
      "loss": 0.6137,
      "step": 2040
    },
    {
      "epoch": 0.6623586429725363,
      "grad_norm": 3.490133047103882,
      "learning_rate": 3.8966074313408725e-05,
      "loss": 0.5703,
      "step": 2050
    },
    {
      "epoch": 0.6655896607431341,
      "grad_norm": 2.3303005695343018,
      "learning_rate": 3.8912224017232095e-05,
      "loss": 0.5799,
      "step": 2060
    },
    {
      "epoch": 0.6688206785137318,
      "grad_norm": 5.55211877822876,
      "learning_rate": 3.885837372105547e-05,
      "loss": 0.5782,
      "step": 2070
    },
    {
      "epoch": 0.6720516962843296,
      "grad_norm": 5.311337947845459,
      "learning_rate": 3.880452342487884e-05,
      "loss": 0.692,
      "step": 2080
    },
    {
      "epoch": 0.6752827140549273,
      "grad_norm": 3.96500563621521,
      "learning_rate": 3.8750673128702205e-05,
      "loss": 0.512,
      "step": 2090
    },
    {
      "epoch": 0.678513731825525,
      "grad_norm": 5.835485935211182,
      "learning_rate": 3.869682283252558e-05,
      "loss": 0.5752,
      "step": 2100
    },
    {
      "epoch": 0.6817447495961227,
      "grad_norm": 5.8569159507751465,
      "learning_rate": 3.864297253634895e-05,
      "loss": 0.6707,
      "step": 2110
    },
    {
      "epoch": 0.6849757673667205,
      "grad_norm": 5.234961986541748,
      "learning_rate": 3.858912224017232e-05,
      "loss": 0.5535,
      "step": 2120
    },
    {
      "epoch": 0.6882067851373183,
      "grad_norm": 4.01052713394165,
      "learning_rate": 3.853527194399569e-05,
      "loss": 0.4793,
      "step": 2130
    },
    {
      "epoch": 0.691437802907916,
      "grad_norm": 4.227420806884766,
      "learning_rate": 3.848142164781906e-05,
      "loss": 0.572,
      "step": 2140
    },
    {
      "epoch": 0.6946688206785138,
      "grad_norm": 5.354206085205078,
      "learning_rate": 3.842757135164244e-05,
      "loss": 0.4994,
      "step": 2150
    },
    {
      "epoch": 0.6978998384491115,
      "grad_norm": 3.960420846939087,
      "learning_rate": 3.8373721055465803e-05,
      "loss": 0.6361,
      "step": 2160
    },
    {
      "epoch": 0.7011308562197092,
      "grad_norm": 4.85116720199585,
      "learning_rate": 3.831987075928918e-05,
      "loss": 0.628,
      "step": 2170
    },
    {
      "epoch": 0.7043618739903069,
      "grad_norm": 4.524918079376221,
      "learning_rate": 3.826602046311255e-05,
      "loss": 0.6749,
      "step": 2180
    },
    {
      "epoch": 0.7075928917609047,
      "grad_norm": 3.9776062965393066,
      "learning_rate": 3.821217016693592e-05,
      "loss": 0.5754,
      "step": 2190
    },
    {
      "epoch": 0.7108239095315024,
      "grad_norm": 4.142299175262451,
      "learning_rate": 3.815831987075929e-05,
      "loss": 0.644,
      "step": 2200
    },
    {
      "epoch": 0.7140549273021002,
      "grad_norm": 6.341064929962158,
      "learning_rate": 3.810446957458266e-05,
      "loss": 0.6085,
      "step": 2210
    },
    {
      "epoch": 0.7172859450726979,
      "grad_norm": 4.491867542266846,
      "learning_rate": 3.805061927840604e-05,
      "loss": 0.6565,
      "step": 2220
    },
    {
      "epoch": 0.7205169628432956,
      "grad_norm": 5.957065582275391,
      "learning_rate": 3.79967689822294e-05,
      "loss": 0.5588,
      "step": 2230
    },
    {
      "epoch": 0.7237479806138933,
      "grad_norm": 5.602373123168945,
      "learning_rate": 3.794291868605278e-05,
      "loss": 0.7917,
      "step": 2240
    },
    {
      "epoch": 0.7269789983844911,
      "grad_norm": 5.8564019203186035,
      "learning_rate": 3.788906838987615e-05,
      "loss": 0.7085,
      "step": 2250
    },
    {
      "epoch": 0.7302100161550888,
      "grad_norm": 5.674192905426025,
      "learning_rate": 3.783521809369951e-05,
      "loss": 0.6009,
      "step": 2260
    },
    {
      "epoch": 0.7334410339256866,
      "grad_norm": 3.295180320739746,
      "learning_rate": 3.778136779752289e-05,
      "loss": 0.5853,
      "step": 2270
    },
    {
      "epoch": 0.7366720516962844,
      "grad_norm": 4.710778713226318,
      "learning_rate": 3.772751750134626e-05,
      "loss": 0.7596,
      "step": 2280
    },
    {
      "epoch": 0.7399030694668821,
      "grad_norm": 4.2119975090026855,
      "learning_rate": 3.767366720516963e-05,
      "loss": 0.6248,
      "step": 2290
    },
    {
      "epoch": 0.7431340872374798,
      "grad_norm": 4.90091609954834,
      "learning_rate": 3.7619816908993e-05,
      "loss": 0.5493,
      "step": 2300
    },
    {
      "epoch": 0.7463651050080775,
      "grad_norm": 6.209066867828369,
      "learning_rate": 3.756596661281637e-05,
      "loss": 0.5727,
      "step": 2310
    },
    {
      "epoch": 0.7495961227786753,
      "grad_norm": 5.241613388061523,
      "learning_rate": 3.751211631663975e-05,
      "loss": 0.6093,
      "step": 2320
    },
    {
      "epoch": 0.752827140549273,
      "grad_norm": 6.120643138885498,
      "learning_rate": 3.745826602046311e-05,
      "loss": 0.6132,
      "step": 2330
    },
    {
      "epoch": 0.7560581583198708,
      "grad_norm": 5.706867218017578,
      "learning_rate": 3.740441572428649e-05,
      "loss": 0.703,
      "step": 2340
    },
    {
      "epoch": 0.7592891760904685,
      "grad_norm": 6.526123523712158,
      "learning_rate": 3.735056542810986e-05,
      "loss": 0.6932,
      "step": 2350
    },
    {
      "epoch": 0.7625201938610663,
      "grad_norm": 6.290457248687744,
      "learning_rate": 3.729671513193323e-05,
      "loss": 0.5864,
      "step": 2360
    },
    {
      "epoch": 0.7657512116316639,
      "grad_norm": 4.790426731109619,
      "learning_rate": 3.72428648357566e-05,
      "loss": 0.6349,
      "step": 2370
    },
    {
      "epoch": 0.7689822294022617,
      "grad_norm": 4.8561530113220215,
      "learning_rate": 3.718901453957997e-05,
      "loss": 0.6474,
      "step": 2380
    },
    {
      "epoch": 0.7722132471728594,
      "grad_norm": 3.3073103427886963,
      "learning_rate": 3.7135164243403345e-05,
      "loss": 0.5635,
      "step": 2390
    },
    {
      "epoch": 0.7754442649434572,
      "grad_norm": 7.05451774597168,
      "learning_rate": 3.708131394722671e-05,
      "loss": 0.6756,
      "step": 2400
    },
    {
      "epoch": 0.778675282714055,
      "grad_norm": 4.679426670074463,
      "learning_rate": 3.702746365105008e-05,
      "loss": 0.6411,
      "step": 2410
    },
    {
      "epoch": 0.7819063004846527,
      "grad_norm": 5.037328243255615,
      "learning_rate": 3.6973613354873456e-05,
      "loss": 0.5517,
      "step": 2420
    },
    {
      "epoch": 0.7851373182552503,
      "grad_norm": 6.090858459472656,
      "learning_rate": 3.6919763058696826e-05,
      "loss": 0.7058,
      "step": 2430
    },
    {
      "epoch": 0.7883683360258481,
      "grad_norm": 4.45987606048584,
      "learning_rate": 3.6865912762520196e-05,
      "loss": 0.6546,
      "step": 2440
    },
    {
      "epoch": 0.7915993537964459,
      "grad_norm": 6.142158031463623,
      "learning_rate": 3.6812062466343566e-05,
      "loss": 0.6281,
      "step": 2450
    },
    {
      "epoch": 0.7948303715670436,
      "grad_norm": 4.586140155792236,
      "learning_rate": 3.6758212170166936e-05,
      "loss": 0.6203,
      "step": 2460
    },
    {
      "epoch": 0.7980613893376414,
      "grad_norm": 5.9910359382629395,
      "learning_rate": 3.6704361873990307e-05,
      "loss": 0.6419,
      "step": 2470
    },
    {
      "epoch": 0.8012924071082391,
      "grad_norm": 4.049652099609375,
      "learning_rate": 3.665051157781368e-05,
      "loss": 0.6098,
      "step": 2480
    },
    {
      "epoch": 0.8045234248788369,
      "grad_norm": 5.350765705108643,
      "learning_rate": 3.6596661281637054e-05,
      "loss": 0.6434,
      "step": 2490
    },
    {
      "epoch": 0.8077544426494345,
      "grad_norm": 7.236899375915527,
      "learning_rate": 3.6542810985460424e-05,
      "loss": 0.634,
      "step": 2500
    },
    {
      "epoch": 0.8109854604200323,
      "grad_norm": 10.274799346923828,
      "learning_rate": 3.6488960689283794e-05,
      "loss": 0.5897,
      "step": 2510
    },
    {
      "epoch": 0.81421647819063,
      "grad_norm": 3.503377914428711,
      "learning_rate": 3.6435110393107164e-05,
      "loss": 0.6867,
      "step": 2520
    },
    {
      "epoch": 0.8174474959612278,
      "grad_norm": 5.228992462158203,
      "learning_rate": 3.6381260096930535e-05,
      "loss": 0.626,
      "step": 2530
    },
    {
      "epoch": 0.8206785137318255,
      "grad_norm": 5.3408122062683105,
      "learning_rate": 3.6327409800753905e-05,
      "loss": 0.674,
      "step": 2540
    },
    {
      "epoch": 0.8239095315024233,
      "grad_norm": 10.178389549255371,
      "learning_rate": 3.6273559504577275e-05,
      "loss": 0.6341,
      "step": 2550
    },
    {
      "epoch": 0.827140549273021,
      "grad_norm": 5.281156063079834,
      "learning_rate": 3.6219709208400645e-05,
      "loss": 0.5989,
      "step": 2560
    },
    {
      "epoch": 0.8303715670436187,
      "grad_norm": 5.0918498039245605,
      "learning_rate": 3.616585891222402e-05,
      "loss": 0.6509,
      "step": 2570
    },
    {
      "epoch": 0.8336025848142165,
      "grad_norm": 5.150624752044678,
      "learning_rate": 3.6112008616047385e-05,
      "loss": 0.5909,
      "step": 2580
    },
    {
      "epoch": 0.8368336025848142,
      "grad_norm": 5.081061363220215,
      "learning_rate": 3.605815831987076e-05,
      "loss": 0.6608,
      "step": 2590
    },
    {
      "epoch": 0.840064620355412,
      "grad_norm": 6.393115043640137,
      "learning_rate": 3.600430802369413e-05,
      "loss": 0.6049,
      "step": 2600
    },
    {
      "epoch": 0.8432956381260097,
      "grad_norm": 7.756272315979004,
      "learning_rate": 3.59504577275175e-05,
      "loss": 0.6503,
      "step": 2610
    },
    {
      "epoch": 0.8465266558966075,
      "grad_norm": 6.545628070831299,
      "learning_rate": 3.589660743134087e-05,
      "loss": 0.7844,
      "step": 2620
    },
    {
      "epoch": 0.8497576736672051,
      "grad_norm": 5.642961502075195,
      "learning_rate": 3.584275713516424e-05,
      "loss": 0.6596,
      "step": 2630
    },
    {
      "epoch": 0.8529886914378029,
      "grad_norm": 6.634324550628662,
      "learning_rate": 3.578890683898762e-05,
      "loss": 0.5691,
      "step": 2640
    },
    {
      "epoch": 0.8562197092084006,
      "grad_norm": 6.03825569152832,
      "learning_rate": 3.5735056542810984e-05,
      "loss": 0.6239,
      "step": 2650
    },
    {
      "epoch": 0.8594507269789984,
      "grad_norm": 6.267035007476807,
      "learning_rate": 3.568120624663436e-05,
      "loss": 0.6609,
      "step": 2660
    },
    {
      "epoch": 0.8626817447495961,
      "grad_norm": 7.355453014373779,
      "learning_rate": 3.562735595045773e-05,
      "loss": 0.5964,
      "step": 2670
    },
    {
      "epoch": 0.8659127625201939,
      "grad_norm": 9.460224151611328,
      "learning_rate": 3.55735056542811e-05,
      "loss": 0.4859,
      "step": 2680
    },
    {
      "epoch": 0.8691437802907916,
      "grad_norm": 5.180482387542725,
      "learning_rate": 3.551965535810447e-05,
      "loss": 0.6326,
      "step": 2690
    },
    {
      "epoch": 0.8723747980613893,
      "grad_norm": 5.863675594329834,
      "learning_rate": 3.546580506192784e-05,
      "loss": 0.6342,
      "step": 2700
    },
    {
      "epoch": 0.875605815831987,
      "grad_norm": 5.0313920974731445,
      "learning_rate": 3.541195476575122e-05,
      "loss": 0.4392,
      "step": 2710
    },
    {
      "epoch": 0.8788368336025848,
      "grad_norm": 4.685412406921387,
      "learning_rate": 3.535810446957458e-05,
      "loss": 0.5345,
      "step": 2720
    },
    {
      "epoch": 0.8820678513731826,
      "grad_norm": 2.9302079677581787,
      "learning_rate": 3.530425417339795e-05,
      "loss": 0.5607,
      "step": 2730
    },
    {
      "epoch": 0.8852988691437803,
      "grad_norm": 6.850212097167969,
      "learning_rate": 3.525040387722133e-05,
      "loss": 0.7556,
      "step": 2740
    },
    {
      "epoch": 0.8885298869143781,
      "grad_norm": 4.290643692016602,
      "learning_rate": 3.51965535810447e-05,
      "loss": 0.6181,
      "step": 2750
    },
    {
      "epoch": 0.8917609046849758,
      "grad_norm": 6.186358451843262,
      "learning_rate": 3.514270328486807e-05,
      "loss": 0.5754,
      "step": 2760
    },
    {
      "epoch": 0.8949919224555735,
      "grad_norm": 4.020362854003906,
      "learning_rate": 3.508885298869144e-05,
      "loss": 0.6146,
      "step": 2770
    },
    {
      "epoch": 0.8982229402261712,
      "grad_norm": 6.065805435180664,
      "learning_rate": 3.503500269251481e-05,
      "loss": 0.5745,
      "step": 2780
    },
    {
      "epoch": 0.901453957996769,
      "grad_norm": 3.5250918865203857,
      "learning_rate": 3.498115239633818e-05,
      "loss": 0.4773,
      "step": 2790
    },
    {
      "epoch": 0.9046849757673667,
      "grad_norm": 5.63525390625,
      "learning_rate": 3.492730210016155e-05,
      "loss": 0.5951,
      "step": 2800
    },
    {
      "epoch": 0.9079159935379645,
      "grad_norm": 6.02093505859375,
      "learning_rate": 3.487345180398493e-05,
      "loss": 0.5999,
      "step": 2810
    },
    {
      "epoch": 0.9111470113085622,
      "grad_norm": 4.406713962554932,
      "learning_rate": 3.48196015078083e-05,
      "loss": 0.5645,
      "step": 2820
    },
    {
      "epoch": 0.9143780290791599,
      "grad_norm": 4.587800979614258,
      "learning_rate": 3.476575121163167e-05,
      "loss": 0.5001,
      "step": 2830
    },
    {
      "epoch": 0.9176090468497576,
      "grad_norm": 5.142082691192627,
      "learning_rate": 3.471190091545504e-05,
      "loss": 0.6255,
      "step": 2840
    },
    {
      "epoch": 0.9208400646203554,
      "grad_norm": 5.29564905166626,
      "learning_rate": 3.465805061927841e-05,
      "loss": 0.6025,
      "step": 2850
    },
    {
      "epoch": 0.9240710823909531,
      "grad_norm": 7.106198310852051,
      "learning_rate": 3.460420032310178e-05,
      "loss": 0.6275,
      "step": 2860
    },
    {
      "epoch": 0.9273021001615509,
      "grad_norm": 4.0117034912109375,
      "learning_rate": 3.455035002692515e-05,
      "loss": 0.6194,
      "step": 2870
    },
    {
      "epoch": 0.9305331179321487,
      "grad_norm": 5.332397937774658,
      "learning_rate": 3.449649973074852e-05,
      "loss": 0.6134,
      "step": 2880
    },
    {
      "epoch": 0.9337641357027464,
      "grad_norm": 7.008533954620361,
      "learning_rate": 3.4442649434571895e-05,
      "loss": 0.6269,
      "step": 2890
    },
    {
      "epoch": 0.9369951534733441,
      "grad_norm": 5.8252973556518555,
      "learning_rate": 3.438879913839526e-05,
      "loss": 0.5496,
      "step": 2900
    },
    {
      "epoch": 0.9402261712439418,
      "grad_norm": 8.497054100036621,
      "learning_rate": 3.4334948842218636e-05,
      "loss": 0.615,
      "step": 2910
    },
    {
      "epoch": 0.9434571890145396,
      "grad_norm": 4.075296401977539,
      "learning_rate": 3.4281098546042006e-05,
      "loss": 0.552,
      "step": 2920
    },
    {
      "epoch": 0.9466882067851373,
      "grad_norm": 5.483770847320557,
      "learning_rate": 3.4227248249865376e-05,
      "loss": 0.6142,
      "step": 2930
    },
    {
      "epoch": 0.9499192245557351,
      "grad_norm": 5.94126558303833,
      "learning_rate": 3.4173397953688746e-05,
      "loss": 0.5607,
      "step": 2940
    },
    {
      "epoch": 0.9531502423263328,
      "grad_norm": 6.034850120544434,
      "learning_rate": 3.4119547657512117e-05,
      "loss": 0.597,
      "step": 2950
    },
    {
      "epoch": 0.9563812600969306,
      "grad_norm": 4.423614978790283,
      "learning_rate": 3.4065697361335494e-05,
      "loss": 0.5418,
      "step": 2960
    },
    {
      "epoch": 0.9596122778675282,
      "grad_norm": 4.744788646697998,
      "learning_rate": 3.401184706515886e-05,
      "loss": 0.6287,
      "step": 2970
    },
    {
      "epoch": 0.962843295638126,
      "grad_norm": 4.870917320251465,
      "learning_rate": 3.3957996768982234e-05,
      "loss": 0.5174,
      "step": 2980
    },
    {
      "epoch": 0.9660743134087237,
      "grad_norm": 6.054892063140869,
      "learning_rate": 3.3904146472805604e-05,
      "loss": 0.6527,
      "step": 2990
    },
    {
      "epoch": 0.9693053311793215,
      "grad_norm": 4.294091701507568,
      "learning_rate": 3.385029617662897e-05,
      "loss": 0.4925,
      "step": 3000
    },
    {
      "epoch": 0.9725363489499192,
      "grad_norm": 8.23051643371582,
      "learning_rate": 3.3796445880452344e-05,
      "loss": 0.7563,
      "step": 3010
    },
    {
      "epoch": 0.975767366720517,
      "grad_norm": 5.4221720695495605,
      "learning_rate": 3.3742595584275715e-05,
      "loss": 0.6469,
      "step": 3020
    },
    {
      "epoch": 0.9789983844911146,
      "grad_norm": 4.458278656005859,
      "learning_rate": 3.368874528809909e-05,
      "loss": 0.5703,
      "step": 3030
    },
    {
      "epoch": 0.9822294022617124,
      "grad_norm": 4.550007343292236,
      "learning_rate": 3.3634894991922455e-05,
      "loss": 0.6657,
      "step": 3040
    },
    {
      "epoch": 0.9854604200323102,
      "grad_norm": 4.883275985717773,
      "learning_rate": 3.3581044695745825e-05,
      "loss": 0.578,
      "step": 3050
    },
    {
      "epoch": 0.9886914378029079,
      "grad_norm": 3.981276035308838,
      "learning_rate": 3.35271943995692e-05,
      "loss": 0.6322,
      "step": 3060
    },
    {
      "epoch": 0.9919224555735057,
      "grad_norm": 5.139693260192871,
      "learning_rate": 3.3473344103392566e-05,
      "loss": 0.5806,
      "step": 3070
    },
    {
      "epoch": 0.9951534733441034,
      "grad_norm": 4.166479110717773,
      "learning_rate": 3.341949380721594e-05,
      "loss": 0.5571,
      "step": 3080
    },
    {
      "epoch": 0.9983844911147012,
      "grad_norm": 6.588808536529541,
      "learning_rate": 3.336564351103931e-05,
      "loss": 0.6154,
      "step": 3090
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.6360738277435303,
      "eval_runtime": 30.3438,
      "eval_samples_per_second": 22.673,
      "eval_steps_per_second": 11.337,
      "step": 3095
    },
    {
      "epoch": 1.001615508885299,
      "grad_norm": 3.594515085220337,
      "learning_rate": 3.331179321486268e-05,
      "loss": 0.4714,
      "step": 3100
    },
    {
      "epoch": 1.0048465266558966,
      "grad_norm": 4.198843955993652,
      "learning_rate": 3.325794291868605e-05,
      "loss": 0.3531,
      "step": 3110
    },
    {
      "epoch": 1.0080775444264944,
      "grad_norm": 5.137091636657715,
      "learning_rate": 3.3204092622509423e-05,
      "loss": 0.2973,
      "step": 3120
    },
    {
      "epoch": 1.011308562197092,
      "grad_norm": 4.512781143188477,
      "learning_rate": 3.31502423263328e-05,
      "loss": 0.308,
      "step": 3130
    },
    {
      "epoch": 1.0145395799676897,
      "grad_norm": 2.5433144569396973,
      "learning_rate": 3.3096392030156164e-05,
      "loss": 0.3532,
      "step": 3140
    },
    {
      "epoch": 1.0177705977382876,
      "grad_norm": 5.5038862228393555,
      "learning_rate": 3.3042541733979534e-05,
      "loss": 0.3958,
      "step": 3150
    },
    {
      "epoch": 1.0210016155088852,
      "grad_norm": 3.6983330249786377,
      "learning_rate": 3.298869143780291e-05,
      "loss": 0.3756,
      "step": 3160
    },
    {
      "epoch": 1.024232633279483,
      "grad_norm": 4.135544776916504,
      "learning_rate": 3.293484114162628e-05,
      "loss": 0.3046,
      "step": 3170
    },
    {
      "epoch": 1.0274636510500808,
      "grad_norm": 5.3857269287109375,
      "learning_rate": 3.288099084544965e-05,
      "loss": 0.3139,
      "step": 3180
    },
    {
      "epoch": 1.0306946688206786,
      "grad_norm": 4.683266639709473,
      "learning_rate": 3.282714054927302e-05,
      "loss": 0.2576,
      "step": 3190
    },
    {
      "epoch": 1.0339256865912763,
      "grad_norm": 3.641350030899048,
      "learning_rate": 3.277329025309639e-05,
      "loss": 0.375,
      "step": 3200
    },
    {
      "epoch": 1.037156704361874,
      "grad_norm": 5.188790321350098,
      "learning_rate": 3.271943995691977e-05,
      "loss": 0.3046,
      "step": 3210
    },
    {
      "epoch": 1.0403877221324718,
      "grad_norm": 4.120845794677734,
      "learning_rate": 3.266558966074313e-05,
      "loss": 0.3503,
      "step": 3220
    },
    {
      "epoch": 1.0436187399030694,
      "grad_norm": 4.220724582672119,
      "learning_rate": 3.261173936456651e-05,
      "loss": 0.3137,
      "step": 3230
    },
    {
      "epoch": 1.0468497576736673,
      "grad_norm": 4.033409118652344,
      "learning_rate": 3.255788906838988e-05,
      "loss": 0.385,
      "step": 3240
    },
    {
      "epoch": 1.050080775444265,
      "grad_norm": 3.704493761062622,
      "learning_rate": 3.250403877221325e-05,
      "loss": 0.339,
      "step": 3250
    },
    {
      "epoch": 1.0533117932148626,
      "grad_norm": 6.313892364501953,
      "learning_rate": 3.245018847603662e-05,
      "loss": 0.3241,
      "step": 3260
    },
    {
      "epoch": 1.0565428109854604,
      "grad_norm": 4.251166343688965,
      "learning_rate": 3.239633817985999e-05,
      "loss": 0.3437,
      "step": 3270
    },
    {
      "epoch": 1.059773828756058,
      "grad_norm": 4.65138053894043,
      "learning_rate": 3.234248788368337e-05,
      "loss": 0.315,
      "step": 3280
    },
    {
      "epoch": 1.063004846526656,
      "grad_norm": 6.053945064544678,
      "learning_rate": 3.228863758750673e-05,
      "loss": 0.3213,
      "step": 3290
    },
    {
      "epoch": 1.0662358642972536,
      "grad_norm": 5.3856964111328125,
      "learning_rate": 3.223478729133011e-05,
      "loss": 0.3188,
      "step": 3300
    },
    {
      "epoch": 1.0694668820678515,
      "grad_norm": 5.8341755867004395,
      "learning_rate": 3.218093699515348e-05,
      "loss": 0.3731,
      "step": 3310
    },
    {
      "epoch": 1.072697899838449,
      "grad_norm": 3.805866003036499,
      "learning_rate": 3.212708669897684e-05,
      "loss": 0.3253,
      "step": 3320
    },
    {
      "epoch": 1.0759289176090467,
      "grad_norm": 2.3160195350646973,
      "learning_rate": 3.207323640280022e-05,
      "loss": 0.3027,
      "step": 3330
    },
    {
      "epoch": 1.0791599353796446,
      "grad_norm": 4.3052778244018555,
      "learning_rate": 3.201938610662359e-05,
      "loss": 0.3183,
      "step": 3340
    },
    {
      "epoch": 1.0823909531502423,
      "grad_norm": 4.035207748413086,
      "learning_rate": 3.196553581044696e-05,
      "loss": 0.3641,
      "step": 3350
    },
    {
      "epoch": 1.0856219709208401,
      "grad_norm": 4.548916816711426,
      "learning_rate": 3.191168551427033e-05,
      "loss": 0.3792,
      "step": 3360
    },
    {
      "epoch": 1.0888529886914378,
      "grad_norm": 5.757932186126709,
      "learning_rate": 3.18578352180937e-05,
      "loss": 0.3869,
      "step": 3370
    },
    {
      "epoch": 1.0920840064620356,
      "grad_norm": 4.26397705078125,
      "learning_rate": 3.1803984921917076e-05,
      "loss": 0.3873,
      "step": 3380
    },
    {
      "epoch": 1.0953150242326333,
      "grad_norm": 6.166093349456787,
      "learning_rate": 3.175013462574044e-05,
      "loss": 0.3407,
      "step": 3390
    },
    {
      "epoch": 1.098546042003231,
      "grad_norm": 4.284563064575195,
      "learning_rate": 3.1696284329563816e-05,
      "loss": 0.4205,
      "step": 3400
    },
    {
      "epoch": 1.1017770597738288,
      "grad_norm": 3.6368446350097656,
      "learning_rate": 3.1642434033387186e-05,
      "loss": 0.419,
      "step": 3410
    },
    {
      "epoch": 1.1050080775444264,
      "grad_norm": 2.441457748413086,
      "learning_rate": 3.1588583737210556e-05,
      "loss": 0.3579,
      "step": 3420
    },
    {
      "epoch": 1.1082390953150243,
      "grad_norm": 5.471728801727295,
      "learning_rate": 3.1534733441033927e-05,
      "loss": 0.4267,
      "step": 3430
    },
    {
      "epoch": 1.111470113085622,
      "grad_norm": 3.5359854698181152,
      "learning_rate": 3.14808831448573e-05,
      "loss": 0.2778,
      "step": 3440
    },
    {
      "epoch": 1.1147011308562198,
      "grad_norm": 3.6293880939483643,
      "learning_rate": 3.1427032848680674e-05,
      "loss": 0.3255,
      "step": 3450
    },
    {
      "epoch": 1.1179321486268174,
      "grad_norm": 4.745990753173828,
      "learning_rate": 3.137318255250404e-05,
      "loss": 0.319,
      "step": 3460
    },
    {
      "epoch": 1.121163166397415,
      "grad_norm": 5.2099690437316895,
      "learning_rate": 3.131933225632741e-05,
      "loss": 0.3721,
      "step": 3470
    },
    {
      "epoch": 1.124394184168013,
      "grad_norm": 3.832227945327759,
      "learning_rate": 3.1265481960150784e-05,
      "loss": 0.43,
      "step": 3480
    },
    {
      "epoch": 1.1276252019386106,
      "grad_norm": 4.963252544403076,
      "learning_rate": 3.1211631663974154e-05,
      "loss": 0.3834,
      "step": 3490
    },
    {
      "epoch": 1.1308562197092085,
      "grad_norm": 7.63633394241333,
      "learning_rate": 3.1157781367797525e-05,
      "loss": 0.3506,
      "step": 3500
    },
    {
      "epoch": 1.134087237479806,
      "grad_norm": 3.952023983001709,
      "learning_rate": 3.1103931071620895e-05,
      "loss": 0.4452,
      "step": 3510
    },
    {
      "epoch": 1.137318255250404,
      "grad_norm": 5.475167751312256,
      "learning_rate": 3.1050080775444265e-05,
      "loss": 0.3116,
      "step": 3520
    },
    {
      "epoch": 1.1405492730210016,
      "grad_norm": 4.308335304260254,
      "learning_rate": 3.0996230479267635e-05,
      "loss": 0.2963,
      "step": 3530
    },
    {
      "epoch": 1.1437802907915993,
      "grad_norm": 7.241868495941162,
      "learning_rate": 3.0942380183091005e-05,
      "loss": 0.3455,
      "step": 3540
    },
    {
      "epoch": 1.1470113085621971,
      "grad_norm": 4.764508247375488,
      "learning_rate": 3.088852988691438e-05,
      "loss": 0.3306,
      "step": 3550
    },
    {
      "epoch": 1.1502423263327948,
      "grad_norm": 7.255648136138916,
      "learning_rate": 3.083467959073775e-05,
      "loss": 0.3652,
      "step": 3560
    },
    {
      "epoch": 1.1534733441033926,
      "grad_norm": 5.119240760803223,
      "learning_rate": 3.078082929456112e-05,
      "loss": 0.394,
      "step": 3570
    },
    {
      "epoch": 1.1567043618739903,
      "grad_norm": 4.270582675933838,
      "learning_rate": 3.072697899838449e-05,
      "loss": 0.2693,
      "step": 3580
    },
    {
      "epoch": 1.1599353796445881,
      "grad_norm": 3.8560256958007812,
      "learning_rate": 3.067312870220786e-05,
      "loss": 0.3386,
      "step": 3590
    },
    {
      "epoch": 1.1631663974151858,
      "grad_norm": 6.757261753082275,
      "learning_rate": 3.061927840603123e-05,
      "loss": 0.3862,
      "step": 3600
    },
    {
      "epoch": 1.1663974151857834,
      "grad_norm": 6.008406639099121,
      "learning_rate": 3.0565428109854604e-05,
      "loss": 0.328,
      "step": 3610
    },
    {
      "epoch": 1.1696284329563813,
      "grad_norm": 4.8051323890686035,
      "learning_rate": 3.0511577813677977e-05,
      "loss": 0.3435,
      "step": 3620
    },
    {
      "epoch": 1.172859450726979,
      "grad_norm": 6.198620796203613,
      "learning_rate": 3.045772751750135e-05,
      "loss": 0.3104,
      "step": 3630
    },
    {
      "epoch": 1.1760904684975768,
      "grad_norm": 3.5069892406463623,
      "learning_rate": 3.0403877221324718e-05,
      "loss": 0.3051,
      "step": 3640
    },
    {
      "epoch": 1.1793214862681745,
      "grad_norm": 5.443741798400879,
      "learning_rate": 3.035002692514809e-05,
      "loss": 0.3783,
      "step": 3650
    },
    {
      "epoch": 1.1825525040387723,
      "grad_norm": 4.125328540802002,
      "learning_rate": 3.029617662897146e-05,
      "loss": 0.3138,
      "step": 3660
    },
    {
      "epoch": 1.18578352180937,
      "grad_norm": 4.3997368812561035,
      "learning_rate": 3.0242326332794828e-05,
      "loss": 0.3137,
      "step": 3670
    },
    {
      "epoch": 1.1890145395799676,
      "grad_norm": 6.396403789520264,
      "learning_rate": 3.01884760366182e-05,
      "loss": 0.3403,
      "step": 3680
    },
    {
      "epoch": 1.1922455573505655,
      "grad_norm": 4.659742832183838,
      "learning_rate": 3.0134625740441575e-05,
      "loss": 0.3803,
      "step": 3690
    },
    {
      "epoch": 1.1954765751211631,
      "grad_norm": 4.189445495605469,
      "learning_rate": 3.0080775444264945e-05,
      "loss": 0.3153,
      "step": 3700
    },
    {
      "epoch": 1.198707592891761,
      "grad_norm": 6.5922675132751465,
      "learning_rate": 3.0026925148088316e-05,
      "loss": 0.3206,
      "step": 3710
    },
    {
      "epoch": 1.2019386106623586,
      "grad_norm": 3.1965019702911377,
      "learning_rate": 2.9973074851911686e-05,
      "loss": 0.3204,
      "step": 3720
    },
    {
      "epoch": 1.2051696284329565,
      "grad_norm": 4.365371227264404,
      "learning_rate": 2.991922455573506e-05,
      "loss": 0.2942,
      "step": 3730
    },
    {
      "epoch": 1.2084006462035541,
      "grad_norm": 3.540346622467041,
      "learning_rate": 2.9865374259558426e-05,
      "loss": 0.3126,
      "step": 3740
    },
    {
      "epoch": 1.2116316639741518,
      "grad_norm": 4.955575942993164,
      "learning_rate": 2.98115239633818e-05,
      "loss": 0.3426,
      "step": 3750
    },
    {
      "epoch": 1.2148626817447497,
      "grad_norm": 4.418692588806152,
      "learning_rate": 2.975767366720517e-05,
      "loss": 0.3044,
      "step": 3760
    },
    {
      "epoch": 1.2180936995153473,
      "grad_norm": 4.3208537101745605,
      "learning_rate": 2.9703823371028544e-05,
      "loss": 0.3064,
      "step": 3770
    },
    {
      "epoch": 1.2213247172859452,
      "grad_norm": 3.550570487976074,
      "learning_rate": 2.964997307485191e-05,
      "loss": 0.292,
      "step": 3780
    },
    {
      "epoch": 1.2245557350565428,
      "grad_norm": 4.0210347175598145,
      "learning_rate": 2.9596122778675284e-05,
      "loss": 0.3043,
      "step": 3790
    },
    {
      "epoch": 1.2277867528271407,
      "grad_norm": 3.7278873920440674,
      "learning_rate": 2.9542272482498658e-05,
      "loss": 0.2741,
      "step": 3800
    },
    {
      "epoch": 1.2310177705977383,
      "grad_norm": 4.785367965698242,
      "learning_rate": 2.9488422186322028e-05,
      "loss": 0.392,
      "step": 3810
    },
    {
      "epoch": 1.234248788368336,
      "grad_norm": 7.646238803863525,
      "learning_rate": 2.9434571890145395e-05,
      "loss": 0.3336,
      "step": 3820
    },
    {
      "epoch": 1.2374798061389338,
      "grad_norm": 4.981622695922852,
      "learning_rate": 2.9380721593968768e-05,
      "loss": 0.4007,
      "step": 3830
    },
    {
      "epoch": 1.2407108239095315,
      "grad_norm": 4.254907131195068,
      "learning_rate": 2.9326871297792142e-05,
      "loss": 0.3475,
      "step": 3840
    },
    {
      "epoch": 1.2439418416801293,
      "grad_norm": 3.963886260986328,
      "learning_rate": 2.927302100161551e-05,
      "loss": 0.2982,
      "step": 3850
    },
    {
      "epoch": 1.247172859450727,
      "grad_norm": 5.706756591796875,
      "learning_rate": 2.9219170705438882e-05,
      "loss": 0.2977,
      "step": 3860
    },
    {
      "epoch": 1.2504038772213248,
      "grad_norm": 3.966737985610962,
      "learning_rate": 2.9165320409262252e-05,
      "loss": 0.3458,
      "step": 3870
    },
    {
      "epoch": 1.2536348949919225,
      "grad_norm": 10.88615894317627,
      "learning_rate": 2.9111470113085626e-05,
      "loss": 0.2751,
      "step": 3880
    },
    {
      "epoch": 1.2568659127625201,
      "grad_norm": 6.860701084136963,
      "learning_rate": 2.9057619816908993e-05,
      "loss": 0.4163,
      "step": 3890
    },
    {
      "epoch": 1.260096930533118,
      "grad_norm": 6.500321388244629,
      "learning_rate": 2.9003769520732366e-05,
      "loss": 0.3258,
      "step": 3900
    },
    {
      "epoch": 1.2633279483037156,
      "grad_norm": 4.732964992523193,
      "learning_rate": 2.894991922455574e-05,
      "loss": 0.318,
      "step": 3910
    },
    {
      "epoch": 1.2665589660743133,
      "grad_norm": 5.437005996704102,
      "learning_rate": 2.8896068928379107e-05,
      "loss": 0.3278,
      "step": 3920
    },
    {
      "epoch": 1.2697899838449112,
      "grad_norm": 3.3288958072662354,
      "learning_rate": 2.8842218632202477e-05,
      "loss": 0.3257,
      "step": 3930
    },
    {
      "epoch": 1.273021001615509,
      "grad_norm": 3.210108518600464,
      "learning_rate": 2.878836833602585e-05,
      "loss": 0.457,
      "step": 3940
    },
    {
      "epoch": 1.2762520193861067,
      "grad_norm": 4.2764739990234375,
      "learning_rate": 2.8734518039849224e-05,
      "loss": 0.3964,
      "step": 3950
    },
    {
      "epoch": 1.2794830371567043,
      "grad_norm": 2.8560404777526855,
      "learning_rate": 2.868066774367259e-05,
      "loss": 0.3713,
      "step": 3960
    },
    {
      "epoch": 1.2827140549273022,
      "grad_norm": 3.716827869415283,
      "learning_rate": 2.862681744749596e-05,
      "loss": 0.339,
      "step": 3970
    },
    {
      "epoch": 1.2859450726978998,
      "grad_norm": 5.4364333152771,
      "learning_rate": 2.8572967151319335e-05,
      "loss": 0.3337,
      "step": 3980
    },
    {
      "epoch": 1.2891760904684975,
      "grad_norm": 4.182095527648926,
      "learning_rate": 2.85191168551427e-05,
      "loss": 0.3289,
      "step": 3990
    },
    {
      "epoch": 1.2924071082390953,
      "grad_norm": 4.007205486297607,
      "learning_rate": 2.8465266558966075e-05,
      "loss": 0.3629,
      "step": 4000
    },
    {
      "epoch": 1.2956381260096932,
      "grad_norm": 4.727148056030273,
      "learning_rate": 2.841141626278945e-05,
      "loss": 0.4925,
      "step": 4010
    },
    {
      "epoch": 1.2988691437802908,
      "grad_norm": 4.228445053100586,
      "learning_rate": 2.835756596661282e-05,
      "loss": 0.3795,
      "step": 4020
    },
    {
      "epoch": 1.3021001615508885,
      "grad_norm": 3.7812774181365967,
      "learning_rate": 2.8303715670436186e-05,
      "loss": 0.3291,
      "step": 4030
    },
    {
      "epoch": 1.3053311793214863,
      "grad_norm": 5.208916664123535,
      "learning_rate": 2.824986537425956e-05,
      "loss": 0.3702,
      "step": 4040
    },
    {
      "epoch": 1.308562197092084,
      "grad_norm": 3.0600380897521973,
      "learning_rate": 2.8196015078082933e-05,
      "loss": 0.2951,
      "step": 4050
    },
    {
      "epoch": 1.3117932148626816,
      "grad_norm": 7.556265354156494,
      "learning_rate": 2.81421647819063e-05,
      "loss": 0.3951,
      "step": 4060
    },
    {
      "epoch": 1.3150242326332795,
      "grad_norm": 4.418763160705566,
      "learning_rate": 2.8088314485729673e-05,
      "loss": 0.4857,
      "step": 4070
    },
    {
      "epoch": 1.3182552504038771,
      "grad_norm": 4.247167587280273,
      "learning_rate": 2.8034464189553043e-05,
      "loss": 0.2848,
      "step": 4080
    },
    {
      "epoch": 1.321486268174475,
      "grad_norm": 5.758114814758301,
      "learning_rate": 2.7980613893376417e-05,
      "loss": 0.4632,
      "step": 4090
    },
    {
      "epoch": 1.3247172859450727,
      "grad_norm": 7.184207916259766,
      "learning_rate": 2.7926763597199784e-05,
      "loss": 0.4283,
      "step": 4100
    },
    {
      "epoch": 1.3279483037156705,
      "grad_norm": 4.316873073577881,
      "learning_rate": 2.7872913301023157e-05,
      "loss": 0.3748,
      "step": 4110
    },
    {
      "epoch": 1.3311793214862682,
      "grad_norm": 5.543394565582275,
      "learning_rate": 2.781906300484653e-05,
      "loss": 0.2979,
      "step": 4120
    },
    {
      "epoch": 1.3344103392568658,
      "grad_norm": 4.685208320617676,
      "learning_rate": 2.7765212708669898e-05,
      "loss": 0.3443,
      "step": 4130
    },
    {
      "epoch": 1.3376413570274637,
      "grad_norm": 4.699176788330078,
      "learning_rate": 2.7711362412493268e-05,
      "loss": 0.4024,
      "step": 4140
    },
    {
      "epoch": 1.3408723747980613,
      "grad_norm": 9.837064743041992,
      "learning_rate": 2.765751211631664e-05,
      "loss": 0.3929,
      "step": 4150
    },
    {
      "epoch": 1.3441033925686592,
      "grad_norm": 4.751153945922852,
      "learning_rate": 2.7603661820140015e-05,
      "loss": 0.3141,
      "step": 4160
    },
    {
      "epoch": 1.3473344103392568,
      "grad_norm": 4.085095405578613,
      "learning_rate": 2.7549811523963382e-05,
      "loss": 0.3504,
      "step": 4170
    },
    {
      "epoch": 1.3505654281098547,
      "grad_norm": 5.8654303550720215,
      "learning_rate": 2.7495961227786755e-05,
      "loss": 0.3798,
      "step": 4180
    },
    {
      "epoch": 1.3537964458804523,
      "grad_norm": 5.570512771606445,
      "learning_rate": 2.7442110931610126e-05,
      "loss": 0.3841,
      "step": 4190
    },
    {
      "epoch": 1.35702746365105,
      "grad_norm": 3.6244332790374756,
      "learning_rate": 2.7388260635433492e-05,
      "loss": 0.3037,
      "step": 4200
    },
    {
      "epoch": 1.3602584814216478,
      "grad_norm": 3.32893443107605,
      "learning_rate": 2.7334410339256866e-05,
      "loss": 0.3294,
      "step": 4210
    },
    {
      "epoch": 1.3634894991922455,
      "grad_norm": 4.914620876312256,
      "learning_rate": 2.728056004308024e-05,
      "loss": 0.3919,
      "step": 4220
    },
    {
      "epoch": 1.3667205169628434,
      "grad_norm": 4.704594135284424,
      "learning_rate": 2.722670974690361e-05,
      "loss": 0.3701,
      "step": 4230
    },
    {
      "epoch": 1.369951534733441,
      "grad_norm": 5.118253707885742,
      "learning_rate": 2.717285945072698e-05,
      "loss": 0.3397,
      "step": 4240
    },
    {
      "epoch": 1.3731825525040389,
      "grad_norm": 3.3292644023895264,
      "learning_rate": 2.711900915455035e-05,
      "loss": 0.3691,
      "step": 4250
    },
    {
      "epoch": 1.3764135702746365,
      "grad_norm": 5.544024467468262,
      "learning_rate": 2.7065158858373724e-05,
      "loss": 0.4036,
      "step": 4260
    },
    {
      "epoch": 1.3796445880452342,
      "grad_norm": 3.642896890640259,
      "learning_rate": 2.701130856219709e-05,
      "loss": 0.2863,
      "step": 4270
    },
    {
      "epoch": 1.382875605815832,
      "grad_norm": 4.3086652755737305,
      "learning_rate": 2.6957458266020464e-05,
      "loss": 0.3268,
      "step": 4280
    },
    {
      "epoch": 1.3861066235864297,
      "grad_norm": 4.350589275360107,
      "learning_rate": 2.6903607969843834e-05,
      "loss": 0.2926,
      "step": 4290
    },
    {
      "epoch": 1.3893376413570275,
      "grad_norm": 7.5202178955078125,
      "learning_rate": 2.6849757673667208e-05,
      "loss": 0.311,
      "step": 4300
    },
    {
      "epoch": 1.3925686591276252,
      "grad_norm": 6.6687164306640625,
      "learning_rate": 2.6795907377490575e-05,
      "loss": 0.3555,
      "step": 4310
    },
    {
      "epoch": 1.395799676898223,
      "grad_norm": 5.025568008422852,
      "learning_rate": 2.674205708131395e-05,
      "loss": 0.3346,
      "step": 4320
    },
    {
      "epoch": 1.3990306946688207,
      "grad_norm": 6.058773994445801,
      "learning_rate": 2.6688206785137322e-05,
      "loss": 0.4404,
      "step": 4330
    },
    {
      "epoch": 1.4022617124394183,
      "grad_norm": 3.735057830810547,
      "learning_rate": 2.663435648896069e-05,
      "loss": 0.2553,
      "step": 4340
    },
    {
      "epoch": 1.4054927302100162,
      "grad_norm": 3.743479013442993,
      "learning_rate": 2.658050619278406e-05,
      "loss": 0.3786,
      "step": 4350
    },
    {
      "epoch": 1.4087237479806138,
      "grad_norm": 5.286190509796143,
      "learning_rate": 2.6526655896607432e-05,
      "loss": 0.3191,
      "step": 4360
    },
    {
      "epoch": 1.4119547657512117,
      "grad_norm": 4.3563947677612305,
      "learning_rate": 2.6472805600430806e-05,
      "loss": 0.3507,
      "step": 4370
    },
    {
      "epoch": 1.4151857835218093,
      "grad_norm": 10.20096206665039,
      "learning_rate": 2.6418955304254173e-05,
      "loss": 0.3812,
      "step": 4380
    },
    {
      "epoch": 1.4184168012924072,
      "grad_norm": 3.746702194213867,
      "learning_rate": 2.6365105008077546e-05,
      "loss": 0.3247,
      "step": 4390
    },
    {
      "epoch": 1.4216478190630049,
      "grad_norm": 4.73356819152832,
      "learning_rate": 2.6311254711900917e-05,
      "loss": 0.3277,
      "step": 4400
    },
    {
      "epoch": 1.4248788368336025,
      "grad_norm": 2.9033610820770264,
      "learning_rate": 2.625740441572429e-05,
      "loss": 0.3448,
      "step": 4410
    },
    {
      "epoch": 1.4281098546042004,
      "grad_norm": 9.341527938842773,
      "learning_rate": 2.6203554119547657e-05,
      "loss": 0.3773,
      "step": 4420
    },
    {
      "epoch": 1.431340872374798,
      "grad_norm": 3.336911678314209,
      "learning_rate": 2.614970382337103e-05,
      "loss": 0.3253,
      "step": 4430
    },
    {
      "epoch": 1.4345718901453959,
      "grad_norm": 4.073915004730225,
      "learning_rate": 2.6095853527194404e-05,
      "loss": 0.4024,
      "step": 4440
    },
    {
      "epoch": 1.4378029079159935,
      "grad_norm": 4.953529357910156,
      "learning_rate": 2.604200323101777e-05,
      "loss": 0.3577,
      "step": 4450
    },
    {
      "epoch": 1.4410339256865914,
      "grad_norm": 5.524261951446533,
      "learning_rate": 2.598815293484114e-05,
      "loss": 0.3476,
      "step": 4460
    },
    {
      "epoch": 1.444264943457189,
      "grad_norm": 3.6130995750427246,
      "learning_rate": 2.5934302638664515e-05,
      "loss": 0.3951,
      "step": 4470
    },
    {
      "epoch": 1.4474959612277867,
      "grad_norm": 3.9251961708068848,
      "learning_rate": 2.588045234248789e-05,
      "loss": 0.3543,
      "step": 4480
    },
    {
      "epoch": 1.4507269789983845,
      "grad_norm": 4.848758220672607,
      "learning_rate": 2.5826602046311255e-05,
      "loss": 0.3614,
      "step": 4490
    },
    {
      "epoch": 1.4539579967689822,
      "grad_norm": 5.89107084274292,
      "learning_rate": 2.577275175013463e-05,
      "loss": 0.4334,
      "step": 4500
    },
    {
      "epoch": 1.4571890145395798,
      "grad_norm": 2.99661922454834,
      "learning_rate": 2.5718901453958e-05,
      "loss": 0.2733,
      "step": 4510
    },
    {
      "epoch": 1.4604200323101777,
      "grad_norm": 10.322159767150879,
      "learning_rate": 2.5665051157781366e-05,
      "loss": 0.3285,
      "step": 4520
    },
    {
      "epoch": 1.4636510500807756,
      "grad_norm": 7.67434549331665,
      "learning_rate": 2.561120086160474e-05,
      "loss": 0.3769,
      "step": 4530
    },
    {
      "epoch": 1.4668820678513732,
      "grad_norm": 4.524430751800537,
      "learning_rate": 2.5557350565428113e-05,
      "loss": 0.2905,
      "step": 4540
    },
    {
      "epoch": 1.4701130856219708,
      "grad_norm": 4.926537990570068,
      "learning_rate": 2.5503500269251483e-05,
      "loss": 0.3925,
      "step": 4550
    },
    {
      "epoch": 1.4733441033925687,
      "grad_norm": 4.525279521942139,
      "learning_rate": 2.5449649973074853e-05,
      "loss": 0.338,
      "step": 4560
    },
    {
      "epoch": 1.4765751211631664,
      "grad_norm": 4.1748738288879395,
      "learning_rate": 2.5395799676898223e-05,
      "loss": 0.288,
      "step": 4570
    },
    {
      "epoch": 1.479806138933764,
      "grad_norm": 2.8475985527038574,
      "learning_rate": 2.5341949380721597e-05,
      "loss": 0.3167,
      "step": 4580
    },
    {
      "epoch": 1.4830371567043619,
      "grad_norm": 2.856743574142456,
      "learning_rate": 2.5288099084544964e-05,
      "loss": 0.3191,
      "step": 4590
    },
    {
      "epoch": 1.4862681744749597,
      "grad_norm": 3.6782619953155518,
      "learning_rate": 2.5234248788368337e-05,
      "loss": 0.3153,
      "step": 4600
    },
    {
      "epoch": 1.4894991922455574,
      "grad_norm": 4.431684494018555,
      "learning_rate": 2.5180398492191708e-05,
      "loss": 0.3671,
      "step": 4610
    },
    {
      "epoch": 1.492730210016155,
      "grad_norm": 4.087255954742432,
      "learning_rate": 2.512654819601508e-05,
      "loss": 0.4334,
      "step": 4620
    },
    {
      "epoch": 1.495961227786753,
      "grad_norm": 4.250303268432617,
      "learning_rate": 2.5072697899838448e-05,
      "loss": 0.3421,
      "step": 4630
    },
    {
      "epoch": 1.4991922455573505,
      "grad_norm": 5.576714992523193,
      "learning_rate": 2.501884760366182e-05,
      "loss": 0.286,
      "step": 4640
    },
    {
      "epoch": 1.5024232633279482,
      "grad_norm": 6.3796186447143555,
      "learning_rate": 2.4964997307485192e-05,
      "loss": 0.3646,
      "step": 4650
    },
    {
      "epoch": 1.505654281098546,
      "grad_norm": 4.855607986450195,
      "learning_rate": 2.4911147011308565e-05,
      "loss": 0.2881,
      "step": 4660
    },
    {
      "epoch": 1.508885298869144,
      "grad_norm": 4.737467288970947,
      "learning_rate": 2.4857296715131932e-05,
      "loss": 0.3262,
      "step": 4670
    },
    {
      "epoch": 1.5121163166397416,
      "grad_norm": 4.6217522621154785,
      "learning_rate": 2.4803446418955306e-05,
      "loss": 0.3419,
      "step": 4680
    },
    {
      "epoch": 1.5153473344103392,
      "grad_norm": 4.233343124389648,
      "learning_rate": 2.4749596122778676e-05,
      "loss": 0.3159,
      "step": 4690
    },
    {
      "epoch": 1.518578352180937,
      "grad_norm": 4.948814868927002,
      "learning_rate": 2.469574582660205e-05,
      "loss": 0.4813,
      "step": 4700
    },
    {
      "epoch": 1.5218093699515347,
      "grad_norm": 5.0148844718933105,
      "learning_rate": 2.464189553042542e-05,
      "loss": 0.3497,
      "step": 4710
    },
    {
      "epoch": 1.5250403877221324,
      "grad_norm": 4.243407726287842,
      "learning_rate": 2.4588045234248787e-05,
      "loss": 0.3249,
      "step": 4720
    },
    {
      "epoch": 1.5282714054927302,
      "grad_norm": 6.010425567626953,
      "learning_rate": 2.453419493807216e-05,
      "loss": 0.4398,
      "step": 4730
    },
    {
      "epoch": 1.531502423263328,
      "grad_norm": 4.584954261779785,
      "learning_rate": 2.448034464189553e-05,
      "loss": 0.4173,
      "step": 4740
    },
    {
      "epoch": 1.5347334410339257,
      "grad_norm": 3.980572462081909,
      "learning_rate": 2.4426494345718904e-05,
      "loss": 0.3365,
      "step": 4750
    },
    {
      "epoch": 1.5379644588045234,
      "grad_norm": 2.865311861038208,
      "learning_rate": 2.4372644049542274e-05,
      "loss": 0.2865,
      "step": 4760
    },
    {
      "epoch": 1.5411954765751212,
      "grad_norm": 3.4792792797088623,
      "learning_rate": 2.4318793753365644e-05,
      "loss": 0.3154,
      "step": 4770
    },
    {
      "epoch": 1.5444264943457189,
      "grad_norm": 3.7823071479797363,
      "learning_rate": 2.4264943457189015e-05,
      "loss": 0.287,
      "step": 4780
    },
    {
      "epoch": 1.5476575121163165,
      "grad_norm": 8.227283477783203,
      "learning_rate": 2.4211093161012388e-05,
      "loss": 0.3827,
      "step": 4790
    },
    {
      "epoch": 1.5508885298869144,
      "grad_norm": 3.8182692527770996,
      "learning_rate": 2.4157242864835758e-05,
      "loss": 0.2954,
      "step": 4800
    },
    {
      "epoch": 1.5541195476575123,
      "grad_norm": 10.49171257019043,
      "learning_rate": 2.410339256865913e-05,
      "loss": 0.3428,
      "step": 4810
    },
    {
      "epoch": 1.55735056542811,
      "grad_norm": 7.731858253479004,
      "learning_rate": 2.40495422724825e-05,
      "loss": 0.2393,
      "step": 4820
    },
    {
      "epoch": 1.5605815831987075,
      "grad_norm": 6.525121212005615,
      "learning_rate": 2.399569197630587e-05,
      "loss": 0.3765,
      "step": 4830
    },
    {
      "epoch": 1.5638126009693054,
      "grad_norm": 2.529740333557129,
      "learning_rate": 2.3941841680129242e-05,
      "loss": 0.3489,
      "step": 4840
    },
    {
      "epoch": 1.567043618739903,
      "grad_norm": 4.2833404541015625,
      "learning_rate": 2.3887991383952613e-05,
      "loss": 0.3468,
      "step": 4850
    },
    {
      "epoch": 1.5702746365105007,
      "grad_norm": 4.328820705413818,
      "learning_rate": 2.3834141087775986e-05,
      "loss": 0.3913,
      "step": 4860
    },
    {
      "epoch": 1.5735056542810986,
      "grad_norm": 2.267984628677368,
      "learning_rate": 2.3780290791599356e-05,
      "loss": 0.3383,
      "step": 4870
    },
    {
      "epoch": 1.5767366720516964,
      "grad_norm": 4.3401713371276855,
      "learning_rate": 2.3726440495422723e-05,
      "loss": 0.2686,
      "step": 4880
    },
    {
      "epoch": 1.579967689822294,
      "grad_norm": 3.935333251953125,
      "learning_rate": 2.3672590199246097e-05,
      "loss": 0.3664,
      "step": 4890
    },
    {
      "epoch": 1.5831987075928917,
      "grad_norm": 3.9327220916748047,
      "learning_rate": 2.3618739903069467e-05,
      "loss": 0.3292,
      "step": 4900
    },
    {
      "epoch": 1.5864297253634896,
      "grad_norm": 3.535565137863159,
      "learning_rate": 2.356488960689284e-05,
      "loss": 0.4443,
      "step": 4910
    },
    {
      "epoch": 1.5896607431340872,
      "grad_norm": 3.5554585456848145,
      "learning_rate": 2.351103931071621e-05,
      "loss": 0.3769,
      "step": 4920
    },
    {
      "epoch": 1.5928917609046849,
      "grad_norm": 3.7203187942504883,
      "learning_rate": 2.345718901453958e-05,
      "loss": 0.307,
      "step": 4930
    },
    {
      "epoch": 1.5961227786752827,
      "grad_norm": 3.4395334720611572,
      "learning_rate": 2.340333871836295e-05,
      "loss": 0.3546,
      "step": 4940
    },
    {
      "epoch": 1.5993537964458806,
      "grad_norm": 4.16448974609375,
      "learning_rate": 2.334948842218632e-05,
      "loss": 0.3693,
      "step": 4950
    },
    {
      "epoch": 1.602584814216478,
      "grad_norm": 4.768030166625977,
      "learning_rate": 2.3295638126009695e-05,
      "loss": 0.3614,
      "step": 4960
    },
    {
      "epoch": 1.605815831987076,
      "grad_norm": 4.501328468322754,
      "learning_rate": 2.3241787829833065e-05,
      "loss": 0.3534,
      "step": 4970
    },
    {
      "epoch": 1.6090468497576738,
      "grad_norm": 6.861719608306885,
      "learning_rate": 2.3187937533656435e-05,
      "loss": 0.3812,
      "step": 4980
    },
    {
      "epoch": 1.6122778675282714,
      "grad_norm": 5.65146017074585,
      "learning_rate": 2.3134087237479806e-05,
      "loss": 0.433,
      "step": 4990
    },
    {
      "epoch": 1.615508885298869,
      "grad_norm": 3.9977164268493652,
      "learning_rate": 2.308023694130318e-05,
      "loss": 0.2965,
      "step": 5000
    },
    {
      "epoch": 1.618739903069467,
      "grad_norm": 4.0115180015563965,
      "learning_rate": 2.302638664512655e-05,
      "loss": 0.315,
      "step": 5010
    },
    {
      "epoch": 1.6219709208400648,
      "grad_norm": 4.842001914978027,
      "learning_rate": 2.297253634894992e-05,
      "loss": 0.3786,
      "step": 5020
    },
    {
      "epoch": 1.6252019386106622,
      "grad_norm": 3.7633118629455566,
      "learning_rate": 2.2918686052773293e-05,
      "loss": 0.3306,
      "step": 5030
    },
    {
      "epoch": 1.62843295638126,
      "grad_norm": 5.437653064727783,
      "learning_rate": 2.286483575659666e-05,
      "loss": 0.4316,
      "step": 5040
    },
    {
      "epoch": 1.631663974151858,
      "grad_norm": 5.336374282836914,
      "learning_rate": 2.2810985460420033e-05,
      "loss": 0.3925,
      "step": 5050
    },
    {
      "epoch": 1.6348949919224556,
      "grad_norm": 4.853799343109131,
      "learning_rate": 2.2757135164243404e-05,
      "loss": 0.3623,
      "step": 5060
    },
    {
      "epoch": 1.6381260096930532,
      "grad_norm": 3.532496213912964,
      "learning_rate": 2.2703284868066777e-05,
      "loss": 0.3521,
      "step": 5070
    },
    {
      "epoch": 1.641357027463651,
      "grad_norm": 4.505873680114746,
      "learning_rate": 2.2649434571890147e-05,
      "loss": 0.3024,
      "step": 5080
    },
    {
      "epoch": 1.644588045234249,
      "grad_norm": 4.7654852867126465,
      "learning_rate": 2.2595584275713518e-05,
      "loss": 0.3921,
      "step": 5090
    },
    {
      "epoch": 1.6478190630048464,
      "grad_norm": 5.006505012512207,
      "learning_rate": 2.2541733979536888e-05,
      "loss": 0.33,
      "step": 5100
    },
    {
      "epoch": 1.6510500807754442,
      "grad_norm": 2.9085562229156494,
      "learning_rate": 2.2487883683360258e-05,
      "loss": 0.2776,
      "step": 5110
    },
    {
      "epoch": 1.654281098546042,
      "grad_norm": 6.694738864898682,
      "learning_rate": 2.243403338718363e-05,
      "loss": 0.3399,
      "step": 5120
    },
    {
      "epoch": 1.6575121163166397,
      "grad_norm": 3.3243889808654785,
      "learning_rate": 2.2380183091007002e-05,
      "loss": 0.2998,
      "step": 5130
    },
    {
      "epoch": 1.6607431340872374,
      "grad_norm": 6.101940631866455,
      "learning_rate": 2.2326332794830372e-05,
      "loss": 0.3743,
      "step": 5140
    },
    {
      "epoch": 1.6639741518578353,
      "grad_norm": 5.4771928787231445,
      "learning_rate": 2.2272482498653742e-05,
      "loss": 0.3462,
      "step": 5150
    },
    {
      "epoch": 1.667205169628433,
      "grad_norm": 5.844724655151367,
      "learning_rate": 2.2218632202477116e-05,
      "loss": 0.3991,
      "step": 5160
    },
    {
      "epoch": 1.6704361873990305,
      "grad_norm": 6.147848129272461,
      "learning_rate": 2.2164781906300486e-05,
      "loss": 0.3926,
      "step": 5170
    },
    {
      "epoch": 1.6736672051696284,
      "grad_norm": 3.430649518966675,
      "learning_rate": 2.2110931610123856e-05,
      "loss": 0.3449,
      "step": 5180
    },
    {
      "epoch": 1.6768982229402263,
      "grad_norm": 3.760610818862915,
      "learning_rate": 2.205708131394723e-05,
      "loss": 0.2604,
      "step": 5190
    },
    {
      "epoch": 1.680129240710824,
      "grad_norm": 6.898835182189941,
      "learning_rate": 2.2003231017770597e-05,
      "loss": 0.4513,
      "step": 5200
    },
    {
      "epoch": 1.6833602584814216,
      "grad_norm": 4.964336395263672,
      "learning_rate": 2.194938072159397e-05,
      "loss": 0.3852,
      "step": 5210
    },
    {
      "epoch": 1.6865912762520194,
      "grad_norm": 8.644818305969238,
      "learning_rate": 2.189553042541734e-05,
      "loss": 0.3726,
      "step": 5220
    },
    {
      "epoch": 1.689822294022617,
      "grad_norm": 2.748265266418457,
      "learning_rate": 2.1841680129240714e-05,
      "loss": 0.4235,
      "step": 5230
    },
    {
      "epoch": 1.6930533117932147,
      "grad_norm": 3.0466935634613037,
      "learning_rate": 2.1787829833064084e-05,
      "loss": 0.3664,
      "step": 5240
    },
    {
      "epoch": 1.6962843295638126,
      "grad_norm": 4.768592357635498,
      "learning_rate": 2.1733979536887454e-05,
      "loss": 0.3465,
      "step": 5250
    },
    {
      "epoch": 1.6995153473344105,
      "grad_norm": 4.9658966064453125,
      "learning_rate": 2.1680129240710824e-05,
      "loss": 0.3714,
      "step": 5260
    },
    {
      "epoch": 1.702746365105008,
      "grad_norm": 2.5839223861694336,
      "learning_rate": 2.1626278944534195e-05,
      "loss": 0.2959,
      "step": 5270
    },
    {
      "epoch": 1.7059773828756057,
      "grad_norm": 4.034128665924072,
      "learning_rate": 2.1572428648357568e-05,
      "loss": 0.3351,
      "step": 5280
    },
    {
      "epoch": 1.7092084006462036,
      "grad_norm": 6.282344341278076,
      "learning_rate": 2.151857835218094e-05,
      "loss": 0.3292,
      "step": 5290
    },
    {
      "epoch": 1.7124394184168013,
      "grad_norm": 4.993409633636475,
      "learning_rate": 2.146472805600431e-05,
      "loss": 0.3064,
      "step": 5300
    },
    {
      "epoch": 1.715670436187399,
      "grad_norm": 2.860206127166748,
      "learning_rate": 2.141087775982768e-05,
      "loss": 0.3097,
      "step": 5310
    },
    {
      "epoch": 1.7189014539579968,
      "grad_norm": 3.6575372219085693,
      "learning_rate": 2.135702746365105e-05,
      "loss": 0.2859,
      "step": 5320
    },
    {
      "epoch": 1.7221324717285946,
      "grad_norm": 5.446681499481201,
      "learning_rate": 2.1303177167474423e-05,
      "loss": 0.4911,
      "step": 5330
    },
    {
      "epoch": 1.7253634894991923,
      "grad_norm": 5.9735565185546875,
      "learning_rate": 2.1249326871297793e-05,
      "loss": 0.3923,
      "step": 5340
    },
    {
      "epoch": 1.72859450726979,
      "grad_norm": 4.954345703125,
      "learning_rate": 2.1195476575121166e-05,
      "loss": 0.3109,
      "step": 5350
    },
    {
      "epoch": 1.7318255250403878,
      "grad_norm": 3.1920082569122314,
      "learning_rate": 2.1141626278944533e-05,
      "loss": 0.3401,
      "step": 5360
    },
    {
      "epoch": 1.7350565428109854,
      "grad_norm": 11.107954025268555,
      "learning_rate": 2.1087775982767907e-05,
      "loss": 0.3467,
      "step": 5370
    },
    {
      "epoch": 1.738287560581583,
      "grad_norm": 3.067021608352661,
      "learning_rate": 2.1033925686591277e-05,
      "loss": 0.3853,
      "step": 5380
    },
    {
      "epoch": 1.741518578352181,
      "grad_norm": 2.829045057296753,
      "learning_rate": 2.098007539041465e-05,
      "loss": 0.3791,
      "step": 5390
    },
    {
      "epoch": 1.7447495961227788,
      "grad_norm": 2.9538443088531494,
      "learning_rate": 2.092622509423802e-05,
      "loss": 0.3456,
      "step": 5400
    },
    {
      "epoch": 1.7479806138933764,
      "grad_norm": 4.229047775268555,
      "learning_rate": 2.087237479806139e-05,
      "loss": 0.3696,
      "step": 5410
    },
    {
      "epoch": 1.751211631663974,
      "grad_norm": 3.320307731628418,
      "learning_rate": 2.081852450188476e-05,
      "loss": 0.2976,
      "step": 5420
    },
    {
      "epoch": 1.754442649434572,
      "grad_norm": 4.895577430725098,
      "learning_rate": 2.076467420570813e-05,
      "loss": 0.335,
      "step": 5430
    },
    {
      "epoch": 1.7576736672051696,
      "grad_norm": 3.500643014907837,
      "learning_rate": 2.0710823909531505e-05,
      "loss": 0.3022,
      "step": 5440
    },
    {
      "epoch": 1.7609046849757672,
      "grad_norm": 3.7906715869903564,
      "learning_rate": 2.0656973613354875e-05,
      "loss": 0.3727,
      "step": 5450
    },
    {
      "epoch": 1.764135702746365,
      "grad_norm": 6.909123420715332,
      "learning_rate": 2.0603123317178245e-05,
      "loss": 0.3722,
      "step": 5460
    },
    {
      "epoch": 1.767366720516963,
      "grad_norm": 4.227447509765625,
      "learning_rate": 2.0549273021001615e-05,
      "loss": 0.2659,
      "step": 5470
    },
    {
      "epoch": 1.7705977382875606,
      "grad_norm": 3.3395841121673584,
      "learning_rate": 2.0495422724824986e-05,
      "loss": 0.3678,
      "step": 5480
    },
    {
      "epoch": 1.7738287560581583,
      "grad_norm": 4.3502068519592285,
      "learning_rate": 2.044157242864836e-05,
      "loss": 0.3106,
      "step": 5490
    },
    {
      "epoch": 1.7770597738287561,
      "grad_norm": 3.6947031021118164,
      "learning_rate": 2.038772213247173e-05,
      "loss": 0.3277,
      "step": 5500
    },
    {
      "epoch": 1.7802907915993538,
      "grad_norm": 5.247866153717041,
      "learning_rate": 2.0333871836295103e-05,
      "loss": 0.3162,
      "step": 5510
    },
    {
      "epoch": 1.7835218093699514,
      "grad_norm": 4.3634161949157715,
      "learning_rate": 2.028002154011847e-05,
      "loss": 0.3052,
      "step": 5520
    },
    {
      "epoch": 1.7867528271405493,
      "grad_norm": 4.896689414978027,
      "learning_rate": 2.0226171243941843e-05,
      "loss": 0.3565,
      "step": 5530
    },
    {
      "epoch": 1.7899838449111471,
      "grad_norm": 4.250126838684082,
      "learning_rate": 2.0172320947765214e-05,
      "loss": 0.4217,
      "step": 5540
    },
    {
      "epoch": 1.7932148626817448,
      "grad_norm": 3.852511167526245,
      "learning_rate": 2.0118470651588584e-05,
      "loss": 0.3738,
      "step": 5550
    },
    {
      "epoch": 1.7964458804523424,
      "grad_norm": 2.5389044284820557,
      "learning_rate": 2.0064620355411957e-05,
      "loss": 0.2903,
      "step": 5560
    },
    {
      "epoch": 1.7996768982229403,
      "grad_norm": 5.682387351989746,
      "learning_rate": 2.0010770059235324e-05,
      "loss": 0.3522,
      "step": 5570
    },
    {
      "epoch": 1.802907915993538,
      "grad_norm": 3.372093677520752,
      "learning_rate": 1.9956919763058698e-05,
      "loss": 0.2705,
      "step": 5580
    },
    {
      "epoch": 1.8061389337641356,
      "grad_norm": 5.364351272583008,
      "learning_rate": 1.9903069466882068e-05,
      "loss": 0.353,
      "step": 5590
    },
    {
      "epoch": 1.8093699515347335,
      "grad_norm": 6.527543544769287,
      "learning_rate": 1.984921917070544e-05,
      "loss": 0.3801,
      "step": 5600
    },
    {
      "epoch": 1.8126009693053313,
      "grad_norm": 3.2363827228546143,
      "learning_rate": 1.9795368874528812e-05,
      "loss": 0.3276,
      "step": 5610
    },
    {
      "epoch": 1.815831987075929,
      "grad_norm": 4.241222858428955,
      "learning_rate": 1.9741518578352182e-05,
      "loss": 0.3487,
      "step": 5620
    },
    {
      "epoch": 1.8190630048465266,
      "grad_norm": 6.128350257873535,
      "learning_rate": 1.9687668282175552e-05,
      "loss": 0.294,
      "step": 5630
    },
    {
      "epoch": 1.8222940226171245,
      "grad_norm": 5.181721210479736,
      "learning_rate": 1.9633817985998922e-05,
      "loss": 0.4589,
      "step": 5640
    },
    {
      "epoch": 1.8255250403877221,
      "grad_norm": 3.240436315536499,
      "learning_rate": 1.9579967689822296e-05,
      "loss": 0.3881,
      "step": 5650
    },
    {
      "epoch": 1.8287560581583198,
      "grad_norm": 2.6457996368408203,
      "learning_rate": 1.9526117393645666e-05,
      "loss": 0.3308,
      "step": 5660
    },
    {
      "epoch": 1.8319870759289176,
      "grad_norm": 3.932724714279175,
      "learning_rate": 1.9472267097469036e-05,
      "loss": 0.3457,
      "step": 5670
    },
    {
      "epoch": 1.8352180936995155,
      "grad_norm": 3.6828184127807617,
      "learning_rate": 1.9418416801292407e-05,
      "loss": 0.3086,
      "step": 5680
    },
    {
      "epoch": 1.8384491114701131,
      "grad_norm": 6.590358734130859,
      "learning_rate": 1.936456650511578e-05,
      "loss": 0.464,
      "step": 5690
    },
    {
      "epoch": 1.8416801292407108,
      "grad_norm": 3.892549514770508,
      "learning_rate": 1.931071620893915e-05,
      "loss": 0.2973,
      "step": 5700
    },
    {
      "epoch": 1.8449111470113086,
      "grad_norm": 6.130838394165039,
      "learning_rate": 1.925686591276252e-05,
      "loss": 0.3235,
      "step": 5710
    },
    {
      "epoch": 1.8481421647819063,
      "grad_norm": 4.254144191741943,
      "learning_rate": 1.9203015616585894e-05,
      "loss": 0.3465,
      "step": 5720
    },
    {
      "epoch": 1.851373182552504,
      "grad_norm": 5.88566255569458,
      "learning_rate": 1.914916532040926e-05,
      "loss": 0.3434,
      "step": 5730
    },
    {
      "epoch": 1.8546042003231018,
      "grad_norm": 2.3880560398101807,
      "learning_rate": 1.9095315024232634e-05,
      "loss": 0.2949,
      "step": 5740
    },
    {
      "epoch": 1.8578352180936997,
      "grad_norm": 4.307471752166748,
      "learning_rate": 1.9041464728056005e-05,
      "loss": 0.3499,
      "step": 5750
    },
    {
      "epoch": 1.861066235864297,
      "grad_norm": 2.444092273712158,
      "learning_rate": 1.8987614431879378e-05,
      "loss": 0.2737,
      "step": 5760
    },
    {
      "epoch": 1.864297253634895,
      "grad_norm": 3.6658999919891357,
      "learning_rate": 1.893376413570275e-05,
      "loss": 0.3407,
      "step": 5770
    },
    {
      "epoch": 1.8675282714054928,
      "grad_norm": 4.401204586029053,
      "learning_rate": 1.887991383952612e-05,
      "loss": 0.3205,
      "step": 5780
    },
    {
      "epoch": 1.8707592891760905,
      "grad_norm": 5.192491054534912,
      "learning_rate": 1.882606354334949e-05,
      "loss": 0.2885,
      "step": 5790
    },
    {
      "epoch": 1.8739903069466881,
      "grad_norm": 5.432775020599365,
      "learning_rate": 1.877221324717286e-05,
      "loss": 0.3463,
      "step": 5800
    },
    {
      "epoch": 1.877221324717286,
      "grad_norm": 6.219046115875244,
      "learning_rate": 1.8718362950996233e-05,
      "loss": 0.2967,
      "step": 5810
    },
    {
      "epoch": 1.8804523424878838,
      "grad_norm": 5.31177282333374,
      "learning_rate": 1.8664512654819603e-05,
      "loss": 0.367,
      "step": 5820
    },
    {
      "epoch": 1.8836833602584813,
      "grad_norm": 5.103212833404541,
      "learning_rate": 1.8610662358642973e-05,
      "loss": 0.3104,
      "step": 5830
    },
    {
      "epoch": 1.8869143780290791,
      "grad_norm": 5.684974670410156,
      "learning_rate": 1.8556812062466343e-05,
      "loss": 0.3287,
      "step": 5840
    },
    {
      "epoch": 1.890145395799677,
      "grad_norm": 5.0377726554870605,
      "learning_rate": 1.8502961766289713e-05,
      "loss": 0.2951,
      "step": 5850
    },
    {
      "epoch": 1.8933764135702746,
      "grad_norm": 4.062934398651123,
      "learning_rate": 1.8449111470113087e-05,
      "loss": 0.3394,
      "step": 5860
    },
    {
      "epoch": 1.8966074313408723,
      "grad_norm": 2.3519368171691895,
      "learning_rate": 1.8395261173936457e-05,
      "loss": 0.3771,
      "step": 5870
    },
    {
      "epoch": 1.8998384491114702,
      "grad_norm": 2.2913565635681152,
      "learning_rate": 1.834141087775983e-05,
      "loss": 0.336,
      "step": 5880
    },
    {
      "epoch": 1.903069466882068,
      "grad_norm": 4.830004692077637,
      "learning_rate": 1.8287560581583198e-05,
      "loss": 0.4042,
      "step": 5890
    },
    {
      "epoch": 1.9063004846526654,
      "grad_norm": 3.182584285736084,
      "learning_rate": 1.823371028540657e-05,
      "loss": 0.2774,
      "step": 5900
    },
    {
      "epoch": 1.9095315024232633,
      "grad_norm": 3.9698143005371094,
      "learning_rate": 1.817985998922994e-05,
      "loss": 0.2693,
      "step": 5910
    },
    {
      "epoch": 1.9127625201938612,
      "grad_norm": 4.202843189239502,
      "learning_rate": 1.812600969305331e-05,
      "loss": 0.3592,
      "step": 5920
    },
    {
      "epoch": 1.9159935379644588,
      "grad_norm": 4.147406101226807,
      "learning_rate": 1.8072159396876685e-05,
      "loss": 0.2933,
      "step": 5930
    },
    {
      "epoch": 1.9192245557350565,
      "grad_norm": 4.062290191650391,
      "learning_rate": 1.8018309100700055e-05,
      "loss": 0.3142,
      "step": 5940
    },
    {
      "epoch": 1.9224555735056543,
      "grad_norm": 5.736400127410889,
      "learning_rate": 1.7964458804523425e-05,
      "loss": 0.3688,
      "step": 5950
    },
    {
      "epoch": 1.925686591276252,
      "grad_norm": 6.62998628616333,
      "learning_rate": 1.7910608508346796e-05,
      "loss": 0.3311,
      "step": 5960
    },
    {
      "epoch": 1.9289176090468496,
      "grad_norm": 3.7007088661193848,
      "learning_rate": 1.785675821217017e-05,
      "loss": 0.3524,
      "step": 5970
    },
    {
      "epoch": 1.9321486268174475,
      "grad_norm": 4.7984514236450195,
      "learning_rate": 1.780290791599354e-05,
      "loss": 0.3018,
      "step": 5980
    },
    {
      "epoch": 1.9353796445880453,
      "grad_norm": 3.2714362144470215,
      "learning_rate": 1.774905761981691e-05,
      "loss": 0.3302,
      "step": 5990
    },
    {
      "epoch": 1.938610662358643,
      "grad_norm": 4.167322158813477,
      "learning_rate": 1.769520732364028e-05,
      "loss": 0.3368,
      "step": 6000
    },
    {
      "epoch": 1.9418416801292406,
      "grad_norm": 4.22084379196167,
      "learning_rate": 1.764135702746365e-05,
      "loss": 0.3771,
      "step": 6010
    },
    {
      "epoch": 1.9450726978998385,
      "grad_norm": 4.41655969619751,
      "learning_rate": 1.7587506731287024e-05,
      "loss": 0.3428,
      "step": 6020
    },
    {
      "epoch": 1.9483037156704361,
      "grad_norm": 4.692601203918457,
      "learning_rate": 1.7533656435110394e-05,
      "loss": 0.2427,
      "step": 6030
    },
    {
      "epoch": 1.9515347334410338,
      "grad_norm": 6.7695231437683105,
      "learning_rate": 1.7479806138933767e-05,
      "loss": 0.3671,
      "step": 6040
    },
    {
      "epoch": 1.9547657512116317,
      "grad_norm": 4.934293746948242,
      "learning_rate": 1.7425955842757134e-05,
      "loss": 0.4047,
      "step": 6050
    },
    {
      "epoch": 1.9579967689822295,
      "grad_norm": 5.652031421661377,
      "learning_rate": 1.7372105546580508e-05,
      "loss": 0.4684,
      "step": 6060
    },
    {
      "epoch": 1.9612277867528272,
      "grad_norm": 2.5011255741119385,
      "learning_rate": 1.7318255250403878e-05,
      "loss": 0.2815,
      "step": 6070
    },
    {
      "epoch": 1.9644588045234248,
      "grad_norm": 2.9346249103546143,
      "learning_rate": 1.7264404954227248e-05,
      "loss": 0.3536,
      "step": 6080
    },
    {
      "epoch": 1.9676898222940227,
      "grad_norm": 3.761251449584961,
      "learning_rate": 1.7210554658050622e-05,
      "loss": 0.325,
      "step": 6090
    },
    {
      "epoch": 1.9709208400646203,
      "grad_norm": 3.9247238636016846,
      "learning_rate": 1.7156704361873992e-05,
      "loss": 0.2769,
      "step": 6100
    },
    {
      "epoch": 1.974151857835218,
      "grad_norm": 5.742280006408691,
      "learning_rate": 1.7102854065697362e-05,
      "loss": 0.3268,
      "step": 6110
    },
    {
      "epoch": 1.9773828756058158,
      "grad_norm": 7.020021915435791,
      "learning_rate": 1.7049003769520732e-05,
      "loss": 0.2212,
      "step": 6120
    },
    {
      "epoch": 1.9806138933764137,
      "grad_norm": 4.5917205810546875,
      "learning_rate": 1.6995153473344106e-05,
      "loss": 0.3617,
      "step": 6130
    },
    {
      "epoch": 1.9838449111470113,
      "grad_norm": 4.190851211547852,
      "learning_rate": 1.6941303177167476e-05,
      "loss": 0.3588,
      "step": 6140
    },
    {
      "epoch": 1.987075928917609,
      "grad_norm": 3.376032829284668,
      "learning_rate": 1.6887452880990846e-05,
      "loss": 0.3151,
      "step": 6150
    },
    {
      "epoch": 1.9903069466882068,
      "grad_norm": 3.502883195877075,
      "learning_rate": 1.6833602584814216e-05,
      "loss": 0.2811,
      "step": 6160
    },
    {
      "epoch": 1.9935379644588045,
      "grad_norm": 4.2385687828063965,
      "learning_rate": 1.6779752288637587e-05,
      "loss": 0.3181,
      "step": 6170
    },
    {
      "epoch": 1.9967689822294021,
      "grad_norm": 4.71256160736084,
      "learning_rate": 1.672590199246096e-05,
      "loss": 0.3284,
      "step": 6180
    },
    {
      "epoch": 2.0,
      "grad_norm": 9.949847221374512,
      "learning_rate": 1.667205169628433e-05,
      "loss": 0.4036,
      "step": 6190
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.634407103061676,
      "eval_runtime": 30.0261,
      "eval_samples_per_second": 22.913,
      "eval_steps_per_second": 11.457,
      "step": 6190
    },
    {
      "epoch": 2.003231017770598,
      "grad_norm": 2.7551116943359375,
      "learning_rate": 1.6618201400107704e-05,
      "loss": 0.2142,
      "step": 6200
    },
    {
      "epoch": 2.0064620355411953,
      "grad_norm": 3.0917422771453857,
      "learning_rate": 1.656435110393107e-05,
      "loss": 0.1814,
      "step": 6210
    },
    {
      "epoch": 2.009693053311793,
      "grad_norm": 2.0329430103302,
      "learning_rate": 1.651050080775444e-05,
      "loss": 0.1601,
      "step": 6220
    },
    {
      "epoch": 2.012924071082391,
      "grad_norm": 7.104781627655029,
      "learning_rate": 1.6456650511577815e-05,
      "loss": 0.1671,
      "step": 6230
    },
    {
      "epoch": 2.016155088852989,
      "grad_norm": 2.9438068866729736,
      "learning_rate": 1.6402800215401185e-05,
      "loss": 0.1401,
      "step": 6240
    },
    {
      "epoch": 2.0193861066235863,
      "grad_norm": 3.4403929710388184,
      "learning_rate": 1.634894991922456e-05,
      "loss": 0.1876,
      "step": 6250
    },
    {
      "epoch": 2.022617124394184,
      "grad_norm": 6.996779918670654,
      "learning_rate": 1.629509962304793e-05,
      "loss": 0.2167,
      "step": 6260
    },
    {
      "epoch": 2.025848142164782,
      "grad_norm": 2.3112361431121826,
      "learning_rate": 1.62412493268713e-05,
      "loss": 0.1409,
      "step": 6270
    },
    {
      "epoch": 2.0290791599353795,
      "grad_norm": 2.568971872329712,
      "learning_rate": 1.618739903069467e-05,
      "loss": 0.1574,
      "step": 6280
    },
    {
      "epoch": 2.0323101777059773,
      "grad_norm": 3.7159276008605957,
      "learning_rate": 1.6133548734518043e-05,
      "loss": 0.1887,
      "step": 6290
    },
    {
      "epoch": 2.035541195476575,
      "grad_norm": 2.79407000541687,
      "learning_rate": 1.6079698438341413e-05,
      "loss": 0.1837,
      "step": 6300
    },
    {
      "epoch": 2.038772213247173,
      "grad_norm": 4.385810375213623,
      "learning_rate": 1.6025848142164783e-05,
      "loss": 0.1986,
      "step": 6310
    },
    {
      "epoch": 2.0420032310177705,
      "grad_norm": 2.599432945251465,
      "learning_rate": 1.5971997845988153e-05,
      "loss": 0.1623,
      "step": 6320
    },
    {
      "epoch": 2.0452342487883683,
      "grad_norm": 7.3237199783325195,
      "learning_rate": 1.5918147549811523e-05,
      "loss": 0.1711,
      "step": 6330
    },
    {
      "epoch": 2.048465266558966,
      "grad_norm": 3.9612841606140137,
      "learning_rate": 1.5864297253634897e-05,
      "loss": 0.1597,
      "step": 6340
    },
    {
      "epoch": 2.0516962843295636,
      "grad_norm": 6.985826015472412,
      "learning_rate": 1.5810446957458267e-05,
      "loss": 0.2476,
      "step": 6350
    },
    {
      "epoch": 2.0549273021001615,
      "grad_norm": 4.404146671295166,
      "learning_rate": 1.575659666128164e-05,
      "loss": 0.1313,
      "step": 6360
    },
    {
      "epoch": 2.0581583198707594,
      "grad_norm": 4.7027764320373535,
      "learning_rate": 1.5702746365105007e-05,
      "loss": 0.1509,
      "step": 6370
    },
    {
      "epoch": 2.0613893376413572,
      "grad_norm": 2.9014811515808105,
      "learning_rate": 1.5648896068928378e-05,
      "loss": 0.1734,
      "step": 6380
    },
    {
      "epoch": 2.0646203554119547,
      "grad_norm": 3.2872729301452637,
      "learning_rate": 1.559504577275175e-05,
      "loss": 0.1456,
      "step": 6390
    },
    {
      "epoch": 2.0678513731825525,
      "grad_norm": 3.5889673233032227,
      "learning_rate": 1.554119547657512e-05,
      "loss": 0.0967,
      "step": 6400
    },
    {
      "epoch": 2.0710823909531504,
      "grad_norm": 4.452873229980469,
      "learning_rate": 1.5487345180398495e-05,
      "loss": 0.1455,
      "step": 6410
    },
    {
      "epoch": 2.074313408723748,
      "grad_norm": 5.206044673919678,
      "learning_rate": 1.5433494884221862e-05,
      "loss": 0.1943,
      "step": 6420
    },
    {
      "epoch": 2.0775444264943457,
      "grad_norm": 1.8523144721984863,
      "learning_rate": 1.5379644588045235e-05,
      "loss": 0.1902,
      "step": 6430
    },
    {
      "epoch": 2.0807754442649435,
      "grad_norm": 5.577451705932617,
      "learning_rate": 1.5325794291868606e-05,
      "loss": 0.1819,
      "step": 6440
    },
    {
      "epoch": 2.0840064620355414,
      "grad_norm": 9.780898094177246,
      "learning_rate": 1.5271943995691976e-05,
      "loss": 0.1714,
      "step": 6450
    },
    {
      "epoch": 2.087237479806139,
      "grad_norm": 3.3416941165924072,
      "learning_rate": 1.5218093699515348e-05,
      "loss": 0.1591,
      "step": 6460
    },
    {
      "epoch": 2.0904684975767367,
      "grad_norm": 5.102044105529785,
      "learning_rate": 1.5164243403338718e-05,
      "loss": 0.2091,
      "step": 6470
    },
    {
      "epoch": 2.0936995153473346,
      "grad_norm": 3.7679200172424316,
      "learning_rate": 1.5110393107162091e-05,
      "loss": 0.2148,
      "step": 6480
    },
    {
      "epoch": 2.096930533117932,
      "grad_norm": 8.639057159423828,
      "learning_rate": 1.505654281098546e-05,
      "loss": 0.1935,
      "step": 6490
    },
    {
      "epoch": 2.10016155088853,
      "grad_norm": 4.542999744415283,
      "learning_rate": 1.5002692514808834e-05,
      "loss": 0.1495,
      "step": 6500
    },
    {
      "epoch": 2.1033925686591277,
      "grad_norm": 3.5148963928222656,
      "learning_rate": 1.4948842218632204e-05,
      "loss": 0.1949,
      "step": 6510
    },
    {
      "epoch": 2.106623586429725,
      "grad_norm": 4.196393966674805,
      "learning_rate": 1.4894991922455572e-05,
      "loss": 0.1302,
      "step": 6520
    },
    {
      "epoch": 2.109854604200323,
      "grad_norm": 12.319845199584961,
      "learning_rate": 1.4841141626278946e-05,
      "loss": 0.1776,
      "step": 6530
    },
    {
      "epoch": 2.113085621970921,
      "grad_norm": 3.6273422241210938,
      "learning_rate": 1.4787291330102316e-05,
      "loss": 0.2158,
      "step": 6540
    },
    {
      "epoch": 2.1163166397415187,
      "grad_norm": 3.9631426334381104,
      "learning_rate": 1.4733441033925688e-05,
      "loss": 0.1459,
      "step": 6550
    },
    {
      "epoch": 2.119547657512116,
      "grad_norm": 8.427729606628418,
      "learning_rate": 1.4679590737749058e-05,
      "loss": 0.1879,
      "step": 6560
    },
    {
      "epoch": 2.122778675282714,
      "grad_norm": 4.803462982177734,
      "learning_rate": 1.462574044157243e-05,
      "loss": 0.1551,
      "step": 6570
    },
    {
      "epoch": 2.126009693053312,
      "grad_norm": 5.960893154144287,
      "learning_rate": 1.45718901453958e-05,
      "loss": 0.1861,
      "step": 6580
    },
    {
      "epoch": 2.1292407108239093,
      "grad_norm": 2.672006607055664,
      "learning_rate": 1.4518039849219172e-05,
      "loss": 0.1714,
      "step": 6590
    },
    {
      "epoch": 2.132471728594507,
      "grad_norm": 4.077564716339111,
      "learning_rate": 1.4464189553042542e-05,
      "loss": 0.1382,
      "step": 6600
    },
    {
      "epoch": 2.135702746365105,
      "grad_norm": 3.0325701236724854,
      "learning_rate": 1.4410339256865912e-05,
      "loss": 0.1319,
      "step": 6610
    },
    {
      "epoch": 2.138933764135703,
      "grad_norm": 3.3615024089813232,
      "learning_rate": 1.4356488960689284e-05,
      "loss": 0.2092,
      "step": 6620
    },
    {
      "epoch": 2.1421647819063003,
      "grad_norm": 2.5225753784179688,
      "learning_rate": 1.4302638664512655e-05,
      "loss": 0.1862,
      "step": 6630
    },
    {
      "epoch": 2.145395799676898,
      "grad_norm": 2.6968722343444824,
      "learning_rate": 1.4248788368336028e-05,
      "loss": 0.1459,
      "step": 6640
    },
    {
      "epoch": 2.148626817447496,
      "grad_norm": 2.7132468223571777,
      "learning_rate": 1.4194938072159397e-05,
      "loss": 0.1454,
      "step": 6650
    },
    {
      "epoch": 2.1518578352180935,
      "grad_norm": 4.271932601928711,
      "learning_rate": 1.414108777598277e-05,
      "loss": 0.1497,
      "step": 6660
    },
    {
      "epoch": 2.1550888529886914,
      "grad_norm": 2.768099784851074,
      "learning_rate": 1.408723747980614e-05,
      "loss": 0.1264,
      "step": 6670
    },
    {
      "epoch": 2.158319870759289,
      "grad_norm": 3.9061522483825684,
      "learning_rate": 1.4033387183629509e-05,
      "loss": 0.1493,
      "step": 6680
    },
    {
      "epoch": 2.161550888529887,
      "grad_norm": 4.673736095428467,
      "learning_rate": 1.3979536887452882e-05,
      "loss": 0.1322,
      "step": 6690
    },
    {
      "epoch": 2.1647819063004845,
      "grad_norm": 2.5031957626342773,
      "learning_rate": 1.3925686591276253e-05,
      "loss": 0.1281,
      "step": 6700
    },
    {
      "epoch": 2.1680129240710824,
      "grad_norm": 2.6627819538116455,
      "learning_rate": 1.3871836295099625e-05,
      "loss": 0.1253,
      "step": 6710
    },
    {
      "epoch": 2.1712439418416802,
      "grad_norm": 4.467174530029297,
      "learning_rate": 1.3817985998922995e-05,
      "loss": 0.2039,
      "step": 6720
    },
    {
      "epoch": 2.1744749596122777,
      "grad_norm": 2.4559977054595947,
      "learning_rate": 1.3764135702746367e-05,
      "loss": 0.1579,
      "step": 6730
    },
    {
      "epoch": 2.1777059773828755,
      "grad_norm": 8.363282203674316,
      "learning_rate": 1.3710285406569737e-05,
      "loss": 0.144,
      "step": 6740
    },
    {
      "epoch": 2.1809369951534734,
      "grad_norm": 2.751481056213379,
      "learning_rate": 1.3656435110393107e-05,
      "loss": 0.1338,
      "step": 6750
    },
    {
      "epoch": 2.1841680129240713,
      "grad_norm": 2.890092372894287,
      "learning_rate": 1.3602584814216479e-05,
      "loss": 0.1196,
      "step": 6760
    },
    {
      "epoch": 2.1873990306946687,
      "grad_norm": 3.2592108249664307,
      "learning_rate": 1.3548734518039849e-05,
      "loss": 0.131,
      "step": 6770
    },
    {
      "epoch": 2.1906300484652665,
      "grad_norm": 1.4395098686218262,
      "learning_rate": 1.3494884221863221e-05,
      "loss": 0.1801,
      "step": 6780
    },
    {
      "epoch": 2.1938610662358644,
      "grad_norm": 6.248368740081787,
      "learning_rate": 1.3441033925686591e-05,
      "loss": 0.1426,
      "step": 6790
    },
    {
      "epoch": 2.197092084006462,
      "grad_norm": 3.933706283569336,
      "learning_rate": 1.3387183629509965e-05,
      "loss": 0.2337,
      "step": 6800
    },
    {
      "epoch": 2.2003231017770597,
      "grad_norm": 6.051784038543701,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 0.1353,
      "step": 6810
    },
    {
      "epoch": 2.2035541195476576,
      "grad_norm": 3.178679943084717,
      "learning_rate": 1.3279483037156707e-05,
      "loss": 0.1475,
      "step": 6820
    },
    {
      "epoch": 2.2067851373182554,
      "grad_norm": 2.602907419204712,
      "learning_rate": 1.3225632740980075e-05,
      "loss": 0.111,
      "step": 6830
    },
    {
      "epoch": 2.210016155088853,
      "grad_norm": 3.861889123916626,
      "learning_rate": 1.3171782444803446e-05,
      "loss": 0.1844,
      "step": 6840
    },
    {
      "epoch": 2.2132471728594507,
      "grad_norm": 3.749948740005493,
      "learning_rate": 1.3117932148626819e-05,
      "loss": 0.1481,
      "step": 6850
    },
    {
      "epoch": 2.2164781906300486,
      "grad_norm": 4.170068740844727,
      "learning_rate": 1.3064081852450188e-05,
      "loss": 0.1709,
      "step": 6860
    },
    {
      "epoch": 2.219709208400646,
      "grad_norm": 3.004392385482788,
      "learning_rate": 1.3010231556273561e-05,
      "loss": 0.1388,
      "step": 6870
    },
    {
      "epoch": 2.222940226171244,
      "grad_norm": 3.311798334121704,
      "learning_rate": 1.2956381260096931e-05,
      "loss": 0.1469,
      "step": 6880
    },
    {
      "epoch": 2.2261712439418417,
      "grad_norm": 3.549508810043335,
      "learning_rate": 1.2902530963920303e-05,
      "loss": 0.1705,
      "step": 6890
    },
    {
      "epoch": 2.2294022617124396,
      "grad_norm": 5.7819743156433105,
      "learning_rate": 1.2848680667743674e-05,
      "loss": 0.1491,
      "step": 6900
    },
    {
      "epoch": 2.232633279483037,
      "grad_norm": 5.149758815765381,
      "learning_rate": 1.2794830371567044e-05,
      "loss": 0.1716,
      "step": 6910
    },
    {
      "epoch": 2.235864297253635,
      "grad_norm": 3.3008811473846436,
      "learning_rate": 1.2740980075390416e-05,
      "loss": 0.1557,
      "step": 6920
    },
    {
      "epoch": 2.2390953150242328,
      "grad_norm": 2.724541425704956,
      "learning_rate": 1.2687129779213786e-05,
      "loss": 0.1702,
      "step": 6930
    },
    {
      "epoch": 2.24232633279483,
      "grad_norm": 2.2602927684783936,
      "learning_rate": 1.2633279483037158e-05,
      "loss": 0.1436,
      "step": 6940
    },
    {
      "epoch": 2.245557350565428,
      "grad_norm": 2.3471016883850098,
      "learning_rate": 1.2579429186860528e-05,
      "loss": 0.1674,
      "step": 6950
    },
    {
      "epoch": 2.248788368336026,
      "grad_norm": 4.838591575622559,
      "learning_rate": 1.25255788906839e-05,
      "loss": 0.1433,
      "step": 6960
    },
    {
      "epoch": 2.2520193861066238,
      "grad_norm": 5.285545825958252,
      "learning_rate": 1.247172859450727e-05,
      "loss": 0.138,
      "step": 6970
    },
    {
      "epoch": 2.255250403877221,
      "grad_norm": 4.0778913497924805,
      "learning_rate": 1.2417878298330642e-05,
      "loss": 0.1335,
      "step": 6980
    },
    {
      "epoch": 2.258481421647819,
      "grad_norm": 3.3143858909606934,
      "learning_rate": 1.2364028002154012e-05,
      "loss": 0.1827,
      "step": 6990
    },
    {
      "epoch": 2.261712439418417,
      "grad_norm": 3.354755401611328,
      "learning_rate": 1.2310177705977384e-05,
      "loss": 0.1887,
      "step": 7000
    },
    {
      "epoch": 2.2649434571890144,
      "grad_norm": 2.680807590484619,
      "learning_rate": 1.2256327409800754e-05,
      "loss": 0.1496,
      "step": 7010
    },
    {
      "epoch": 2.268174474959612,
      "grad_norm": 3.58699893951416,
      "learning_rate": 1.2202477113624124e-05,
      "loss": 0.1668,
      "step": 7020
    },
    {
      "epoch": 2.27140549273021,
      "grad_norm": 4.703036785125732,
      "learning_rate": 1.2148626817447496e-05,
      "loss": 0.1448,
      "step": 7030
    },
    {
      "epoch": 2.274636510500808,
      "grad_norm": 4.7705183029174805,
      "learning_rate": 1.2094776521270868e-05,
      "loss": 0.1126,
      "step": 7040
    },
    {
      "epoch": 2.2778675282714054,
      "grad_norm": 5.078954219818115,
      "learning_rate": 1.2040926225094238e-05,
      "loss": 0.1414,
      "step": 7050
    },
    {
      "epoch": 2.2810985460420032,
      "grad_norm": 2.958632469177246,
      "learning_rate": 1.198707592891761e-05,
      "loss": 0.157,
      "step": 7060
    },
    {
      "epoch": 2.284329563812601,
      "grad_norm": 3.2749805450439453,
      "learning_rate": 1.193322563274098e-05,
      "loss": 0.1927,
      "step": 7070
    },
    {
      "epoch": 2.2875605815831985,
      "grad_norm": 2.0342674255371094,
      "learning_rate": 1.1879375336564352e-05,
      "loss": 0.1186,
      "step": 7080
    },
    {
      "epoch": 2.2907915993537964,
      "grad_norm": 4.9169511795043945,
      "learning_rate": 1.1825525040387722e-05,
      "loss": 0.2111,
      "step": 7090
    },
    {
      "epoch": 2.2940226171243943,
      "grad_norm": 4.083467483520508,
      "learning_rate": 1.1771674744211093e-05,
      "loss": 0.1807,
      "step": 7100
    },
    {
      "epoch": 2.297253634894992,
      "grad_norm": 3.0079290866851807,
      "learning_rate": 1.1717824448034465e-05,
      "loss": 0.1674,
      "step": 7110
    },
    {
      "epoch": 2.3004846526655895,
      "grad_norm": 3.1796112060546875,
      "learning_rate": 1.1663974151857836e-05,
      "loss": 0.151,
      "step": 7120
    },
    {
      "epoch": 2.3037156704361874,
      "grad_norm": 2.3154382705688477,
      "learning_rate": 1.1610123855681207e-05,
      "loss": 0.1945,
      "step": 7130
    },
    {
      "epoch": 2.3069466882067853,
      "grad_norm": 1.694227933883667,
      "learning_rate": 1.1556273559504578e-05,
      "loss": 0.1578,
      "step": 7140
    },
    {
      "epoch": 2.3101777059773827,
      "grad_norm": 3.9661855697631836,
      "learning_rate": 1.1502423263327949e-05,
      "loss": 0.118,
      "step": 7150
    },
    {
      "epoch": 2.3134087237479806,
      "grad_norm": 4.849869251251221,
      "learning_rate": 1.1448572967151319e-05,
      "loss": 0.1929,
      "step": 7160
    },
    {
      "epoch": 2.3166397415185784,
      "grad_norm": 3.689103603363037,
      "learning_rate": 1.139472267097469e-05,
      "loss": 0.1653,
      "step": 7170
    },
    {
      "epoch": 2.3198707592891763,
      "grad_norm": 3.778978109359741,
      "learning_rate": 1.1340872374798061e-05,
      "loss": 0.1597,
      "step": 7180
    },
    {
      "epoch": 2.3231017770597737,
      "grad_norm": 3.4130148887634277,
      "learning_rate": 1.1287022078621433e-05,
      "loss": 0.1046,
      "step": 7190
    },
    {
      "epoch": 2.3263327948303716,
      "grad_norm": 2.8517026901245117,
      "learning_rate": 1.1233171782444805e-05,
      "loss": 0.1545,
      "step": 7200
    },
    {
      "epoch": 2.3295638126009695,
      "grad_norm": 6.709962368011475,
      "learning_rate": 1.1179321486268175e-05,
      "loss": 0.1846,
      "step": 7210
    },
    {
      "epoch": 2.332794830371567,
      "grad_norm": 2.885329246520996,
      "learning_rate": 1.1125471190091547e-05,
      "loss": 0.1445,
      "step": 7220
    },
    {
      "epoch": 2.3360258481421647,
      "grad_norm": 2.750810146331787,
      "learning_rate": 1.1071620893914917e-05,
      "loss": 0.1654,
      "step": 7230
    },
    {
      "epoch": 2.3392568659127626,
      "grad_norm": 2.9657154083251953,
      "learning_rate": 1.1017770597738287e-05,
      "loss": 0.1061,
      "step": 7240
    },
    {
      "epoch": 2.3424878836833605,
      "grad_norm": 4.028951168060303,
      "learning_rate": 1.0963920301561659e-05,
      "loss": 0.1659,
      "step": 7250
    },
    {
      "epoch": 2.345718901453958,
      "grad_norm": 2.8319122791290283,
      "learning_rate": 1.091007000538503e-05,
      "loss": 0.1399,
      "step": 7260
    },
    {
      "epoch": 2.3489499192245558,
      "grad_norm": 8.533252716064453,
      "learning_rate": 1.0856219709208401e-05,
      "loss": 0.2563,
      "step": 7270
    },
    {
      "epoch": 2.3521809369951536,
      "grad_norm": 5.181148529052734,
      "learning_rate": 1.0802369413031773e-05,
      "loss": 0.1953,
      "step": 7280
    },
    {
      "epoch": 2.355411954765751,
      "grad_norm": 4.0318217277526855,
      "learning_rate": 1.0748519116855143e-05,
      "loss": 0.2228,
      "step": 7290
    },
    {
      "epoch": 2.358642972536349,
      "grad_norm": 9.729830741882324,
      "learning_rate": 1.0694668820678515e-05,
      "loss": 0.1639,
      "step": 7300
    },
    {
      "epoch": 2.361873990306947,
      "grad_norm": 1.8426117897033691,
      "learning_rate": 1.0640818524501885e-05,
      "loss": 0.1697,
      "step": 7310
    },
    {
      "epoch": 2.3651050080775446,
      "grad_norm": 2.4394919872283936,
      "learning_rate": 1.0586968228325256e-05,
      "loss": 0.1216,
      "step": 7320
    },
    {
      "epoch": 2.368336025848142,
      "grad_norm": 4.517444610595703,
      "learning_rate": 1.0533117932148627e-05,
      "loss": 0.1581,
      "step": 7330
    },
    {
      "epoch": 2.37156704361874,
      "grad_norm": 3.8034520149230957,
      "learning_rate": 1.0479267635971998e-05,
      "loss": 0.159,
      "step": 7340
    },
    {
      "epoch": 2.374798061389338,
      "grad_norm": 5.634431838989258,
      "learning_rate": 1.042541733979537e-05,
      "loss": 0.1337,
      "step": 7350
    },
    {
      "epoch": 2.378029079159935,
      "grad_norm": 5.8311967849731445,
      "learning_rate": 1.0371567043618741e-05,
      "loss": 0.1489,
      "step": 7360
    },
    {
      "epoch": 2.381260096930533,
      "grad_norm": 4.669323921203613,
      "learning_rate": 1.0317716747442112e-05,
      "loss": 0.1701,
      "step": 7370
    },
    {
      "epoch": 2.384491114701131,
      "grad_norm": 2.6114072799682617,
      "learning_rate": 1.0263866451265483e-05,
      "loss": 0.1525,
      "step": 7380
    },
    {
      "epoch": 2.387722132471729,
      "grad_norm": 4.355450630187988,
      "learning_rate": 1.0210016155088854e-05,
      "loss": 0.1359,
      "step": 7390
    },
    {
      "epoch": 2.3909531502423262,
      "grad_norm": 5.6059064865112305,
      "learning_rate": 1.0156165858912224e-05,
      "loss": 0.1373,
      "step": 7400
    },
    {
      "epoch": 2.394184168012924,
      "grad_norm": 5.067635536193848,
      "learning_rate": 1.0102315562735596e-05,
      "loss": 0.1837,
      "step": 7410
    },
    {
      "epoch": 2.397415185783522,
      "grad_norm": 4.298458099365234,
      "learning_rate": 1.0048465266558966e-05,
      "loss": 0.1441,
      "step": 7420
    },
    {
      "epoch": 2.4006462035541194,
      "grad_norm": 3.2857422828674316,
      "learning_rate": 9.994614970382338e-06,
      "loss": 0.1658,
      "step": 7430
    },
    {
      "epoch": 2.4038772213247173,
      "grad_norm": 3.025630235671997,
      "learning_rate": 9.94076467420571e-06,
      "loss": 0.1486,
      "step": 7440
    },
    {
      "epoch": 2.407108239095315,
      "grad_norm": 5.4725542068481445,
      "learning_rate": 9.88691437802908e-06,
      "loss": 0.1399,
      "step": 7450
    },
    {
      "epoch": 2.410339256865913,
      "grad_norm": 4.99868106842041,
      "learning_rate": 9.83306408185245e-06,
      "loss": 0.2079,
      "step": 7460
    },
    {
      "epoch": 2.4135702746365104,
      "grad_norm": 3.329953908920288,
      "learning_rate": 9.779213785675822e-06,
      "loss": 0.2006,
      "step": 7470
    },
    {
      "epoch": 2.4168012924071083,
      "grad_norm": 6.5509114265441895,
      "learning_rate": 9.725363489499192e-06,
      "loss": 0.1437,
      "step": 7480
    },
    {
      "epoch": 2.420032310177706,
      "grad_norm": 2.031871795654297,
      "learning_rate": 9.671513193322564e-06,
      "loss": 0.1171,
      "step": 7490
    },
    {
      "epoch": 2.4232633279483036,
      "grad_norm": 2.554154634475708,
      "learning_rate": 9.617662897145934e-06,
      "loss": 0.1594,
      "step": 7500
    },
    {
      "epoch": 2.4264943457189014,
      "grad_norm": 3.322770118713379,
      "learning_rate": 9.563812600969306e-06,
      "loss": 0.1357,
      "step": 7510
    },
    {
      "epoch": 2.4297253634894993,
      "grad_norm": 5.097125053405762,
      "learning_rate": 9.509962304792678e-06,
      "loss": 0.1491,
      "step": 7520
    },
    {
      "epoch": 2.432956381260097,
      "grad_norm": 22.03585433959961,
      "learning_rate": 9.456112008616048e-06,
      "loss": 0.1289,
      "step": 7530
    },
    {
      "epoch": 2.4361873990306946,
      "grad_norm": 3.161773920059204,
      "learning_rate": 9.402261712439418e-06,
      "loss": 0.1699,
      "step": 7540
    },
    {
      "epoch": 2.4394184168012925,
      "grad_norm": 5.333274841308594,
      "learning_rate": 9.34841141626279e-06,
      "loss": 0.1738,
      "step": 7550
    },
    {
      "epoch": 2.4426494345718903,
      "grad_norm": 2.837158441543579,
      "learning_rate": 9.29456112008616e-06,
      "loss": 0.1313,
      "step": 7560
    },
    {
      "epoch": 2.4458804523424877,
      "grad_norm": 4.3957719802856445,
      "learning_rate": 9.240710823909532e-06,
      "loss": 0.1568,
      "step": 7570
    },
    {
      "epoch": 2.4491114701130856,
      "grad_norm": 2.1002964973449707,
      "learning_rate": 9.186860527732903e-06,
      "loss": 0.179,
      "step": 7580
    },
    {
      "epoch": 2.4523424878836835,
      "grad_norm": 4.147471904754639,
      "learning_rate": 9.133010231556274e-06,
      "loss": 0.1277,
      "step": 7590
    },
    {
      "epoch": 2.4555735056542813,
      "grad_norm": 3.370772361755371,
      "learning_rate": 9.079159935379646e-06,
      "loss": 0.1327,
      "step": 7600
    },
    {
      "epoch": 2.4588045234248788,
      "grad_norm": 3.8874552249908447,
      "learning_rate": 9.025309639203015e-06,
      "loss": 0.1403,
      "step": 7610
    },
    {
      "epoch": 2.4620355411954766,
      "grad_norm": 8.892433166503906,
      "learning_rate": 8.971459343026387e-06,
      "loss": 0.1808,
      "step": 7620
    },
    {
      "epoch": 2.4652665589660745,
      "grad_norm": 2.721038579940796,
      "learning_rate": 8.917609046849757e-06,
      "loss": 0.1398,
      "step": 7630
    },
    {
      "epoch": 2.468497576736672,
      "grad_norm": 3.9776206016540527,
      "learning_rate": 8.863758750673129e-06,
      "loss": 0.1984,
      "step": 7640
    },
    {
      "epoch": 2.47172859450727,
      "grad_norm": 2.4554665088653564,
      "learning_rate": 8.8099084544965e-06,
      "loss": 0.1344,
      "step": 7650
    },
    {
      "epoch": 2.4749596122778676,
      "grad_norm": 3.961465358734131,
      "learning_rate": 8.756058158319871e-06,
      "loss": 0.1565,
      "step": 7660
    },
    {
      "epoch": 2.4781906300484655,
      "grad_norm": 4.116394996643066,
      "learning_rate": 8.702207862143243e-06,
      "loss": 0.1496,
      "step": 7670
    },
    {
      "epoch": 2.481421647819063,
      "grad_norm": 2.372032403945923,
      "learning_rate": 8.648357565966613e-06,
      "loss": 0.1483,
      "step": 7680
    },
    {
      "epoch": 2.484652665589661,
      "grad_norm": 5.3884196281433105,
      "learning_rate": 8.594507269789983e-06,
      "loss": 0.1994,
      "step": 7690
    },
    {
      "epoch": 2.4878836833602587,
      "grad_norm": 3.4228532314300537,
      "learning_rate": 8.540656973613355e-06,
      "loss": 0.1253,
      "step": 7700
    },
    {
      "epoch": 2.491114701130856,
      "grad_norm": 2.907379627227783,
      "learning_rate": 8.486806677436725e-06,
      "loss": 0.1526,
      "step": 7710
    },
    {
      "epoch": 2.494345718901454,
      "grad_norm": 5.309654712677002,
      "learning_rate": 8.432956381260097e-06,
      "loss": 0.2119,
      "step": 7720
    },
    {
      "epoch": 2.497576736672052,
      "grad_norm": 2.323455333709717,
      "learning_rate": 8.379106085083469e-06,
      "loss": 0.1635,
      "step": 7730
    },
    {
      "epoch": 2.5008077544426497,
      "grad_norm": 4.043670177459717,
      "learning_rate": 8.32525578890684e-06,
      "loss": 0.1598,
      "step": 7740
    },
    {
      "epoch": 2.504038772213247,
      "grad_norm": 4.680424213409424,
      "learning_rate": 8.271405492730211e-06,
      "loss": 0.1762,
      "step": 7750
    },
    {
      "epoch": 2.507269789983845,
      "grad_norm": 2.6190693378448486,
      "learning_rate": 8.217555196553581e-06,
      "loss": 0.1249,
      "step": 7760
    },
    {
      "epoch": 2.5105008077544424,
      "grad_norm": 2.5392792224884033,
      "learning_rate": 8.163704900376952e-06,
      "loss": 0.1445,
      "step": 7770
    },
    {
      "epoch": 2.5137318255250403,
      "grad_norm": 4.380664348602295,
      "learning_rate": 8.109854604200323e-06,
      "loss": 0.1589,
      "step": 7780
    },
    {
      "epoch": 2.516962843295638,
      "grad_norm": 3.4721977710723877,
      "learning_rate": 8.056004308023694e-06,
      "loss": 0.1182,
      "step": 7790
    },
    {
      "epoch": 2.520193861066236,
      "grad_norm": 4.108119487762451,
      "learning_rate": 8.002154011847066e-06,
      "loss": 0.1033,
      "step": 7800
    },
    {
      "epoch": 2.523424878836834,
      "grad_norm": 2.5732529163360596,
      "learning_rate": 7.948303715670437e-06,
      "loss": 0.2068,
      "step": 7810
    },
    {
      "epoch": 2.5266558966074313,
      "grad_norm": 3.5896878242492676,
      "learning_rate": 7.894453419493808e-06,
      "loss": 0.1867,
      "step": 7820
    },
    {
      "epoch": 2.529886914378029,
      "grad_norm": 4.2224931716918945,
      "learning_rate": 7.84060312331718e-06,
      "loss": 0.1644,
      "step": 7830
    },
    {
      "epoch": 2.5331179321486266,
      "grad_norm": 3.6993231773376465,
      "learning_rate": 7.78675282714055e-06,
      "loss": 0.1467,
      "step": 7840
    },
    {
      "epoch": 2.5363489499192244,
      "grad_norm": 4.597766876220703,
      "learning_rate": 7.73290253096392e-06,
      "loss": 0.217,
      "step": 7850
    },
    {
      "epoch": 2.5395799676898223,
      "grad_norm": 2.5922443866729736,
      "learning_rate": 7.679052234787292e-06,
      "loss": 0.1791,
      "step": 7860
    },
    {
      "epoch": 2.54281098546042,
      "grad_norm": 5.156345367431641,
      "learning_rate": 7.625201938610663e-06,
      "loss": 0.1806,
      "step": 7870
    },
    {
      "epoch": 2.546042003231018,
      "grad_norm": 4.177368640899658,
      "learning_rate": 7.571351642434034e-06,
      "loss": 0.1159,
      "step": 7880
    },
    {
      "epoch": 2.5492730210016155,
      "grad_norm": 1.7641513347625732,
      "learning_rate": 7.517501346257405e-06,
      "loss": 0.1391,
      "step": 7890
    },
    {
      "epoch": 2.5525040387722133,
      "grad_norm": 2.3837521076202393,
      "learning_rate": 7.463651050080776e-06,
      "loss": 0.2005,
      "step": 7900
    },
    {
      "epoch": 2.5557350565428107,
      "grad_norm": 0.3874976336956024,
      "learning_rate": 7.409800753904148e-06,
      "loss": 0.1464,
      "step": 7910
    },
    {
      "epoch": 2.5589660743134086,
      "grad_norm": 5.702009677886963,
      "learning_rate": 7.355950457727517e-06,
      "loss": 0.1169,
      "step": 7920
    },
    {
      "epoch": 2.5621970920840065,
      "grad_norm": 5.177280902862549,
      "learning_rate": 7.302100161550888e-06,
      "loss": 0.155,
      "step": 7930
    },
    {
      "epoch": 2.5654281098546043,
      "grad_norm": 3.585212469100952,
      "learning_rate": 7.24824986537426e-06,
      "loss": 0.1463,
      "step": 7940
    },
    {
      "epoch": 2.568659127625202,
      "grad_norm": 10.795221328735352,
      "learning_rate": 7.194399569197631e-06,
      "loss": 0.1461,
      "step": 7950
    },
    {
      "epoch": 2.5718901453957996,
      "grad_norm": 5.090578556060791,
      "learning_rate": 7.140549273021002e-06,
      "loss": 0.1207,
      "step": 7960
    },
    {
      "epoch": 2.5751211631663975,
      "grad_norm": 2.5015347003936768,
      "learning_rate": 7.086698976844373e-06,
      "loss": 0.1219,
      "step": 7970
    },
    {
      "epoch": 2.578352180936995,
      "grad_norm": 3.150416851043701,
      "learning_rate": 7.032848680667744e-06,
      "loss": 0.1211,
      "step": 7980
    },
    {
      "epoch": 2.581583198707593,
      "grad_norm": 1.9693617820739746,
      "learning_rate": 6.9789983844911144e-06,
      "loss": 0.1097,
      "step": 7990
    },
    {
      "epoch": 2.5848142164781907,
      "grad_norm": 16.478946685791016,
      "learning_rate": 6.9251480883144855e-06,
      "loss": 0.2313,
      "step": 8000
    },
    {
      "epoch": 2.5880452342487885,
      "grad_norm": 2.640983819961548,
      "learning_rate": 6.8712977921378565e-06,
      "loss": 0.1666,
      "step": 8010
    },
    {
      "epoch": 2.5912762520193864,
      "grad_norm": 6.027722358703613,
      "learning_rate": 6.817447495961228e-06,
      "loss": 0.1111,
      "step": 8020
    },
    {
      "epoch": 2.594507269789984,
      "grad_norm": 3.7563438415527344,
      "learning_rate": 6.7635971997845995e-06,
      "loss": 0.1271,
      "step": 8030
    },
    {
      "epoch": 2.5977382875605817,
      "grad_norm": 3.514388084411621,
      "learning_rate": 6.7097469036079705e-06,
      "loss": 0.1476,
      "step": 8040
    },
    {
      "epoch": 2.600969305331179,
      "grad_norm": 3.5392467975616455,
      "learning_rate": 6.6558966074313415e-06,
      "loss": 0.1074,
      "step": 8050
    },
    {
      "epoch": 2.604200323101777,
      "grad_norm": 3.5623178482055664,
      "learning_rate": 6.6020463112547126e-06,
      "loss": 0.1466,
      "step": 8060
    },
    {
      "epoch": 2.607431340872375,
      "grad_norm": 5.837624549865723,
      "learning_rate": 6.548196015078083e-06,
      "loss": 0.1672,
      "step": 8070
    },
    {
      "epoch": 2.6106623586429727,
      "grad_norm": 2.572343587875366,
      "learning_rate": 6.494345718901454e-06,
      "loss": 0.1581,
      "step": 8080
    },
    {
      "epoch": 2.61389337641357,
      "grad_norm": 5.351709842681885,
      "learning_rate": 6.440495422724825e-06,
      "loss": 0.1356,
      "step": 8090
    },
    {
      "epoch": 2.617124394184168,
      "grad_norm": 3.538238525390625,
      "learning_rate": 6.386645126548197e-06,
      "loss": 0.1571,
      "step": 8100
    },
    {
      "epoch": 2.620355411954766,
      "grad_norm": 2.886399745941162,
      "learning_rate": 6.332794830371568e-06,
      "loss": 0.2054,
      "step": 8110
    },
    {
      "epoch": 2.6235864297253633,
      "grad_norm": 3.048006534576416,
      "learning_rate": 6.278944534194939e-06,
      "loss": 0.149,
      "step": 8120
    },
    {
      "epoch": 2.626817447495961,
      "grad_norm": 2.052727222442627,
      "learning_rate": 6.225094238018309e-06,
      "loss": 0.0901,
      "step": 8130
    },
    {
      "epoch": 2.630048465266559,
      "grad_norm": 3.4168078899383545,
      "learning_rate": 6.171243941841681e-06,
      "loss": 0.1215,
      "step": 8140
    },
    {
      "epoch": 2.633279483037157,
      "grad_norm": 3.3606555461883545,
      "learning_rate": 6.117393645665052e-06,
      "loss": 0.1839,
      "step": 8150
    },
    {
      "epoch": 2.6365105008077543,
      "grad_norm": 2.6987781524658203,
      "learning_rate": 6.063543349488422e-06,
      "loss": 0.1997,
      "step": 8160
    },
    {
      "epoch": 2.639741518578352,
      "grad_norm": 1.517898678779602,
      "learning_rate": 6.009693053311793e-06,
      "loss": 0.1679,
      "step": 8170
    },
    {
      "epoch": 2.64297253634895,
      "grad_norm": 11.195014953613281,
      "learning_rate": 5.955842757135165e-06,
      "loss": 0.1288,
      "step": 8180
    },
    {
      "epoch": 2.6462035541195474,
      "grad_norm": 0.8956793546676636,
      "learning_rate": 5.901992460958536e-06,
      "loss": 0.1374,
      "step": 8190
    },
    {
      "epoch": 2.6494345718901453,
      "grad_norm": 3.6975598335266113,
      "learning_rate": 5.848142164781906e-06,
      "loss": 0.1743,
      "step": 8200
    },
    {
      "epoch": 2.652665589660743,
      "grad_norm": 3.6409292221069336,
      "learning_rate": 5.794291868605277e-06,
      "loss": 0.1226,
      "step": 8210
    },
    {
      "epoch": 2.655896607431341,
      "grad_norm": 3.754660129547119,
      "learning_rate": 5.740441572428648e-06,
      "loss": 0.1635,
      "step": 8220
    },
    {
      "epoch": 2.6591276252019385,
      "grad_norm": 3.4002373218536377,
      "learning_rate": 5.6865912762520194e-06,
      "loss": 0.1867,
      "step": 8230
    },
    {
      "epoch": 2.6623586429725363,
      "grad_norm": 3.0120856761932373,
      "learning_rate": 5.6327409800753905e-06,
      "loss": 0.1405,
      "step": 8240
    },
    {
      "epoch": 2.665589660743134,
      "grad_norm": 4.301506996154785,
      "learning_rate": 5.5788906838987615e-06,
      "loss": 0.1485,
      "step": 8250
    },
    {
      "epoch": 2.6688206785137316,
      "grad_norm": 2.610022783279419,
      "learning_rate": 5.5250403877221325e-06,
      "loss": 0.1128,
      "step": 8260
    },
    {
      "epoch": 2.6720516962843295,
      "grad_norm": 2.180542230606079,
      "learning_rate": 5.471190091545504e-06,
      "loss": 0.1409,
      "step": 8270
    },
    {
      "epoch": 2.6752827140549273,
      "grad_norm": 5.568445205688477,
      "learning_rate": 5.417339795368875e-06,
      "loss": 0.1906,
      "step": 8280
    },
    {
      "epoch": 2.678513731825525,
      "grad_norm": 3.3678224086761475,
      "learning_rate": 5.363489499192246e-06,
      "loss": 0.1588,
      "step": 8290
    },
    {
      "epoch": 2.6817447495961226,
      "grad_norm": 4.01224422454834,
      "learning_rate": 5.309639203015617e-06,
      "loss": 0.1777,
      "step": 8300
    },
    {
      "epoch": 2.6849757673667205,
      "grad_norm": 2.815232276916504,
      "learning_rate": 5.255788906838988e-06,
      "loss": 0.1573,
      "step": 8310
    },
    {
      "epoch": 2.6882067851373184,
      "grad_norm": 3.662761688232422,
      "learning_rate": 5.201938610662359e-06,
      "loss": 0.1765,
      "step": 8320
    },
    {
      "epoch": 2.691437802907916,
      "grad_norm": 3.8865294456481934,
      "learning_rate": 5.14808831448573e-06,
      "loss": 0.1268,
      "step": 8330
    },
    {
      "epoch": 2.6946688206785137,
      "grad_norm": 6.039398193359375,
      "learning_rate": 5.094238018309101e-06,
      "loss": 0.1456,
      "step": 8340
    },
    {
      "epoch": 2.6978998384491115,
      "grad_norm": 5.485719203948975,
      "learning_rate": 5.040387722132472e-06,
      "loss": 0.1887,
      "step": 8350
    },
    {
      "epoch": 2.7011308562197094,
      "grad_norm": 2.1398680210113525,
      "learning_rate": 4.986537425955843e-06,
      "loss": 0.116,
      "step": 8360
    },
    {
      "epoch": 2.704361873990307,
      "grad_norm": 4.011892795562744,
      "learning_rate": 4.932687129779214e-06,
      "loss": 0.1483,
      "step": 8370
    },
    {
      "epoch": 2.7075928917609047,
      "grad_norm": 3.5876080989837646,
      "learning_rate": 4.878836833602585e-06,
      "loss": 0.2119,
      "step": 8380
    },
    {
      "epoch": 2.7108239095315025,
      "grad_norm": 2.3834943771362305,
      "learning_rate": 4.824986537425956e-06,
      "loss": 0.1652,
      "step": 8390
    },
    {
      "epoch": 2.7140549273021,
      "grad_norm": 3.0189173221588135,
      "learning_rate": 4.771136241249327e-06,
      "loss": 0.116,
      "step": 8400
    },
    {
      "epoch": 2.717285945072698,
      "grad_norm": 2.84857177734375,
      "learning_rate": 4.717285945072698e-06,
      "loss": 0.1356,
      "step": 8410
    },
    {
      "epoch": 2.7205169628432957,
      "grad_norm": 4.22494649887085,
      "learning_rate": 4.663435648896069e-06,
      "loss": 0.1484,
      "step": 8420
    },
    {
      "epoch": 2.7237479806138936,
      "grad_norm": 3.7225310802459717,
      "learning_rate": 4.60958535271944e-06,
      "loss": 0.1385,
      "step": 8430
    },
    {
      "epoch": 2.726978998384491,
      "grad_norm": 4.38923454284668,
      "learning_rate": 4.555735056542811e-06,
      "loss": 0.1749,
      "step": 8440
    },
    {
      "epoch": 2.730210016155089,
      "grad_norm": 2.004328727722168,
      "learning_rate": 4.501884760366182e-06,
      "loss": 0.1609,
      "step": 8450
    },
    {
      "epoch": 2.7334410339256867,
      "grad_norm": 2.7023088932037354,
      "learning_rate": 4.448034464189553e-06,
      "loss": 0.1775,
      "step": 8460
    },
    {
      "epoch": 2.736672051696284,
      "grad_norm": 3.8118767738342285,
      "learning_rate": 4.394184168012924e-06,
      "loss": 0.1011,
      "step": 8470
    },
    {
      "epoch": 2.739903069466882,
      "grad_norm": 3.420659065246582,
      "learning_rate": 4.3403338718362954e-06,
      "loss": 0.1958,
      "step": 8480
    },
    {
      "epoch": 2.74313408723748,
      "grad_norm": 5.64076566696167,
      "learning_rate": 4.2864835756596665e-06,
      "loss": 0.1241,
      "step": 8490
    },
    {
      "epoch": 2.7463651050080777,
      "grad_norm": 1.5414416790008545,
      "learning_rate": 4.2326332794830375e-06,
      "loss": 0.1368,
      "step": 8500
    },
    {
      "epoch": 2.749596122778675,
      "grad_norm": 3.9050095081329346,
      "learning_rate": 4.1787829833064086e-06,
      "loss": 0.1483,
      "step": 8510
    },
    {
      "epoch": 2.752827140549273,
      "grad_norm": 4.584418296813965,
      "learning_rate": 4.12493268712978e-06,
      "loss": 0.1575,
      "step": 8520
    },
    {
      "epoch": 2.756058158319871,
      "grad_norm": 2.302233934402466,
      "learning_rate": 4.071082390953151e-06,
      "loss": 0.1359,
      "step": 8530
    },
    {
      "epoch": 2.7592891760904683,
      "grad_norm": 4.369805812835693,
      "learning_rate": 4.017232094776522e-06,
      "loss": 0.1273,
      "step": 8540
    },
    {
      "epoch": 2.762520193861066,
      "grad_norm": 2.952127695083618,
      "learning_rate": 3.963381798599893e-06,
      "loss": 0.12,
      "step": 8550
    },
    {
      "epoch": 2.765751211631664,
      "grad_norm": 5.84299898147583,
      "learning_rate": 3.909531502423264e-06,
      "loss": 0.1599,
      "step": 8560
    },
    {
      "epoch": 2.768982229402262,
      "grad_norm": 2.9140284061431885,
      "learning_rate": 3.855681206246634e-06,
      "loss": 0.1532,
      "step": 8570
    },
    {
      "epoch": 2.7722132471728593,
      "grad_norm": 2.772942304611206,
      "learning_rate": 3.8018309100700054e-06,
      "loss": 0.1418,
      "step": 8580
    },
    {
      "epoch": 2.775444264943457,
      "grad_norm": 1.9513009786605835,
      "learning_rate": 3.7479806138933765e-06,
      "loss": 0.1592,
      "step": 8590
    },
    {
      "epoch": 2.778675282714055,
      "grad_norm": 4.091526031494141,
      "learning_rate": 3.694130317716748e-06,
      "loss": 0.1071,
      "step": 8600
    },
    {
      "epoch": 2.7819063004846525,
      "grad_norm": 4.6003241539001465,
      "learning_rate": 3.6402800215401186e-06,
      "loss": 0.134,
      "step": 8610
    },
    {
      "epoch": 2.7851373182552503,
      "grad_norm": 3.4858193397521973,
      "learning_rate": 3.5864297253634896e-06,
      "loss": 0.1726,
      "step": 8620
    },
    {
      "epoch": 2.788368336025848,
      "grad_norm": 7.191484451293945,
      "learning_rate": 3.5325794291868606e-06,
      "loss": 0.1416,
      "step": 8630
    },
    {
      "epoch": 2.791599353796446,
      "grad_norm": 1.735489010810852,
      "learning_rate": 3.478729133010232e-06,
      "loss": 0.179,
      "step": 8640
    },
    {
      "epoch": 2.7948303715670435,
      "grad_norm": 3.4895317554473877,
      "learning_rate": 3.4248788368336027e-06,
      "loss": 0.1378,
      "step": 8650
    },
    {
      "epoch": 2.7980613893376414,
      "grad_norm": 2.942540407180786,
      "learning_rate": 3.3710285406569738e-06,
      "loss": 0.1312,
      "step": 8660
    },
    {
      "epoch": 2.8012924071082392,
      "grad_norm": 3.5204904079437256,
      "learning_rate": 3.317178244480345e-06,
      "loss": 0.1385,
      "step": 8670
    },
    {
      "epoch": 2.8045234248788367,
      "grad_norm": 8.086026191711426,
      "learning_rate": 3.2633279483037163e-06,
      "loss": 0.1792,
      "step": 8680
    },
    {
      "epoch": 2.8077544426494345,
      "grad_norm": 4.14892053604126,
      "learning_rate": 3.209477652127087e-06,
      "loss": 0.1629,
      "step": 8690
    },
    {
      "epoch": 2.8109854604200324,
      "grad_norm": 9.180904388427734,
      "learning_rate": 3.155627355950458e-06,
      "loss": 0.1423,
      "step": 8700
    },
    {
      "epoch": 2.8142164781906303,
      "grad_norm": 3.043846845626831,
      "learning_rate": 3.1017770597738285e-06,
      "loss": 0.1442,
      "step": 8710
    },
    {
      "epoch": 2.8174474959612277,
      "grad_norm": 5.004662036895752,
      "learning_rate": 3.0479267635972e-06,
      "loss": 0.1864,
      "step": 8720
    },
    {
      "epoch": 2.8206785137318255,
      "grad_norm": 3.6084144115448,
      "learning_rate": 2.9940764674205706e-06,
      "loss": 0.1635,
      "step": 8730
    },
    {
      "epoch": 2.8239095315024234,
      "grad_norm": 3.9359304904937744,
      "learning_rate": 2.940226171243942e-06,
      "loss": 0.1394,
      "step": 8740
    },
    {
      "epoch": 2.827140549273021,
      "grad_norm": 3.218871593475342,
      "learning_rate": 2.8863758750673127e-06,
      "loss": 0.138,
      "step": 8750
    },
    {
      "epoch": 2.8303715670436187,
      "grad_norm": 1.6579891443252563,
      "learning_rate": 2.832525578890684e-06,
      "loss": 0.1073,
      "step": 8760
    },
    {
      "epoch": 2.8336025848142166,
      "grad_norm": 2.630061388015747,
      "learning_rate": 2.778675282714055e-06,
      "loss": 0.1276,
      "step": 8770
    },
    {
      "epoch": 2.8368336025848144,
      "grad_norm": 3.840949058532715,
      "learning_rate": 2.7248249865374263e-06,
      "loss": 0.1482,
      "step": 8780
    },
    {
      "epoch": 2.840064620355412,
      "grad_norm": 3.2689292430877686,
      "learning_rate": 2.670974690360797e-06,
      "loss": 0.1074,
      "step": 8790
    },
    {
      "epoch": 2.8432956381260097,
      "grad_norm": 1.2886056900024414,
      "learning_rate": 2.6171243941841683e-06,
      "loss": 0.1875,
      "step": 8800
    },
    {
      "epoch": 2.8465266558966076,
      "grad_norm": 1.8959859609603882,
      "learning_rate": 2.563274098007539e-06,
      "loss": 0.139,
      "step": 8810
    },
    {
      "epoch": 2.849757673667205,
      "grad_norm": 1.423194408416748,
      "learning_rate": 2.5094238018309104e-06,
      "loss": 0.1182,
      "step": 8820
    },
    {
      "epoch": 2.852988691437803,
      "grad_norm": 3.3883426189422607,
      "learning_rate": 2.455573505654281e-06,
      "loss": 0.153,
      "step": 8830
    },
    {
      "epoch": 2.8562197092084007,
      "grad_norm": 5.065515518188477,
      "learning_rate": 2.4017232094776525e-06,
      "loss": 0.1589,
      "step": 8840
    },
    {
      "epoch": 2.8594507269789986,
      "grad_norm": 3.8002402782440186,
      "learning_rate": 2.347872913301023e-06,
      "loss": 0.1542,
      "step": 8850
    },
    {
      "epoch": 2.862681744749596,
      "grad_norm": 1.8810588121414185,
      "learning_rate": 2.294022617124394e-06,
      "loss": 0.1059,
      "step": 8860
    },
    {
      "epoch": 2.865912762520194,
      "grad_norm": 3.4953129291534424,
      "learning_rate": 2.240172320947765e-06,
      "loss": 0.222,
      "step": 8870
    },
    {
      "epoch": 2.8691437802907918,
      "grad_norm": 3.034600019454956,
      "learning_rate": 2.1863220247711362e-06,
      "loss": 0.2093,
      "step": 8880
    },
    {
      "epoch": 2.872374798061389,
      "grad_norm": 4.016815185546875,
      "learning_rate": 2.1324717285945073e-06,
      "loss": 0.1513,
      "step": 8890
    },
    {
      "epoch": 2.875605815831987,
      "grad_norm": 4.629176139831543,
      "learning_rate": 2.0786214324178783e-06,
      "loss": 0.1599,
      "step": 8900
    },
    {
      "epoch": 2.878836833602585,
      "grad_norm": 2.8473293781280518,
      "learning_rate": 2.0247711362412494e-06,
      "loss": 0.08,
      "step": 8910
    },
    {
      "epoch": 2.8820678513731828,
      "grad_norm": 3.6309456825256348,
      "learning_rate": 1.9709208400646204e-06,
      "loss": 0.159,
      "step": 8920
    },
    {
      "epoch": 2.88529886914378,
      "grad_norm": 3.2165110111236572,
      "learning_rate": 1.9170705438879914e-06,
      "loss": 0.1517,
      "step": 8930
    },
    {
      "epoch": 2.888529886914378,
      "grad_norm": 3.588094472885132,
      "learning_rate": 1.8632202477113625e-06,
      "loss": 0.1321,
      "step": 8940
    },
    {
      "epoch": 2.891760904684976,
      "grad_norm": 2.222195863723755,
      "learning_rate": 1.8093699515347337e-06,
      "loss": 0.1206,
      "step": 8950
    },
    {
      "epoch": 2.8949919224555734,
      "grad_norm": 3.270918130874634,
      "learning_rate": 1.7555196553581046e-06,
      "loss": 0.1173,
      "step": 8960
    },
    {
      "epoch": 2.898222940226171,
      "grad_norm": 1.7314953804016113,
      "learning_rate": 1.7016693591814756e-06,
      "loss": 0.1444,
      "step": 8970
    },
    {
      "epoch": 2.901453957996769,
      "grad_norm": 4.009300231933594,
      "learning_rate": 1.6478190630048467e-06,
      "loss": 0.1446,
      "step": 8980
    },
    {
      "epoch": 2.904684975767367,
      "grad_norm": 3.1888890266418457,
      "learning_rate": 1.5939687668282177e-06,
      "loss": 0.1231,
      "step": 8990
    },
    {
      "epoch": 2.9079159935379644,
      "grad_norm": 5.577599048614502,
      "learning_rate": 1.5401184706515887e-06,
      "loss": 0.1628,
      "step": 9000
    },
    {
      "epoch": 2.9111470113085622,
      "grad_norm": 4.326919078826904,
      "learning_rate": 1.4862681744749598e-06,
      "loss": 0.1191,
      "step": 9010
    },
    {
      "epoch": 2.9143780290791597,
      "grad_norm": 5.417238712310791,
      "learning_rate": 1.4324178782983308e-06,
      "loss": 0.1298,
      "step": 9020
    },
    {
      "epoch": 2.9176090468497575,
      "grad_norm": 4.180749893188477,
      "learning_rate": 1.3785675821217019e-06,
      "loss": 0.1182,
      "step": 9030
    },
    {
      "epoch": 2.9208400646203554,
      "grad_norm": 6.489224433898926,
      "learning_rate": 1.324717285945073e-06,
      "loss": 0.178,
      "step": 9040
    },
    {
      "epoch": 2.9240710823909533,
      "grad_norm": 6.457488059997559,
      "learning_rate": 1.270866989768444e-06,
      "loss": 0.1576,
      "step": 9050
    },
    {
      "epoch": 2.927302100161551,
      "grad_norm": 4.485931396484375,
      "learning_rate": 1.2170166935918148e-06,
      "loss": 0.1521,
      "step": 9060
    },
    {
      "epoch": 2.9305331179321485,
      "grad_norm": 3.7466681003570557,
      "learning_rate": 1.1631663974151858e-06,
      "loss": 0.117,
      "step": 9070
    },
    {
      "epoch": 2.9337641357027464,
      "grad_norm": 3.5305941104888916,
      "learning_rate": 1.1093161012385569e-06,
      "loss": 0.1583,
      "step": 9080
    },
    {
      "epoch": 2.936995153473344,
      "grad_norm": 4.031449317932129,
      "learning_rate": 1.0554658050619279e-06,
      "loss": 0.1463,
      "step": 9090
    },
    {
      "epoch": 2.9402261712439417,
      "grad_norm": 2.286595106124878,
      "learning_rate": 1.001615508885299e-06,
      "loss": 0.1003,
      "step": 9100
    },
    {
      "epoch": 2.9434571890145396,
      "grad_norm": 4.662479400634766,
      "learning_rate": 9.477652127086699e-07,
      "loss": 0.1173,
      "step": 9110
    },
    {
      "epoch": 2.9466882067851374,
      "grad_norm": 1.9779536724090576,
      "learning_rate": 8.939149165320409e-07,
      "loss": 0.127,
      "step": 9120
    },
    {
      "epoch": 2.9499192245557353,
      "grad_norm": 6.518853187561035,
      "learning_rate": 8.40064620355412e-07,
      "loss": 0.1602,
      "step": 9130
    },
    {
      "epoch": 2.9531502423263327,
      "grad_norm": 5.583995819091797,
      "learning_rate": 7.86214324178783e-07,
      "loss": 0.1328,
      "step": 9140
    },
    {
      "epoch": 2.9563812600969306,
      "grad_norm": 4.3496880531311035,
      "learning_rate": 7.32364028002154e-07,
      "loss": 0.1651,
      "step": 9150
    },
    {
      "epoch": 2.959612277867528,
      "grad_norm": 2.0987510681152344,
      "learning_rate": 6.785137318255251e-07,
      "loss": 0.1553,
      "step": 9160
    },
    {
      "epoch": 2.962843295638126,
      "grad_norm": 5.45397424697876,
      "learning_rate": 6.246634356488961e-07,
      "loss": 0.1534,
      "step": 9170
    },
    {
      "epoch": 2.9660743134087237,
      "grad_norm": 3.2964258193969727,
      "learning_rate": 5.708131394722672e-07,
      "loss": 0.14,
      "step": 9180
    },
    {
      "epoch": 2.9693053311793216,
      "grad_norm": 6.001625061035156,
      "learning_rate": 5.169628432956382e-07,
      "loss": 0.1725,
      "step": 9190
    },
    {
      "epoch": 2.9725363489499195,
      "grad_norm": 2.820589303970337,
      "learning_rate": 4.6311254711900924e-07,
      "loss": 0.1417,
      "step": 9200
    },
    {
      "epoch": 2.975767366720517,
      "grad_norm": 5.531758785247803,
      "learning_rate": 4.0926225094238017e-07,
      "loss": 0.151,
      "step": 9210
    },
    {
      "epoch": 2.9789983844911148,
      "grad_norm": 4.201934337615967,
      "learning_rate": 3.554119547657512e-07,
      "loss": 0.1543,
      "step": 9220
    },
    {
      "epoch": 2.982229402261712,
      "grad_norm": 2.1736459732055664,
      "learning_rate": 3.0156165858912226e-07,
      "loss": 0.1178,
      "step": 9230
    },
    {
      "epoch": 2.98546042003231,
      "grad_norm": 12.747474670410156,
      "learning_rate": 2.477113624124933e-07,
      "loss": 0.1176,
      "step": 9240
    },
    {
      "epoch": 2.988691437802908,
      "grad_norm": 3.4133763313293457,
      "learning_rate": 1.9386106623586428e-07,
      "loss": 0.1403,
      "step": 9250
    },
    {
      "epoch": 2.991922455573506,
      "grad_norm": 4.7978668212890625,
      "learning_rate": 1.4001077005923533e-07,
      "loss": 0.1626,
      "step": 9260
    },
    {
      "epoch": 2.9951534733441036,
      "grad_norm": 2.3619542121887207,
      "learning_rate": 8.616047388260637e-08,
      "loss": 0.1211,
      "step": 9270
    },
    {
      "epoch": 2.998384491114701,
      "grad_norm": 3.6097607612609863,
      "learning_rate": 3.231017770597739e-08,
      "loss": 0.1667,
      "step": 9280
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.7322298288345337,
      "eval_runtime": 31.9999,
      "eval_samples_per_second": 21.5,
      "eval_steps_per_second": 10.75,
      "step": 9285
    }
  ],
  "logging_steps": 10,
  "max_steps": 9285,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.011831557370675e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
