{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 3095,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0032310177705977385,
      "grad_norm": 34.0753173828125,
      "learning_rate": 4.9951534733441036e-05,
      "loss": 6.0805,
      "step": 10
    },
    {
      "epoch": 0.006462035541195477,
      "grad_norm": 17.43198013305664,
      "learning_rate": 4.9897684437264406e-05,
      "loss": 1.4963,
      "step": 20
    },
    {
      "epoch": 0.009693053311793215,
      "grad_norm": 10.218494415283203,
      "learning_rate": 4.984383414108778e-05,
      "loss": 0.8785,
      "step": 30
    },
    {
      "epoch": 0.012924071082390954,
      "grad_norm": 10.021735191345215,
      "learning_rate": 4.9789983844911146e-05,
      "loss": 0.8844,
      "step": 40
    },
    {
      "epoch": 0.01615508885298869,
      "grad_norm": 10.396621704101562,
      "learning_rate": 4.973613354873452e-05,
      "loss": 0.6746,
      "step": 50
    },
    {
      "epoch": 0.01938610662358643,
      "grad_norm": 6.229109764099121,
      "learning_rate": 4.968228325255789e-05,
      "loss": 0.6948,
      "step": 60
    },
    {
      "epoch": 0.022617124394184167,
      "grad_norm": 8.677510261535645,
      "learning_rate": 4.962843295638126e-05,
      "loss": 0.6282,
      "step": 70
    },
    {
      "epoch": 0.025848142164781908,
      "grad_norm": 5.078341484069824,
      "learning_rate": 4.9574582660204634e-05,
      "loss": 0.8092,
      "step": 80
    },
    {
      "epoch": 0.029079159935379646,
      "grad_norm": 8.823516845703125,
      "learning_rate": 4.9520732364028004e-05,
      "loss": 0.7702,
      "step": 90
    },
    {
      "epoch": 0.03231017770597738,
      "grad_norm": 9.344785690307617,
      "learning_rate": 4.946688206785138e-05,
      "loss": 0.771,
      "step": 100
    },
    {
      "epoch": 0.035541195476575124,
      "grad_norm": 9.899773597717285,
      "learning_rate": 4.9413031771674744e-05,
      "loss": 0.7513,
      "step": 110
    },
    {
      "epoch": 0.03877221324717286,
      "grad_norm": 4.770247936248779,
      "learning_rate": 4.9359181475498114e-05,
      "loss": 0.8725,
      "step": 120
    },
    {
      "epoch": 0.0420032310177706,
      "grad_norm": 8.954900741577148,
      "learning_rate": 4.930533117932149e-05,
      "loss": 0.6456,
      "step": 130
    },
    {
      "epoch": 0.045234248788368334,
      "grad_norm": 7.731972694396973,
      "learning_rate": 4.9251480883144855e-05,
      "loss": 0.8212,
      "step": 140
    },
    {
      "epoch": 0.048465266558966075,
      "grad_norm": 8.727777481079102,
      "learning_rate": 4.919763058696823e-05,
      "loss": 0.8216,
      "step": 150
    },
    {
      "epoch": 0.051696284329563816,
      "grad_norm": 7.132745742797852,
      "learning_rate": 4.91437802907916e-05,
      "loss": 0.6854,
      "step": 160
    },
    {
      "epoch": 0.05492730210016155,
      "grad_norm": 6.953613758087158,
      "learning_rate": 4.908992999461497e-05,
      "loss": 0.7559,
      "step": 170
    },
    {
      "epoch": 0.05815831987075929,
      "grad_norm": 6.949471473693848,
      "learning_rate": 4.903607969843834e-05,
      "loss": 0.6783,
      "step": 180
    },
    {
      "epoch": 0.061389337641357025,
      "grad_norm": 5.419915676116943,
      "learning_rate": 4.898222940226171e-05,
      "loss": 0.7272,
      "step": 190
    },
    {
      "epoch": 0.06462035541195477,
      "grad_norm": 5.572080135345459,
      "learning_rate": 4.892837910608509e-05,
      "loss": 0.6984,
      "step": 200
    },
    {
      "epoch": 0.06785137318255251,
      "grad_norm": 4.152251243591309,
      "learning_rate": 4.887452880990845e-05,
      "loss": 0.6364,
      "step": 210
    },
    {
      "epoch": 0.07108239095315025,
      "grad_norm": 4.543114185333252,
      "learning_rate": 4.882067851373183e-05,
      "loss": 0.5163,
      "step": 220
    },
    {
      "epoch": 0.07431340872374798,
      "grad_norm": 7.520122051239014,
      "learning_rate": 4.87668282175552e-05,
      "loss": 0.7731,
      "step": 230
    },
    {
      "epoch": 0.07754442649434572,
      "grad_norm": 8.398537635803223,
      "learning_rate": 4.871297792137857e-05,
      "loss": 0.6554,
      "step": 240
    },
    {
      "epoch": 0.08077544426494346,
      "grad_norm": 5.979633331298828,
      "learning_rate": 4.865912762520194e-05,
      "loss": 0.57,
      "step": 250
    },
    {
      "epoch": 0.0840064620355412,
      "grad_norm": 8.134841918945312,
      "learning_rate": 4.860527732902531e-05,
      "loss": 0.7389,
      "step": 260
    },
    {
      "epoch": 0.08723747980613894,
      "grad_norm": 6.747562408447266,
      "learning_rate": 4.855142703284868e-05,
      "loss": 0.782,
      "step": 270
    },
    {
      "epoch": 0.09046849757673667,
      "grad_norm": 8.840903282165527,
      "learning_rate": 4.849757673667205e-05,
      "loss": 0.6765,
      "step": 280
    },
    {
      "epoch": 0.09369951534733441,
      "grad_norm": 7.44451379776001,
      "learning_rate": 4.844372644049542e-05,
      "loss": 0.6815,
      "step": 290
    },
    {
      "epoch": 0.09693053311793215,
      "grad_norm": 7.596870422363281,
      "learning_rate": 4.83898761443188e-05,
      "loss": 0.579,
      "step": 300
    },
    {
      "epoch": 0.10016155088852989,
      "grad_norm": 6.126553535461426,
      "learning_rate": 4.833602584814217e-05,
      "loss": 0.6172,
      "step": 310
    },
    {
      "epoch": 0.10339256865912763,
      "grad_norm": 5.047300815582275,
      "learning_rate": 4.828217555196554e-05,
      "loss": 0.6803,
      "step": 320
    },
    {
      "epoch": 0.10662358642972536,
      "grad_norm": 4.315315246582031,
      "learning_rate": 4.822832525578891e-05,
      "loss": 0.5842,
      "step": 330
    },
    {
      "epoch": 0.1098546042003231,
      "grad_norm": 6.132907867431641,
      "learning_rate": 4.817447495961228e-05,
      "loss": 0.6585,
      "step": 340
    },
    {
      "epoch": 0.11308562197092084,
      "grad_norm": 7.39940071105957,
      "learning_rate": 4.8120624663435656e-05,
      "loss": 0.6464,
      "step": 350
    },
    {
      "epoch": 0.11631663974151858,
      "grad_norm": 11.19018268585205,
      "learning_rate": 4.806677436725902e-05,
      "loss": 0.6052,
      "step": 360
    },
    {
      "epoch": 0.11954765751211632,
      "grad_norm": 5.490081310272217,
      "learning_rate": 4.8012924071082396e-05,
      "loss": 0.7056,
      "step": 370
    },
    {
      "epoch": 0.12277867528271405,
      "grad_norm": 5.816595554351807,
      "learning_rate": 4.795907377490577e-05,
      "loss": 0.6664,
      "step": 380
    },
    {
      "epoch": 0.1260096930533118,
      "grad_norm": 5.5861310958862305,
      "learning_rate": 4.790522347872913e-05,
      "loss": 0.5473,
      "step": 390
    },
    {
      "epoch": 0.12924071082390953,
      "grad_norm": 5.677304267883301,
      "learning_rate": 4.785137318255251e-05,
      "loss": 0.7861,
      "step": 400
    },
    {
      "epoch": 0.13247172859450726,
      "grad_norm": 5.45418119430542,
      "learning_rate": 4.779752288637588e-05,
      "loss": 0.6849,
      "step": 410
    },
    {
      "epoch": 0.13570274636510501,
      "grad_norm": 5.886417388916016,
      "learning_rate": 4.7743672590199254e-05,
      "loss": 0.6443,
      "step": 420
    },
    {
      "epoch": 0.13893376413570274,
      "grad_norm": 9.187479972839355,
      "learning_rate": 4.768982229402262e-05,
      "loss": 0.6366,
      "step": 430
    },
    {
      "epoch": 0.1421647819063005,
      "grad_norm": 6.043044567108154,
      "learning_rate": 4.763597199784599e-05,
      "loss": 0.6619,
      "step": 440
    },
    {
      "epoch": 0.14539579967689822,
      "grad_norm": 4.649696350097656,
      "learning_rate": 4.7582121701669365e-05,
      "loss": 0.797,
      "step": 450
    },
    {
      "epoch": 0.14862681744749595,
      "grad_norm": 7.0474629402160645,
      "learning_rate": 4.752827140549273e-05,
      "loss": 0.6499,
      "step": 460
    },
    {
      "epoch": 0.1518578352180937,
      "grad_norm": 4.192047119140625,
      "learning_rate": 4.7474421109316105e-05,
      "loss": 0.5539,
      "step": 470
    },
    {
      "epoch": 0.15508885298869143,
      "grad_norm": 7.474441051483154,
      "learning_rate": 4.7420570813139475e-05,
      "loss": 0.7941,
      "step": 480
    },
    {
      "epoch": 0.1583198707592892,
      "grad_norm": 4.800999164581299,
      "learning_rate": 4.7366720516962846e-05,
      "loss": 0.5504,
      "step": 490
    },
    {
      "epoch": 0.16155088852988692,
      "grad_norm": 8.753898620605469,
      "learning_rate": 4.7312870220786216e-05,
      "loss": 0.6171,
      "step": 500
    },
    {
      "epoch": 0.16478190630048464,
      "grad_norm": 6.092473983764648,
      "learning_rate": 4.7259019924609586e-05,
      "loss": 0.561,
      "step": 510
    },
    {
      "epoch": 0.1680129240710824,
      "grad_norm": 6.263099193572998,
      "learning_rate": 4.720516962843296e-05,
      "loss": 0.5916,
      "step": 520
    },
    {
      "epoch": 0.17124394184168013,
      "grad_norm": 8.457779884338379,
      "learning_rate": 4.7151319332256326e-05,
      "loss": 0.6263,
      "step": 530
    },
    {
      "epoch": 0.17447495961227788,
      "grad_norm": 4.0908331871032715,
      "learning_rate": 4.70974690360797e-05,
      "loss": 0.6554,
      "step": 540
    },
    {
      "epoch": 0.1777059773828756,
      "grad_norm": 4.279803276062012,
      "learning_rate": 4.7043618739903073e-05,
      "loss": 0.7109,
      "step": 550
    },
    {
      "epoch": 0.18093699515347333,
      "grad_norm": 5.417016506195068,
      "learning_rate": 4.6989768443726444e-05,
      "loss": 0.6019,
      "step": 560
    },
    {
      "epoch": 0.1841680129240711,
      "grad_norm": 5.828342914581299,
      "learning_rate": 4.6935918147549814e-05,
      "loss": 0.7134,
      "step": 570
    },
    {
      "epoch": 0.18739903069466882,
      "grad_norm": 4.591030597686768,
      "learning_rate": 4.6882067851373184e-05,
      "loss": 0.7083,
      "step": 580
    },
    {
      "epoch": 0.19063004846526657,
      "grad_norm": 5.88403844833374,
      "learning_rate": 4.6828217555196554e-05,
      "loss": 0.698,
      "step": 590
    },
    {
      "epoch": 0.1938610662358643,
      "grad_norm": 7.931091785430908,
      "learning_rate": 4.6774367259019924e-05,
      "loss": 0.6515,
      "step": 600
    },
    {
      "epoch": 0.19709208400646203,
      "grad_norm": 6.014880657196045,
      "learning_rate": 4.6720516962843295e-05,
      "loss": 0.6566,
      "step": 610
    },
    {
      "epoch": 0.20032310177705978,
      "grad_norm": 7.409234046936035,
      "learning_rate": 4.666666666666667e-05,
      "loss": 0.6507,
      "step": 620
    },
    {
      "epoch": 0.2035541195476575,
      "grad_norm": 6.342907428741455,
      "learning_rate": 4.661281637049004e-05,
      "loss": 0.5796,
      "step": 630
    },
    {
      "epoch": 0.20678513731825526,
      "grad_norm": 6.366989612579346,
      "learning_rate": 4.655896607431341e-05,
      "loss": 0.716,
      "step": 640
    },
    {
      "epoch": 0.210016155088853,
      "grad_norm": 5.631803512573242,
      "learning_rate": 4.650511577813678e-05,
      "loss": 0.6638,
      "step": 650
    },
    {
      "epoch": 0.21324717285945072,
      "grad_norm": 4.203280448913574,
      "learning_rate": 4.645126548196015e-05,
      "loss": 0.5892,
      "step": 660
    },
    {
      "epoch": 0.21647819063004847,
      "grad_norm": 6.56283712387085,
      "learning_rate": 4.639741518578352e-05,
      "loss": 0.605,
      "step": 670
    },
    {
      "epoch": 0.2197092084006462,
      "grad_norm": 6.640733242034912,
      "learning_rate": 4.634356488960689e-05,
      "loss": 0.8735,
      "step": 680
    },
    {
      "epoch": 0.22294022617124395,
      "grad_norm": 5.294511795043945,
      "learning_rate": 4.628971459343027e-05,
      "loss": 0.6706,
      "step": 690
    },
    {
      "epoch": 0.22617124394184168,
      "grad_norm": 8.261088371276855,
      "learning_rate": 4.623586429725364e-05,
      "loss": 0.6751,
      "step": 700
    },
    {
      "epoch": 0.2294022617124394,
      "grad_norm": 3.81868314743042,
      "learning_rate": 4.6182014001077e-05,
      "loss": 0.685,
      "step": 710
    },
    {
      "epoch": 0.23263327948303716,
      "grad_norm": 10.138895988464355,
      "learning_rate": 4.612816370490038e-05,
      "loss": 0.6219,
      "step": 720
    },
    {
      "epoch": 0.2358642972536349,
      "grad_norm": 7.007048606872559,
      "learning_rate": 4.607431340872375e-05,
      "loss": 0.6654,
      "step": 730
    },
    {
      "epoch": 0.23909531502423265,
      "grad_norm": 5.96441650390625,
      "learning_rate": 4.602046311254712e-05,
      "loss": 0.6903,
      "step": 740
    },
    {
      "epoch": 0.24232633279483037,
      "grad_norm": 6.107661724090576,
      "learning_rate": 4.596661281637049e-05,
      "loss": 0.6404,
      "step": 750
    },
    {
      "epoch": 0.2455573505654281,
      "grad_norm": 5.454407215118408,
      "learning_rate": 4.591276252019386e-05,
      "loss": 0.6349,
      "step": 760
    },
    {
      "epoch": 0.24878836833602586,
      "grad_norm": 4.563236236572266,
      "learning_rate": 4.585891222401724e-05,
      "loss": 0.7557,
      "step": 770
    },
    {
      "epoch": 0.2520193861066236,
      "grad_norm": 6.125796318054199,
      "learning_rate": 4.58050619278406e-05,
      "loss": 0.6683,
      "step": 780
    },
    {
      "epoch": 0.2552504038772213,
      "grad_norm": 4.779496192932129,
      "learning_rate": 4.575121163166398e-05,
      "loss": 0.609,
      "step": 790
    },
    {
      "epoch": 0.25848142164781907,
      "grad_norm": 5.258349418640137,
      "learning_rate": 4.569736133548735e-05,
      "loss": 0.6984,
      "step": 800
    },
    {
      "epoch": 0.2617124394184168,
      "grad_norm": 4.948271751403809,
      "learning_rate": 4.564351103931072e-05,
      "loss": 0.623,
      "step": 810
    },
    {
      "epoch": 0.2649434571890145,
      "grad_norm": 5.9449639320373535,
      "learning_rate": 4.558966074313409e-05,
      "loss": 0.6516,
      "step": 820
    },
    {
      "epoch": 0.2681744749596123,
      "grad_norm": 5.46173095703125,
      "learning_rate": 4.553581044695746e-05,
      "loss": 0.5932,
      "step": 830
    },
    {
      "epoch": 0.27140549273021003,
      "grad_norm": 7.43815279006958,
      "learning_rate": 4.5481960150780836e-05,
      "loss": 0.7513,
      "step": 840
    },
    {
      "epoch": 0.27463651050080773,
      "grad_norm": 10.136825561523438,
      "learning_rate": 4.54281098546042e-05,
      "loss": 0.5615,
      "step": 850
    },
    {
      "epoch": 0.2778675282714055,
      "grad_norm": 6.646399974822998,
      "learning_rate": 4.537425955842757e-05,
      "loss": 0.6255,
      "step": 860
    },
    {
      "epoch": 0.28109854604200324,
      "grad_norm": 4.491087436676025,
      "learning_rate": 4.532040926225095e-05,
      "loss": 0.7445,
      "step": 870
    },
    {
      "epoch": 0.284329563812601,
      "grad_norm": 8.246696472167969,
      "learning_rate": 4.526655896607432e-05,
      "loss": 0.7707,
      "step": 880
    },
    {
      "epoch": 0.2875605815831987,
      "grad_norm": 5.700790882110596,
      "learning_rate": 4.521270866989769e-05,
      "loss": 0.7866,
      "step": 890
    },
    {
      "epoch": 0.29079159935379645,
      "grad_norm": 4.993128776550293,
      "learning_rate": 4.515885837372106e-05,
      "loss": 0.7403,
      "step": 900
    },
    {
      "epoch": 0.2940226171243942,
      "grad_norm": 8.98244571685791,
      "learning_rate": 4.510500807754443e-05,
      "loss": 0.6067,
      "step": 910
    },
    {
      "epoch": 0.2972536348949919,
      "grad_norm": 6.367303371429443,
      "learning_rate": 4.50511577813678e-05,
      "loss": 0.6465,
      "step": 920
    },
    {
      "epoch": 0.30048465266558966,
      "grad_norm": 5.947965145111084,
      "learning_rate": 4.499730748519117e-05,
      "loss": 0.697,
      "step": 930
    },
    {
      "epoch": 0.3037156704361874,
      "grad_norm": 6.025789737701416,
      "learning_rate": 4.4943457189014545e-05,
      "loss": 0.5661,
      "step": 940
    },
    {
      "epoch": 0.3069466882067851,
      "grad_norm": 3.880239248275757,
      "learning_rate": 4.4889606892837915e-05,
      "loss": 0.6072,
      "step": 950
    },
    {
      "epoch": 0.31017770597738287,
      "grad_norm": 5.827055931091309,
      "learning_rate": 4.4835756596661285e-05,
      "loss": 0.6964,
      "step": 960
    },
    {
      "epoch": 0.3134087237479806,
      "grad_norm": 5.009071350097656,
      "learning_rate": 4.4781906300484656e-05,
      "loss": 0.6829,
      "step": 970
    },
    {
      "epoch": 0.3166397415185784,
      "grad_norm": 6.982411861419678,
      "learning_rate": 4.4728056004308026e-05,
      "loss": 0.571,
      "step": 980
    },
    {
      "epoch": 0.3198707592891761,
      "grad_norm": 5.275861740112305,
      "learning_rate": 4.4674205708131396e-05,
      "loss": 0.5833,
      "step": 990
    },
    {
      "epoch": 0.32310177705977383,
      "grad_norm": 3.115532636642456,
      "learning_rate": 4.4620355411954766e-05,
      "loss": 0.6333,
      "step": 1000
    },
    {
      "epoch": 0.3263327948303716,
      "grad_norm": 4.905674934387207,
      "learning_rate": 4.456650511577814e-05,
      "loss": 0.6031,
      "step": 1010
    },
    {
      "epoch": 0.3295638126009693,
      "grad_norm": 6.972469806671143,
      "learning_rate": 4.451265481960151e-05,
      "loss": 0.6781,
      "step": 1020
    },
    {
      "epoch": 0.33279483037156704,
      "grad_norm": 3.9800636768341064,
      "learning_rate": 4.445880452342488e-05,
      "loss": 0.655,
      "step": 1030
    },
    {
      "epoch": 0.3360258481421648,
      "grad_norm": 7.3007283210754395,
      "learning_rate": 4.4404954227248254e-05,
      "loss": 0.7034,
      "step": 1040
    },
    {
      "epoch": 0.3392568659127625,
      "grad_norm": 5.7714924812316895,
      "learning_rate": 4.4351103931071624e-05,
      "loss": 0.6311,
      "step": 1050
    },
    {
      "epoch": 0.34248788368336025,
      "grad_norm": 7.213589668273926,
      "learning_rate": 4.4297253634894994e-05,
      "loss": 0.5714,
      "step": 1060
    },
    {
      "epoch": 0.345718901453958,
      "grad_norm": 3.5361251831054688,
      "learning_rate": 4.4243403338718364e-05,
      "loss": 0.6268,
      "step": 1070
    },
    {
      "epoch": 0.34894991922455576,
      "grad_norm": 6.756217002868652,
      "learning_rate": 4.4189553042541734e-05,
      "loss": 0.6267,
      "step": 1080
    },
    {
      "epoch": 0.35218093699515346,
      "grad_norm": 7.201263427734375,
      "learning_rate": 4.413570274636511e-05,
      "loss": 0.678,
      "step": 1090
    },
    {
      "epoch": 0.3554119547657512,
      "grad_norm": 5.173950672149658,
      "learning_rate": 4.4081852450188475e-05,
      "loss": 0.6535,
      "step": 1100
    },
    {
      "epoch": 0.35864297253634897,
      "grad_norm": 7.079433441162109,
      "learning_rate": 4.402800215401185e-05,
      "loss": 0.5297,
      "step": 1110
    },
    {
      "epoch": 0.36187399030694667,
      "grad_norm": 5.026819705963135,
      "learning_rate": 4.397415185783522e-05,
      "loss": 0.6042,
      "step": 1120
    },
    {
      "epoch": 0.3651050080775444,
      "grad_norm": 4.992667198181152,
      "learning_rate": 4.392030156165859e-05,
      "loss": 0.6269,
      "step": 1130
    },
    {
      "epoch": 0.3683360258481422,
      "grad_norm": 7.293528079986572,
      "learning_rate": 4.386645126548196e-05,
      "loss": 0.5629,
      "step": 1140
    },
    {
      "epoch": 0.3715670436187399,
      "grad_norm": 5.648796558380127,
      "learning_rate": 4.381260096930533e-05,
      "loss": 0.5555,
      "step": 1150
    },
    {
      "epoch": 0.37479806138933763,
      "grad_norm": 8.666446685791016,
      "learning_rate": 4.375875067312871e-05,
      "loss": 0.619,
      "step": 1160
    },
    {
      "epoch": 0.3780290791599354,
      "grad_norm": 7.06863260269165,
      "learning_rate": 4.370490037695207e-05,
      "loss": 0.7113,
      "step": 1170
    },
    {
      "epoch": 0.38126009693053314,
      "grad_norm": 5.1075334548950195,
      "learning_rate": 4.365105008077544e-05,
      "loss": 0.726,
      "step": 1180
    },
    {
      "epoch": 0.38449111470113084,
      "grad_norm": 5.973669528961182,
      "learning_rate": 4.359719978459882e-05,
      "loss": 0.7338,
      "step": 1190
    },
    {
      "epoch": 0.3877221324717286,
      "grad_norm": 4.622194290161133,
      "learning_rate": 4.3543349488422184e-05,
      "loss": 0.7762,
      "step": 1200
    },
    {
      "epoch": 0.39095315024232635,
      "grad_norm": 6.152627944946289,
      "learning_rate": 4.348949919224556e-05,
      "loss": 0.6994,
      "step": 1210
    },
    {
      "epoch": 0.39418416801292405,
      "grad_norm": 5.533524036407471,
      "learning_rate": 4.343564889606893e-05,
      "loss": 0.6708,
      "step": 1220
    },
    {
      "epoch": 0.3974151857835218,
      "grad_norm": 5.418243885040283,
      "learning_rate": 4.33817985998923e-05,
      "loss": 0.6769,
      "step": 1230
    },
    {
      "epoch": 0.40064620355411956,
      "grad_norm": 5.15695858001709,
      "learning_rate": 4.332794830371567e-05,
      "loss": 0.5932,
      "step": 1240
    },
    {
      "epoch": 0.40387722132471726,
      "grad_norm": 8.226658821105957,
      "learning_rate": 4.327409800753904e-05,
      "loss": 0.6824,
      "step": 1250
    },
    {
      "epoch": 0.407108239095315,
      "grad_norm": 6.876315116882324,
      "learning_rate": 4.322024771136242e-05,
      "loss": 0.6364,
      "step": 1260
    },
    {
      "epoch": 0.41033925686591277,
      "grad_norm": 5.561731338500977,
      "learning_rate": 4.316639741518578e-05,
      "loss": 0.694,
      "step": 1270
    },
    {
      "epoch": 0.4135702746365105,
      "grad_norm": 7.170412063598633,
      "learning_rate": 4.311254711900916e-05,
      "loss": 0.6081,
      "step": 1280
    },
    {
      "epoch": 0.4168012924071082,
      "grad_norm": 5.638001441955566,
      "learning_rate": 4.305869682283253e-05,
      "loss": 0.6447,
      "step": 1290
    },
    {
      "epoch": 0.420032310177706,
      "grad_norm": 6.921096324920654,
      "learning_rate": 4.30048465266559e-05,
      "loss": 0.6492,
      "step": 1300
    },
    {
      "epoch": 0.42326332794830374,
      "grad_norm": 4.082505702972412,
      "learning_rate": 4.295099623047927e-05,
      "loss": 0.6492,
      "step": 1310
    },
    {
      "epoch": 0.42649434571890144,
      "grad_norm": 8.228219032287598,
      "learning_rate": 4.289714593430264e-05,
      "loss": 0.6191,
      "step": 1320
    },
    {
      "epoch": 0.4297253634894992,
      "grad_norm": 6.746574878692627,
      "learning_rate": 4.2843295638126016e-05,
      "loss": 0.5761,
      "step": 1330
    },
    {
      "epoch": 0.43295638126009695,
      "grad_norm": 4.63884162902832,
      "learning_rate": 4.278944534194938e-05,
      "loss": 0.5897,
      "step": 1340
    },
    {
      "epoch": 0.43618739903069464,
      "grad_norm": 4.474815368652344,
      "learning_rate": 4.273559504577275e-05,
      "loss": 0.5679,
      "step": 1350
    },
    {
      "epoch": 0.4394184168012924,
      "grad_norm": 5.937878131866455,
      "learning_rate": 4.268174474959613e-05,
      "loss": 0.621,
      "step": 1360
    },
    {
      "epoch": 0.44264943457189015,
      "grad_norm": 5.862432956695557,
      "learning_rate": 4.26278944534195e-05,
      "loss": 0.5858,
      "step": 1370
    },
    {
      "epoch": 0.4458804523424879,
      "grad_norm": 6.819049835205078,
      "learning_rate": 4.257404415724287e-05,
      "loss": 0.8518,
      "step": 1380
    },
    {
      "epoch": 0.4491114701130856,
      "grad_norm": 4.298892974853516,
      "learning_rate": 4.252019386106624e-05,
      "loss": 0.5846,
      "step": 1390
    },
    {
      "epoch": 0.45234248788368336,
      "grad_norm": 5.562167167663574,
      "learning_rate": 4.246634356488961e-05,
      "loss": 0.5534,
      "step": 1400
    },
    {
      "epoch": 0.4555735056542811,
      "grad_norm": 3.557796001434326,
      "learning_rate": 4.241249326871298e-05,
      "loss": 0.6818,
      "step": 1410
    },
    {
      "epoch": 0.4588045234248788,
      "grad_norm": 7.093986511230469,
      "learning_rate": 4.235864297253635e-05,
      "loss": 0.4935,
      "step": 1420
    },
    {
      "epoch": 0.4620355411954766,
      "grad_norm": 5.53594446182251,
      "learning_rate": 4.2304792676359725e-05,
      "loss": 0.6172,
      "step": 1430
    },
    {
      "epoch": 0.46526655896607433,
      "grad_norm": 4.774928569793701,
      "learning_rate": 4.2250942380183095e-05,
      "loss": 0.7517,
      "step": 1440
    },
    {
      "epoch": 0.46849757673667203,
      "grad_norm": 9.675851821899414,
      "learning_rate": 4.219709208400646e-05,
      "loss": 0.678,
      "step": 1450
    },
    {
      "epoch": 0.4717285945072698,
      "grad_norm": 5.297379493713379,
      "learning_rate": 4.2143241787829836e-05,
      "loss": 0.6048,
      "step": 1460
    },
    {
      "epoch": 0.47495961227786754,
      "grad_norm": 4.54803991317749,
      "learning_rate": 4.2089391491653206e-05,
      "loss": 0.5877,
      "step": 1470
    },
    {
      "epoch": 0.4781906300484653,
      "grad_norm": 4.9278106689453125,
      "learning_rate": 4.203554119547658e-05,
      "loss": 0.5741,
      "step": 1480
    },
    {
      "epoch": 0.481421647819063,
      "grad_norm": 8.183439254760742,
      "learning_rate": 4.1981690899299946e-05,
      "loss": 0.7778,
      "step": 1490
    },
    {
      "epoch": 0.48465266558966075,
      "grad_norm": 5.642411231994629,
      "learning_rate": 4.1927840603123316e-05,
      "loss": 0.7557,
      "step": 1500
    },
    {
      "epoch": 0.4878836833602585,
      "grad_norm": 4.317013740539551,
      "learning_rate": 4.1873990306946693e-05,
      "loss": 0.6219,
      "step": 1510
    },
    {
      "epoch": 0.4911147011308562,
      "grad_norm": 4.463254928588867,
      "learning_rate": 4.182014001077006e-05,
      "loss": 0.6092,
      "step": 1520
    },
    {
      "epoch": 0.49434571890145396,
      "grad_norm": 5.30766487121582,
      "learning_rate": 4.1766289714593434e-05,
      "loss": 0.6413,
      "step": 1530
    },
    {
      "epoch": 0.4975767366720517,
      "grad_norm": 17.289899826049805,
      "learning_rate": 4.1712439418416804e-05,
      "loss": 0.6293,
      "step": 1540
    },
    {
      "epoch": 0.5008077544426495,
      "grad_norm": 6.429140567779541,
      "learning_rate": 4.1658589122240174e-05,
      "loss": 0.6064,
      "step": 1550
    },
    {
      "epoch": 0.5040387722132472,
      "grad_norm": 5.450157642364502,
      "learning_rate": 4.1604738826063544e-05,
      "loss": 0.7137,
      "step": 1560
    },
    {
      "epoch": 0.5072697899838449,
      "grad_norm": 6.1420578956604,
      "learning_rate": 4.1550888529886915e-05,
      "loss": 0.6831,
      "step": 1570
    },
    {
      "epoch": 0.5105008077544426,
      "grad_norm": 9.907917976379395,
      "learning_rate": 4.149703823371029e-05,
      "loss": 0.6089,
      "step": 1580
    },
    {
      "epoch": 0.5137318255250404,
      "grad_norm": 5.157035827636719,
      "learning_rate": 4.1443187937533655e-05,
      "loss": 0.6913,
      "step": 1590
    },
    {
      "epoch": 0.5169628432956381,
      "grad_norm": 6.308208465576172,
      "learning_rate": 4.138933764135703e-05,
      "loss": 0.5301,
      "step": 1600
    },
    {
      "epoch": 0.5201938610662359,
      "grad_norm": 5.167101860046387,
      "learning_rate": 4.13354873451804e-05,
      "loss": 0.626,
      "step": 1610
    },
    {
      "epoch": 0.5234248788368336,
      "grad_norm": 3.8084943294525146,
      "learning_rate": 4.128163704900377e-05,
      "loss": 0.5968,
      "step": 1620
    },
    {
      "epoch": 0.5266558966074314,
      "grad_norm": 6.008001804351807,
      "learning_rate": 4.122778675282714e-05,
      "loss": 0.6248,
      "step": 1630
    },
    {
      "epoch": 0.529886914378029,
      "grad_norm": 7.294092178344727,
      "learning_rate": 4.117393645665051e-05,
      "loss": 0.6915,
      "step": 1640
    },
    {
      "epoch": 0.5331179321486268,
      "grad_norm": 5.32042121887207,
      "learning_rate": 4.112008616047388e-05,
      "loss": 0.6271,
      "step": 1650
    },
    {
      "epoch": 0.5363489499192245,
      "grad_norm": 7.177106857299805,
      "learning_rate": 4.106623586429725e-05,
      "loss": 0.7163,
      "step": 1660
    },
    {
      "epoch": 0.5395799676898223,
      "grad_norm": 4.874721050262451,
      "learning_rate": 4.101238556812062e-05,
      "loss": 0.6872,
      "step": 1670
    },
    {
      "epoch": 0.5428109854604201,
      "grad_norm": 4.677715301513672,
      "learning_rate": 4.0958535271944e-05,
      "loss": 0.5302,
      "step": 1680
    },
    {
      "epoch": 0.5460420032310178,
      "grad_norm": 8.272920608520508,
      "learning_rate": 4.090468497576737e-05,
      "loss": 0.5424,
      "step": 1690
    },
    {
      "epoch": 0.5492730210016155,
      "grad_norm": 4.82570743560791,
      "learning_rate": 4.085083467959074e-05,
      "loss": 0.7043,
      "step": 1700
    },
    {
      "epoch": 0.5525040387722132,
      "grad_norm": 7.974873065948486,
      "learning_rate": 4.079698438341411e-05,
      "loss": 0.6633,
      "step": 1710
    },
    {
      "epoch": 0.555735056542811,
      "grad_norm": 6.089016437530518,
      "learning_rate": 4.074313408723748e-05,
      "loss": 0.5597,
      "step": 1720
    },
    {
      "epoch": 0.5589660743134087,
      "grad_norm": 4.247400283813477,
      "learning_rate": 4.068928379106085e-05,
      "loss": 0.6766,
      "step": 1730
    },
    {
      "epoch": 0.5621970920840065,
      "grad_norm": 4.82316780090332,
      "learning_rate": 4.063543349488422e-05,
      "loss": 0.6388,
      "step": 1740
    },
    {
      "epoch": 0.5654281098546042,
      "grad_norm": 6.509833335876465,
      "learning_rate": 4.05815831987076e-05,
      "loss": 0.6637,
      "step": 1750
    },
    {
      "epoch": 0.568659127625202,
      "grad_norm": 5.070039749145508,
      "learning_rate": 4.052773290253097e-05,
      "loss": 0.6219,
      "step": 1760
    },
    {
      "epoch": 0.5718901453957996,
      "grad_norm": 7.556416034698486,
      "learning_rate": 4.047388260635433e-05,
      "loss": 0.6304,
      "step": 1770
    },
    {
      "epoch": 0.5751211631663974,
      "grad_norm": 7.074969291687012,
      "learning_rate": 4.042003231017771e-05,
      "loss": 0.6381,
      "step": 1780
    },
    {
      "epoch": 0.5783521809369951,
      "grad_norm": 4.140515327453613,
      "learning_rate": 4.036618201400108e-05,
      "loss": 0.5132,
      "step": 1790
    },
    {
      "epoch": 0.5815831987075929,
      "grad_norm": 5.131270885467529,
      "learning_rate": 4.031233171782445e-05,
      "loss": 0.7487,
      "step": 1800
    },
    {
      "epoch": 0.5848142164781907,
      "grad_norm": 7.172304630279541,
      "learning_rate": 4.025848142164782e-05,
      "loss": 0.7329,
      "step": 1810
    },
    {
      "epoch": 0.5880452342487884,
      "grad_norm": 4.882132530212402,
      "learning_rate": 4.020463112547119e-05,
      "loss": 0.5767,
      "step": 1820
    },
    {
      "epoch": 0.5912762520193862,
      "grad_norm": 4.9695210456848145,
      "learning_rate": 4.015078082929457e-05,
      "loss": 0.6158,
      "step": 1830
    },
    {
      "epoch": 0.5945072697899838,
      "grad_norm": 6.865639686584473,
      "learning_rate": 4.009693053311793e-05,
      "loss": 0.6365,
      "step": 1840
    },
    {
      "epoch": 0.5977382875605816,
      "grad_norm": 4.481626510620117,
      "learning_rate": 4.004308023694131e-05,
      "loss": 0.5522,
      "step": 1850
    },
    {
      "epoch": 0.6009693053311793,
      "grad_norm": 4.866164207458496,
      "learning_rate": 3.998922994076468e-05,
      "loss": 0.573,
      "step": 1860
    },
    {
      "epoch": 0.6042003231017771,
      "grad_norm": 6.905168533325195,
      "learning_rate": 3.993537964458805e-05,
      "loss": 0.5641,
      "step": 1870
    },
    {
      "epoch": 0.6074313408723748,
      "grad_norm": 6.353161811828613,
      "learning_rate": 3.988152934841142e-05,
      "loss": 0.7394,
      "step": 1880
    },
    {
      "epoch": 0.6106623586429726,
      "grad_norm": 8.775757789611816,
      "learning_rate": 3.982767905223479e-05,
      "loss": 0.5654,
      "step": 1890
    },
    {
      "epoch": 0.6138933764135702,
      "grad_norm": 5.429425239562988,
      "learning_rate": 3.9773828756058165e-05,
      "loss": 0.6692,
      "step": 1900
    },
    {
      "epoch": 0.617124394184168,
      "grad_norm": 6.828724384307861,
      "learning_rate": 3.971997845988153e-05,
      "loss": 0.591,
      "step": 1910
    },
    {
      "epoch": 0.6203554119547657,
      "grad_norm": 5.227725505828857,
      "learning_rate": 3.9666128163704905e-05,
      "loss": 0.5093,
      "step": 1920
    },
    {
      "epoch": 0.6235864297253635,
      "grad_norm": 6.3347930908203125,
      "learning_rate": 3.9612277867528275e-05,
      "loss": 0.7099,
      "step": 1930
    },
    {
      "epoch": 0.6268174474959612,
      "grad_norm": 6.772780418395996,
      "learning_rate": 3.955842757135164e-05,
      "loss": 0.5872,
      "step": 1940
    },
    {
      "epoch": 0.630048465266559,
      "grad_norm": 4.937075138092041,
      "learning_rate": 3.9504577275175016e-05,
      "loss": 0.5808,
      "step": 1950
    },
    {
      "epoch": 0.6332794830371568,
      "grad_norm": 5.4543867111206055,
      "learning_rate": 3.9450726978998386e-05,
      "loss": 0.6105,
      "step": 1960
    },
    {
      "epoch": 0.6365105008077544,
      "grad_norm": 6.319263458251953,
      "learning_rate": 3.9396876682821756e-05,
      "loss": 0.6641,
      "step": 1970
    },
    {
      "epoch": 0.6397415185783522,
      "grad_norm": 5.6656270027160645,
      "learning_rate": 3.9343026386645126e-05,
      "loss": 0.7074,
      "step": 1980
    },
    {
      "epoch": 0.6429725363489499,
      "grad_norm": 2.8928866386413574,
      "learning_rate": 3.9289176090468497e-05,
      "loss": 0.5834,
      "step": 1990
    },
    {
      "epoch": 0.6462035541195477,
      "grad_norm": 4.535325527191162,
      "learning_rate": 3.9235325794291874e-05,
      "loss": 0.5792,
      "step": 2000
    },
    {
      "epoch": 0.6494345718901454,
      "grad_norm": 4.546639442443848,
      "learning_rate": 3.918147549811524e-05,
      "loss": 0.5867,
      "step": 2010
    },
    {
      "epoch": 0.6526655896607432,
      "grad_norm": 7.3557634353637695,
      "learning_rate": 3.9127625201938614e-05,
      "loss": 0.5758,
      "step": 2020
    },
    {
      "epoch": 0.6558966074313409,
      "grad_norm": 4.156857490539551,
      "learning_rate": 3.9073774905761984e-05,
      "loss": 0.6916,
      "step": 2030
    },
    {
      "epoch": 0.6591276252019386,
      "grad_norm": 5.9208598136901855,
      "learning_rate": 3.9019924609585354e-05,
      "loss": 0.6137,
      "step": 2040
    },
    {
      "epoch": 0.6623586429725363,
      "grad_norm": 3.490133047103882,
      "learning_rate": 3.8966074313408725e-05,
      "loss": 0.5703,
      "step": 2050
    },
    {
      "epoch": 0.6655896607431341,
      "grad_norm": 2.3303005695343018,
      "learning_rate": 3.8912224017232095e-05,
      "loss": 0.5799,
      "step": 2060
    },
    {
      "epoch": 0.6688206785137318,
      "grad_norm": 5.55211877822876,
      "learning_rate": 3.885837372105547e-05,
      "loss": 0.5782,
      "step": 2070
    },
    {
      "epoch": 0.6720516962843296,
      "grad_norm": 5.311337947845459,
      "learning_rate": 3.880452342487884e-05,
      "loss": 0.692,
      "step": 2080
    },
    {
      "epoch": 0.6752827140549273,
      "grad_norm": 3.96500563621521,
      "learning_rate": 3.8750673128702205e-05,
      "loss": 0.512,
      "step": 2090
    },
    {
      "epoch": 0.678513731825525,
      "grad_norm": 5.835485935211182,
      "learning_rate": 3.869682283252558e-05,
      "loss": 0.5752,
      "step": 2100
    },
    {
      "epoch": 0.6817447495961227,
      "grad_norm": 5.8569159507751465,
      "learning_rate": 3.864297253634895e-05,
      "loss": 0.6707,
      "step": 2110
    },
    {
      "epoch": 0.6849757673667205,
      "grad_norm": 5.234961986541748,
      "learning_rate": 3.858912224017232e-05,
      "loss": 0.5535,
      "step": 2120
    },
    {
      "epoch": 0.6882067851373183,
      "grad_norm": 4.01052713394165,
      "learning_rate": 3.853527194399569e-05,
      "loss": 0.4793,
      "step": 2130
    },
    {
      "epoch": 0.691437802907916,
      "grad_norm": 4.227420806884766,
      "learning_rate": 3.848142164781906e-05,
      "loss": 0.572,
      "step": 2140
    },
    {
      "epoch": 0.6946688206785138,
      "grad_norm": 5.354206085205078,
      "learning_rate": 3.842757135164244e-05,
      "loss": 0.4994,
      "step": 2150
    },
    {
      "epoch": 0.6978998384491115,
      "grad_norm": 3.960420846939087,
      "learning_rate": 3.8373721055465803e-05,
      "loss": 0.6361,
      "step": 2160
    },
    {
      "epoch": 0.7011308562197092,
      "grad_norm": 4.85116720199585,
      "learning_rate": 3.831987075928918e-05,
      "loss": 0.628,
      "step": 2170
    },
    {
      "epoch": 0.7043618739903069,
      "grad_norm": 4.524918079376221,
      "learning_rate": 3.826602046311255e-05,
      "loss": 0.6749,
      "step": 2180
    },
    {
      "epoch": 0.7075928917609047,
      "grad_norm": 3.9776062965393066,
      "learning_rate": 3.821217016693592e-05,
      "loss": 0.5754,
      "step": 2190
    },
    {
      "epoch": 0.7108239095315024,
      "grad_norm": 4.142299175262451,
      "learning_rate": 3.815831987075929e-05,
      "loss": 0.644,
      "step": 2200
    },
    {
      "epoch": 0.7140549273021002,
      "grad_norm": 6.341064929962158,
      "learning_rate": 3.810446957458266e-05,
      "loss": 0.6085,
      "step": 2210
    },
    {
      "epoch": 0.7172859450726979,
      "grad_norm": 4.491867542266846,
      "learning_rate": 3.805061927840604e-05,
      "loss": 0.6565,
      "step": 2220
    },
    {
      "epoch": 0.7205169628432956,
      "grad_norm": 5.957065582275391,
      "learning_rate": 3.79967689822294e-05,
      "loss": 0.5588,
      "step": 2230
    },
    {
      "epoch": 0.7237479806138933,
      "grad_norm": 5.602373123168945,
      "learning_rate": 3.794291868605278e-05,
      "loss": 0.7917,
      "step": 2240
    },
    {
      "epoch": 0.7269789983844911,
      "grad_norm": 5.8564019203186035,
      "learning_rate": 3.788906838987615e-05,
      "loss": 0.7085,
      "step": 2250
    },
    {
      "epoch": 0.7302100161550888,
      "grad_norm": 5.674192905426025,
      "learning_rate": 3.783521809369951e-05,
      "loss": 0.6009,
      "step": 2260
    },
    {
      "epoch": 0.7334410339256866,
      "grad_norm": 3.295180320739746,
      "learning_rate": 3.778136779752289e-05,
      "loss": 0.5853,
      "step": 2270
    },
    {
      "epoch": 0.7366720516962844,
      "grad_norm": 4.710778713226318,
      "learning_rate": 3.772751750134626e-05,
      "loss": 0.7596,
      "step": 2280
    },
    {
      "epoch": 0.7399030694668821,
      "grad_norm": 4.2119975090026855,
      "learning_rate": 3.767366720516963e-05,
      "loss": 0.6248,
      "step": 2290
    },
    {
      "epoch": 0.7431340872374798,
      "grad_norm": 4.90091609954834,
      "learning_rate": 3.7619816908993e-05,
      "loss": 0.5493,
      "step": 2300
    },
    {
      "epoch": 0.7463651050080775,
      "grad_norm": 6.209066867828369,
      "learning_rate": 3.756596661281637e-05,
      "loss": 0.5727,
      "step": 2310
    },
    {
      "epoch": 0.7495961227786753,
      "grad_norm": 5.241613388061523,
      "learning_rate": 3.751211631663975e-05,
      "loss": 0.6093,
      "step": 2320
    },
    {
      "epoch": 0.752827140549273,
      "grad_norm": 6.120643138885498,
      "learning_rate": 3.745826602046311e-05,
      "loss": 0.6132,
      "step": 2330
    },
    {
      "epoch": 0.7560581583198708,
      "grad_norm": 5.706867218017578,
      "learning_rate": 3.740441572428649e-05,
      "loss": 0.703,
      "step": 2340
    },
    {
      "epoch": 0.7592891760904685,
      "grad_norm": 6.526123523712158,
      "learning_rate": 3.735056542810986e-05,
      "loss": 0.6932,
      "step": 2350
    },
    {
      "epoch": 0.7625201938610663,
      "grad_norm": 6.290457248687744,
      "learning_rate": 3.729671513193323e-05,
      "loss": 0.5864,
      "step": 2360
    },
    {
      "epoch": 0.7657512116316639,
      "grad_norm": 4.790426731109619,
      "learning_rate": 3.72428648357566e-05,
      "loss": 0.6349,
      "step": 2370
    },
    {
      "epoch": 0.7689822294022617,
      "grad_norm": 4.8561530113220215,
      "learning_rate": 3.718901453957997e-05,
      "loss": 0.6474,
      "step": 2380
    },
    {
      "epoch": 0.7722132471728594,
      "grad_norm": 3.3073103427886963,
      "learning_rate": 3.7135164243403345e-05,
      "loss": 0.5635,
      "step": 2390
    },
    {
      "epoch": 0.7754442649434572,
      "grad_norm": 7.05451774597168,
      "learning_rate": 3.708131394722671e-05,
      "loss": 0.6756,
      "step": 2400
    },
    {
      "epoch": 0.778675282714055,
      "grad_norm": 4.679426670074463,
      "learning_rate": 3.702746365105008e-05,
      "loss": 0.6411,
      "step": 2410
    },
    {
      "epoch": 0.7819063004846527,
      "grad_norm": 5.037328243255615,
      "learning_rate": 3.6973613354873456e-05,
      "loss": 0.5517,
      "step": 2420
    },
    {
      "epoch": 0.7851373182552503,
      "grad_norm": 6.090858459472656,
      "learning_rate": 3.6919763058696826e-05,
      "loss": 0.7058,
      "step": 2430
    },
    {
      "epoch": 0.7883683360258481,
      "grad_norm": 4.45987606048584,
      "learning_rate": 3.6865912762520196e-05,
      "loss": 0.6546,
      "step": 2440
    },
    {
      "epoch": 0.7915993537964459,
      "grad_norm": 6.142158031463623,
      "learning_rate": 3.6812062466343566e-05,
      "loss": 0.6281,
      "step": 2450
    },
    {
      "epoch": 0.7948303715670436,
      "grad_norm": 4.586140155792236,
      "learning_rate": 3.6758212170166936e-05,
      "loss": 0.6203,
      "step": 2460
    },
    {
      "epoch": 0.7980613893376414,
      "grad_norm": 5.9910359382629395,
      "learning_rate": 3.6704361873990307e-05,
      "loss": 0.6419,
      "step": 2470
    },
    {
      "epoch": 0.8012924071082391,
      "grad_norm": 4.049652099609375,
      "learning_rate": 3.665051157781368e-05,
      "loss": 0.6098,
      "step": 2480
    },
    {
      "epoch": 0.8045234248788369,
      "grad_norm": 5.350765705108643,
      "learning_rate": 3.6596661281637054e-05,
      "loss": 0.6434,
      "step": 2490
    },
    {
      "epoch": 0.8077544426494345,
      "grad_norm": 7.236899375915527,
      "learning_rate": 3.6542810985460424e-05,
      "loss": 0.634,
      "step": 2500
    },
    {
      "epoch": 0.8109854604200323,
      "grad_norm": 10.274799346923828,
      "learning_rate": 3.6488960689283794e-05,
      "loss": 0.5897,
      "step": 2510
    },
    {
      "epoch": 0.81421647819063,
      "grad_norm": 3.503377914428711,
      "learning_rate": 3.6435110393107164e-05,
      "loss": 0.6867,
      "step": 2520
    },
    {
      "epoch": 0.8174474959612278,
      "grad_norm": 5.228992462158203,
      "learning_rate": 3.6381260096930535e-05,
      "loss": 0.626,
      "step": 2530
    },
    {
      "epoch": 0.8206785137318255,
      "grad_norm": 5.3408122062683105,
      "learning_rate": 3.6327409800753905e-05,
      "loss": 0.674,
      "step": 2540
    },
    {
      "epoch": 0.8239095315024233,
      "grad_norm": 10.178389549255371,
      "learning_rate": 3.6273559504577275e-05,
      "loss": 0.6341,
      "step": 2550
    },
    {
      "epoch": 0.827140549273021,
      "grad_norm": 5.281156063079834,
      "learning_rate": 3.6219709208400645e-05,
      "loss": 0.5989,
      "step": 2560
    },
    {
      "epoch": 0.8303715670436187,
      "grad_norm": 5.0918498039245605,
      "learning_rate": 3.616585891222402e-05,
      "loss": 0.6509,
      "step": 2570
    },
    {
      "epoch": 0.8336025848142165,
      "grad_norm": 5.150624752044678,
      "learning_rate": 3.6112008616047385e-05,
      "loss": 0.5909,
      "step": 2580
    },
    {
      "epoch": 0.8368336025848142,
      "grad_norm": 5.081061363220215,
      "learning_rate": 3.605815831987076e-05,
      "loss": 0.6608,
      "step": 2590
    },
    {
      "epoch": 0.840064620355412,
      "grad_norm": 6.393115043640137,
      "learning_rate": 3.600430802369413e-05,
      "loss": 0.6049,
      "step": 2600
    },
    {
      "epoch": 0.8432956381260097,
      "grad_norm": 7.756272315979004,
      "learning_rate": 3.59504577275175e-05,
      "loss": 0.6503,
      "step": 2610
    },
    {
      "epoch": 0.8465266558966075,
      "grad_norm": 6.545628070831299,
      "learning_rate": 3.589660743134087e-05,
      "loss": 0.7844,
      "step": 2620
    },
    {
      "epoch": 0.8497576736672051,
      "grad_norm": 5.642961502075195,
      "learning_rate": 3.584275713516424e-05,
      "loss": 0.6596,
      "step": 2630
    },
    {
      "epoch": 0.8529886914378029,
      "grad_norm": 6.634324550628662,
      "learning_rate": 3.578890683898762e-05,
      "loss": 0.5691,
      "step": 2640
    },
    {
      "epoch": 0.8562197092084006,
      "grad_norm": 6.03825569152832,
      "learning_rate": 3.5735056542810984e-05,
      "loss": 0.6239,
      "step": 2650
    },
    {
      "epoch": 0.8594507269789984,
      "grad_norm": 6.267035007476807,
      "learning_rate": 3.568120624663436e-05,
      "loss": 0.6609,
      "step": 2660
    },
    {
      "epoch": 0.8626817447495961,
      "grad_norm": 7.355453014373779,
      "learning_rate": 3.562735595045773e-05,
      "loss": 0.5964,
      "step": 2670
    },
    {
      "epoch": 0.8659127625201939,
      "grad_norm": 9.460224151611328,
      "learning_rate": 3.55735056542811e-05,
      "loss": 0.4859,
      "step": 2680
    },
    {
      "epoch": 0.8691437802907916,
      "grad_norm": 5.180482387542725,
      "learning_rate": 3.551965535810447e-05,
      "loss": 0.6326,
      "step": 2690
    },
    {
      "epoch": 0.8723747980613893,
      "grad_norm": 5.863675594329834,
      "learning_rate": 3.546580506192784e-05,
      "loss": 0.6342,
      "step": 2700
    },
    {
      "epoch": 0.875605815831987,
      "grad_norm": 5.0313920974731445,
      "learning_rate": 3.541195476575122e-05,
      "loss": 0.4392,
      "step": 2710
    },
    {
      "epoch": 0.8788368336025848,
      "grad_norm": 4.685412406921387,
      "learning_rate": 3.535810446957458e-05,
      "loss": 0.5345,
      "step": 2720
    },
    {
      "epoch": 0.8820678513731826,
      "grad_norm": 2.9302079677581787,
      "learning_rate": 3.530425417339795e-05,
      "loss": 0.5607,
      "step": 2730
    },
    {
      "epoch": 0.8852988691437803,
      "grad_norm": 6.850212097167969,
      "learning_rate": 3.525040387722133e-05,
      "loss": 0.7556,
      "step": 2740
    },
    {
      "epoch": 0.8885298869143781,
      "grad_norm": 4.290643692016602,
      "learning_rate": 3.51965535810447e-05,
      "loss": 0.6181,
      "step": 2750
    },
    {
      "epoch": 0.8917609046849758,
      "grad_norm": 6.186358451843262,
      "learning_rate": 3.514270328486807e-05,
      "loss": 0.5754,
      "step": 2760
    },
    {
      "epoch": 0.8949919224555735,
      "grad_norm": 4.020362854003906,
      "learning_rate": 3.508885298869144e-05,
      "loss": 0.6146,
      "step": 2770
    },
    {
      "epoch": 0.8982229402261712,
      "grad_norm": 6.065805435180664,
      "learning_rate": 3.503500269251481e-05,
      "loss": 0.5745,
      "step": 2780
    },
    {
      "epoch": 0.901453957996769,
      "grad_norm": 3.5250918865203857,
      "learning_rate": 3.498115239633818e-05,
      "loss": 0.4773,
      "step": 2790
    },
    {
      "epoch": 0.9046849757673667,
      "grad_norm": 5.63525390625,
      "learning_rate": 3.492730210016155e-05,
      "loss": 0.5951,
      "step": 2800
    },
    {
      "epoch": 0.9079159935379645,
      "grad_norm": 6.02093505859375,
      "learning_rate": 3.487345180398493e-05,
      "loss": 0.5999,
      "step": 2810
    },
    {
      "epoch": 0.9111470113085622,
      "grad_norm": 4.406713962554932,
      "learning_rate": 3.48196015078083e-05,
      "loss": 0.5645,
      "step": 2820
    },
    {
      "epoch": 0.9143780290791599,
      "grad_norm": 4.587800979614258,
      "learning_rate": 3.476575121163167e-05,
      "loss": 0.5001,
      "step": 2830
    },
    {
      "epoch": 0.9176090468497576,
      "grad_norm": 5.142082691192627,
      "learning_rate": 3.471190091545504e-05,
      "loss": 0.6255,
      "step": 2840
    },
    {
      "epoch": 0.9208400646203554,
      "grad_norm": 5.29564905166626,
      "learning_rate": 3.465805061927841e-05,
      "loss": 0.6025,
      "step": 2850
    },
    {
      "epoch": 0.9240710823909531,
      "grad_norm": 7.106198310852051,
      "learning_rate": 3.460420032310178e-05,
      "loss": 0.6275,
      "step": 2860
    },
    {
      "epoch": 0.9273021001615509,
      "grad_norm": 4.0117034912109375,
      "learning_rate": 3.455035002692515e-05,
      "loss": 0.6194,
      "step": 2870
    },
    {
      "epoch": 0.9305331179321487,
      "grad_norm": 5.332397937774658,
      "learning_rate": 3.449649973074852e-05,
      "loss": 0.6134,
      "step": 2880
    },
    {
      "epoch": 0.9337641357027464,
      "grad_norm": 7.008533954620361,
      "learning_rate": 3.4442649434571895e-05,
      "loss": 0.6269,
      "step": 2890
    },
    {
      "epoch": 0.9369951534733441,
      "grad_norm": 5.8252973556518555,
      "learning_rate": 3.438879913839526e-05,
      "loss": 0.5496,
      "step": 2900
    },
    {
      "epoch": 0.9402261712439418,
      "grad_norm": 8.497054100036621,
      "learning_rate": 3.4334948842218636e-05,
      "loss": 0.615,
      "step": 2910
    },
    {
      "epoch": 0.9434571890145396,
      "grad_norm": 4.075296401977539,
      "learning_rate": 3.4281098546042006e-05,
      "loss": 0.552,
      "step": 2920
    },
    {
      "epoch": 0.9466882067851373,
      "grad_norm": 5.483770847320557,
      "learning_rate": 3.4227248249865376e-05,
      "loss": 0.6142,
      "step": 2930
    },
    {
      "epoch": 0.9499192245557351,
      "grad_norm": 5.94126558303833,
      "learning_rate": 3.4173397953688746e-05,
      "loss": 0.5607,
      "step": 2940
    },
    {
      "epoch": 0.9531502423263328,
      "grad_norm": 6.034850120544434,
      "learning_rate": 3.4119547657512117e-05,
      "loss": 0.597,
      "step": 2950
    },
    {
      "epoch": 0.9563812600969306,
      "grad_norm": 4.423614978790283,
      "learning_rate": 3.4065697361335494e-05,
      "loss": 0.5418,
      "step": 2960
    },
    {
      "epoch": 0.9596122778675282,
      "grad_norm": 4.744788646697998,
      "learning_rate": 3.401184706515886e-05,
      "loss": 0.6287,
      "step": 2970
    },
    {
      "epoch": 0.962843295638126,
      "grad_norm": 4.870917320251465,
      "learning_rate": 3.3957996768982234e-05,
      "loss": 0.5174,
      "step": 2980
    },
    {
      "epoch": 0.9660743134087237,
      "grad_norm": 6.054892063140869,
      "learning_rate": 3.3904146472805604e-05,
      "loss": 0.6527,
      "step": 2990
    },
    {
      "epoch": 0.9693053311793215,
      "grad_norm": 4.294091701507568,
      "learning_rate": 3.385029617662897e-05,
      "loss": 0.4925,
      "step": 3000
    },
    {
      "epoch": 0.9725363489499192,
      "grad_norm": 8.23051643371582,
      "learning_rate": 3.3796445880452344e-05,
      "loss": 0.7563,
      "step": 3010
    },
    {
      "epoch": 0.975767366720517,
      "grad_norm": 5.4221720695495605,
      "learning_rate": 3.3742595584275715e-05,
      "loss": 0.6469,
      "step": 3020
    },
    {
      "epoch": 0.9789983844911146,
      "grad_norm": 4.458278656005859,
      "learning_rate": 3.368874528809909e-05,
      "loss": 0.5703,
      "step": 3030
    },
    {
      "epoch": 0.9822294022617124,
      "grad_norm": 4.550007343292236,
      "learning_rate": 3.3634894991922455e-05,
      "loss": 0.6657,
      "step": 3040
    },
    {
      "epoch": 0.9854604200323102,
      "grad_norm": 4.883275985717773,
      "learning_rate": 3.3581044695745825e-05,
      "loss": 0.578,
      "step": 3050
    },
    {
      "epoch": 0.9886914378029079,
      "grad_norm": 3.981276035308838,
      "learning_rate": 3.35271943995692e-05,
      "loss": 0.6322,
      "step": 3060
    },
    {
      "epoch": 0.9919224555735057,
      "grad_norm": 5.139693260192871,
      "learning_rate": 3.3473344103392566e-05,
      "loss": 0.5806,
      "step": 3070
    },
    {
      "epoch": 0.9951534733441034,
      "grad_norm": 4.166479110717773,
      "learning_rate": 3.341949380721594e-05,
      "loss": 0.5571,
      "step": 3080
    },
    {
      "epoch": 0.9983844911147012,
      "grad_norm": 6.588808536529541,
      "learning_rate": 3.336564351103931e-05,
      "loss": 0.6154,
      "step": 3090
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.6360738277435303,
      "eval_runtime": 30.3438,
      "eval_samples_per_second": 22.673,
      "eval_steps_per_second": 11.337,
      "step": 3095
    }
  ],
  "logging_steps": 10,
  "max_steps": 9285,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 6706105191235584.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
